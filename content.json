{"meta":{"title":"MakeItPossible","subtitle":null,"description":"闲着没事写点东西","author":"Caden","url":"https://Caden16.github.io"},"posts":[{"title":"(转)自旋锁spinlock剖析与改进","slug":"自旋锁spinlock剖析与改进","date":"2017-04-29T13:36:43.774Z","updated":"2017-03-12T14:16:40.177Z","comments":true,"path":"操作系统/自旋锁spinlock剖析与改进/","link":"","permalink":"https://Caden16.github.io/操作系统/自旋锁spinlock剖析与改进/","excerpt":"","text":"遇到题目：运行在多核处理器上的Linux环境中,若临界区非常短,且不允许线程上下文切换的情况下,使用下列哪种机制满足上述需求并且性能最好? SpinLockSpinLockMutexSemaphoreCondition variable对SpinLock 以及Mutex不太了解，参考自旋锁spinlock剖析与改进,得到比较全面的认识。spinlock又称自旋锁，线程通过busy-wait-loop的方式来获取锁，任时刻只有一个线程能够获得锁，其他线程忙等待直到获得锁。spinlock在多处理器多线程环境的场景中有很广泛的使用，一般要求使用spinlock的临界区尽量简短，这样获取的锁可以尽快释放，以满足其他忙等的线程。Spinlock和mutex不同，spinlock不会导致线程的状态切换(用户态-&gt;内核态)，但是spinlock使用不当(如临界区执行时间过长)会导致cpu busy飙高。spinlock不会使线程状态发生切换，mutex在获取不到锁的时候会选择sleep。","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"}]},{"title":"git使用","slug":"git使用","date":"2017-04-28T00:00:00.000Z","updated":"2017-04-30T12:35:18.186Z","comments":true,"path":"git/git使用/","link":"","permalink":"https://Caden16.github.io/git/git使用/","excerpt":"","text":"修改已提交commit参考How to modify existing, unpushed commits?修改最近一次commitgit commit –amend修改多次commit git rebase –interactive $parent_of_flawed_commitIf you want to fix several flawed commits, pass the parent of the oldest one of them. An editor will come up, with a list of all commits since the one you gave.Change pick to reword (or on old versions of Git, to edit) in front of any commits you want to fix.Once you save, Git will replay the listed commits. For each commit you want to reword, Git will drop you back into your editor. For each commit you want to edit, Git drops you into the shell. If you’re in the shell: Change the commit in any way you like. git commit –amend git rebase –continue 修改远程仓库地址查看已连接远程仓库git remote -v修改:git remote set-url origin [url]或:git remote rm origingit remote add origin [url]","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://Caden16.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://Caden16.github.io/tags/git/"}]},{"title":"python inner function","slug":"python inner function","date":"2017-04-26T00:00:00.000Z","updated":"2017-04-26T13:11:13.232Z","comments":true,"path":"python/python inner function/","link":"","permalink":"https://Caden16.github.io/python/python inner function/","excerpt":"","text":"参考python之嵌套函数与闭包Python nested scopes with dynamic features一个关于python闭包的问题，内部函数可以获取外部函数的变量吗？使用方法:12345678def outer(): x = 1 def inner(): print x # 1 inner() # 2outer()# 输出结果 : 1 #1的地方，python寻找名为x的local变量，在inner作用域内的locals中寻找不到，python就在外层作用域中寻找，其外层是outer函数。x是定义在outer作用域范围内的local变量。#2的地方，调用了inner函数。这里需要特别注意：inner也只是一个变量名，是遵循python的变量查找规则的（Python先在outer函数的作用域中寻找名为inner的local变量） 错误用法:12345678def outer(): x = 1 def inner(): print x # 1 # UnboundLocalError: local variable 'x' referenced before assignment x = 2 inner() # 2 del x # SyntaxError: can not delete variable 'x' referenced in nested scopeouter() UnboundLocalError: x = 2 相当于声明了 x , 会把outer中的x覆盖, #1 产生变量未声明就使用的错误SyntaxError: Python nested scopes with dynamic features删除的x对象还在嵌套函数中被使用, 不能删除. python3.2 可以使用del x.","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"}]},{"title":"python网速控制","slug":"python流量控制","date":"2017-04-17T00:00:00.000Z","updated":"2017-04-26T13:41:21.890Z","comments":true,"path":"python/python流量控制/","link":"","permalink":"https://Caden16.github.io/python/python流量控制/","excerpt":"","text":"流量控制算法,参考令牌桶算法和漏桶算法令牌桶算法Bandwidth throttling in PythonHow do you rate-limit an IO operation?How to limit download rate of HTTP requests in requests python library?采用令牌漏桶进行报文限流的方法 &gt; 主要算法漏桶算法能够强行限制数据的传输速率，而令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。 漏桶算法（Leaky Bucket）:主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。 令牌桶算法（Token Bucket）令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。令牌桶算法的基本过程如下： 假如用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中； 假设桶最多可以存发b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 当一个n个字节的数据包到达时，就从令牌桶中删除n个令牌，并且数据包被发送到网络； 如果令牌桶中少于n个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外； 算法允许最长b个字节的突发，但从长期运行结果看，数据包的速率被限制成常量r。对于在流量限制外的数据包可以以不同的方式处理： 它们可以被丢弃； 它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输； 它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃。 python token bucket实现python Token Bucket实现IMPLEMENTATION OF THE TOKEN BUCKET ALGORITHM (PYTHON RECIPE)复制代码:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from time import timeclass TokenBucket(object): \"\"\"An implementation of the token bucket algorithm. &gt;&gt;&gt; bucket = TokenBucket(80, 0.5) &gt;&gt;&gt; print bucket.consume(10) True &gt;&gt;&gt; print bucket.consume(90) False \"\"\" def __init__(self, tokens, fill_rate): \"\"\"tokens is the total tokens in the bucket. fill_rate is the rate in tokens/second that the bucket will be refilled.\"\"\" self.capacity = float(tokens) self._tokens = float(tokens) self.fill_rate = float(fill_rate) self.timestamp = time() def consume(self, tokens): \"\"\"Consume tokens from the bucket. Returns True if there were sufficient tokens otherwise False.\"\"\" if tokens &lt;= self.tokens: self._tokens -= tokens else: return False return True def get_tokens(self): if self._tokens &lt; self.capacity: now = time() delta = self.fill_rate * (now - self.timestamp) self._tokens = min(self.capacity, self._tokens + delta) self.timestamp = now return self._tokens tokens = property(get_tokens)if __name__ == '__main__': from time import sleep bucket = TokenBucket(80, 1) print \"tokens =\", bucket.tokens print \"consume(10) =\", bucket.consume(10) print \"consume(10) =\", bucket.consume(10) sleep(1) print \"tokens =\", bucket.tokens sleep(1) print \"tokens =\", bucket.tokens print \"consume(90) =\", bucket.consume(90) print \"tokens =\", bucket.tokens github 实现源码:https://github.com/rbarrois/throttlehttps://github.com/titan-web/rate-limit 使用范围限制文件上传,下载速度,网络连接数量","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"},{"name":"流量控制","slug":"流量控制","permalink":"https://Caden16.github.io/tags/流量控制/"}]},{"title":"kafka存储实现","slug":"kafka存储实现","date":"2017-04-12T00:00:00.000Z","updated":"2017-04-26T11:40:45.341Z","comments":true,"path":"文件存储/kafka存储实现/","link":"","permalink":"https://Caden16.github.io/文件存储/kafka存储实现/","excerpt":"","text":"参考Kafka文件存储机制那些事Kafka之数据存储apache kafka系列之文件系统设计那些kafka 高吞吐量性能揭秘Linux网络编程–sendfile零拷贝高效率发送文件Linux 中的零拷贝技术，第 2 部分通过零拷贝实现有效数据传输kafka数据可靠性深度解读kafka实现高性能存储数据的方式：1.pageCache2.Sendfile (属于零拷贝技术的一种) pageCache当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。 SendfileSendfile是Linux实现的系统调用，可以通过避免文件在内核态和用户态的拷贝来优化文件传输的效率Linux中传统服务器进行数据传输的流程:用户请求–&gt;服务器应用程序调用read读取文件–&gt;内核VFS read–&gt;文件系统read–&gt;DMA加载数据块到pagecache–&gt;用户进程把数据从内核区Copy到用户区–&gt;数据写到网络堆栈相关的内核缓冲区–&gt;数据传输 当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内，如果在内核缓冲区中找不到这块数据，Linux 操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由 DMA 完成的，那么在 DMA 进行数据读取的这一过程中，CPU 只是需要进行缓冲区管理，以及创建和处理 DMA ，除此之外，CPU 不需要再做更多的事情，DMA 执行完数据读取操作之后，会通知操作系统做进一步的处理。Linux 操作系统会根据 read() 系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去，在接下来的处理过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是需要占用 CPU 的。数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。之后，在调用 write() 系统调用的时候，用户应用程序缓冲区中的数据内容可以被安全的丢弃或者更改，因为操作系统已经在内核缓冲区中保留了一份数据拷贝，当数据被成功传送到硬件上之后，这份数据拷贝就可以被丢弃。从上面的描述可以看出，在这种传统的数据传输过程中，数据至少发生了四次拷贝操作，即便是使用了 DMA 来进行与硬件的通讯，CPU 仍然需要访问数据两次。在 read() 读数据的过程中，数据并不是直接来自于硬盘，而是必须先经过操作系统的文件系统层。在 write() 写数据的过程中，为了和要传输的数据包的大小相吻合，数据必须要先被分割成块，而且还要预先考虑包头，并且要进行数据校验和操作。 不使用sendfile时:使用sendfile:","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"操作系统,kafka,文件存储","slug":"操作系统-kafka-文件存储","permalink":"https://Caden16.github.io/tags/操作系统-kafka-文件存储/"}]},{"title":"对大量的不重复数进行排序(查找)","slug":"对大量的不重复数进行排序(查找)","date":"2017-04-01T00:00:00.000Z","updated":"2017-04-01T08:11:54.469Z","comments":true,"path":"算法/对大量的不重复数进行排序(查找)/","link":"","permalink":"https://Caden16.github.io/算法/对大量的不重复数进行排序(查找)/","excerpt":"","text":"对大量的不重复正整数进行排序,如10亿,可使用bitmap对数据进行压缩,这样每一bit位对应一个数,对给出的数进行一次遍历,把相应的位置1.参考算法之美——位图排序采用bitmap位图算法对大量不重复数据进行线性时间排序编程珠玑 第一章 位图排序算法–存储：位图使用字符数组存储•unsigned char bit[2];•可用字节有两个0、1字节，一个字节中有八位•我们只能表示16个数（0~15）–问题•给出一个数，怎么判断其对应位图的位置–步骤•找到该数对应的字节 +再找到该数对应的位–方法•14对应的字节：14/8 = 1•14对应的位：第14%8位•14是存储在第1个字节上的第6号位•8是存储在第1个字节上的第0号位","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://Caden16.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://Caden16.github.io/tags/算法/"}]},{"title":"linux IO学习","slug":"linux IO学习","date":"2017-03-31T00:00:00.000Z","updated":"2017-04-01T12:33:05.104Z","comments":true,"path":"操作系统/linux IO学习/","link":"","permalink":"https://Caden16.github.io/操作系统/linux IO学习/","excerpt":"","text":"参考Linux IO模式及 select、poll、epoll详解聊聊IO多路复用之select、poll、epoll详解select、poll、epoll之间的区别总结[整理] 用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换参考进程切换从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 I/O 多路复用之select、poll、epoll详解select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 selectselect 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 pollint poll (struct pollfd *fds, unsigned int nfds, int timeout);不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 struct pollfd { int fd; / file descriptor \\/ short events; / requested events to watch \\/ short revents; / returned events witnessed \\/};pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面： 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"},{"name":"网络","slug":"网络","permalink":"https://Caden16.github.io/tags/网络/"},{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/tags/文件存储/"}]},{"title":"python string intern","slug":"python string intern","date":"2017-03-28T00:00:00.000Z","updated":"2017-03-28T08:30:34.606Z","comments":true,"path":"python/python string intern/","link":"","permalink":"https://Caden16.github.io/python/python string intern/","excerpt":"","text":"参考什么是string interning(字符串驻留)以及python中字符串的intern机制Python中的字符串采用了intern机制，会自动intern.Incomputer science, string interning is a method of storing only onecopy of each distinct string value, which must be immutable. Interning strings makes some stringprocessing tasks more time- or space-efficient at the cost of requiring moretime when the string is created or interned. The distinct values are stored ina string intern pool. –引自维基百科也就是说，值相同的字符串对象只会保存一份，是共用的，这也决定了字符串必须是不可变对象。Python中的字符串采用了intern机制，会自动intern123456&gt;&gt;a = &apos;kzc&apos;&gt;&gt;b = &apos;k&apos;+&apos;zc&apos;&gt;&gt;id(a)55704656&gt;&gt;id(b)55704656 可以看到，它们是同一个对象。（Java 中直接赋值的字符串也可用 == 来判断，但是使用 new 实例化的对象则需要使用equals(String s) 来判断)intern机制的好处是，需要值相同的字符串的时候（比如标识符），直接从池里拿来用，避免频繁的创建和销毁，提升效率，节约内存。缺点是，拼接字符串、对字符串修改之类的影响性能。因为是不可变的，所以对字符串修改不是inplace操作，要新建对象。这也是为什么拼接多字符串的时候不建议用+而用join()。join()是先计算出所有字符串的长度，然后一一拷贝，只new一次对象。需要小心的坑，并不是所有的字符串都会采用intern机制。只包含下划线、数字、字母的字符串才会被intern。既然python内置函数intern()能显式对任意字符串进行intern。说明不是实现难度的问题。答案在源码stringobject.h中的注释可以找到，/ … … This is generally restricted tostrings that “looklike” Python identifiers, although the intern() builtincan be used to force interning of any string … … \\/也就是说，只对那些看起来像是python标识符的进行intern。 下面看另外一个坑，例1.12&gt;&gt;&apos;kz&apos;+&apos;c&apos; is &apos;kzc&apos;True 例2.1234&gt;&gt;s1 = &apos;kz&apos;&gt;&gt;s2 = &apos;kzc&apos;&gt;&gt;s1+&apos;c&apos; is &apos;kzc&apos;False 为什么第二个栗子是False,只包含字母啊，不是应该被自动intern的么？这是因为第一个栗子中，’kz’+’c’是在compile time求值的，被替换成了’kzc’.而第二个栗子，s1+’c’是在run-time拼接的，导致没有被自动intern. 参考操作符is的1个诡异问题参考python中的is、==和cmp()比较字符串“is” operator behaves unexpectedly with integers123456789101112&gt;&gt;&gt; a = 256&gt;&gt;&gt; b = 256&gt;&gt;&gt; id(a)9987148&gt;&gt;&gt; id(b)9987148&gt;&gt;&gt; a = 257&gt;&gt;&gt; b = 257&gt;&gt;&gt; id(a)11662816&gt;&gt;&gt; id(b)11662828 原因: This is really hardcoded limit in the current CPython implementationThe interpreter preallocates numbers from 0 to 256. intobject.c的有关这部分的源码：#ifndef NSMALLPOSINTS#define NSMALLPOSINTS 257#endif#ifndef NSMALLNEGINTS#define NSMALLNEGINTS 5#endif#if NSMALLNEGINTS + NSMALLPOSINTS &gt; 0/ References to small integers are saved in this array so that they can be shared. The integers that are saved are those in the range -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).\\/static PyIntObject *small_ints[NSMALLNEGINTS + NSMALLPOSINTS];#endif#ifdef COUNT_ALLOCSint quick_int_allocs, quick_neg_int_allocs;#endif","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"}]},{"title":"malloc vs new","slug":"malloc vs new","date":"2017-03-28T00:00:00.000Z","updated":"2017-03-29T11:39:25.571Z","comments":true,"path":"C/malloc vs new/","link":"","permalink":"https://Caden16.github.io/C/malloc vs new/","excerpt":"","text":"C语言里的malloc和CPP中的new的区别:参考In what cases do I use malloc vs new? new vs malloc() 1) new is an operator, while malloc() is a function. 2) new calls constructors, while malloc() does not. 3) new returns exact data type, while malloc() returns void *. 4) new never returns a NULL (will throw on failure) while malloc() returns NULL &amp;&amp; 4) , new can be instructed to return NULL on failure. char* ptr = new (std::nothrow) char [323232]; 5) Reallocation of memory not handled by new while malloc() can 6) new creates from constructor arguments, while malloc uses size. Unless you are forced to use C, you should never use malloc. Always use new. If you need a big chunk of data just do something like: char *pBuffer = new char[1024];Be careful though this is not correct:12//This is incorrect - may delete only one element, may corrupt the heap, or worse...delete pBuffer; Instead you should do this when deleting an array of data:12//This deletes all items in the arraydelete[] pBuffer; The new keyword is the C++ way of doing it, and it will ensure that your type will have their constructor called. The new keyword is also more type safe whereas malloc is not typesafe at all. The only way I could think that would be beneficial to use malloc would be if you needed to change the size of your buffer of data. The new keyword does not have an analogous way like realloc. The realloc function might be able to extend the size of a chunk of memory for you more efficiently.12int* p_scalar = new int(5);//Does not create 5 elements, but initializes to 5int* p_array = new int[5];//Creates 5 elements 1.new、delete、malloc、free关系delete会调用对象的析构函数,和new对应free只会释放内存，new调用构造函数。malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。对于非内部数据类型的对象而言，光用maloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。","raw":null,"content":null,"categories":[{"name":"C","slug":"C","permalink":"https://Caden16.github.io/categories/C/"}],"tags":[{"name":"C","slug":"C","permalink":"https://Caden16.github.io/tags/C/"},{"name":"C++","slug":"C","permalink":"https://Caden16.github.io/tags/C/"}]},{"title":"linux单文件大小限制","slug":"linux单文件大小限制","date":"2017-03-26T00:00:00.000Z","updated":"2017-04-01T12:33:23.312Z","comments":true,"path":"文件存储/linux单文件大小限制/","link":"","permalink":"https://Caden16.github.io/文件存储/linux单文件大小限制/","excerpt":"","text":"参考刨根问底：ext3/ext4文件系统最大空间及单个文件大小演算法则剖析 ext4ext4 维基百科对于ext3:1)ext3文件系统采用32bit的块地址索引空间；2)在inode条目中，引用一个块空间符号需要4byte的大小；3)对于一个inode来说，设计了12个直接指针索引，一个间接指针索引，一个双间接指针索引，以及一个三间接指针索引注：a.这些规定都是文件系统自身的程序代码所决定的，也就是说这是开发时就设计好的，没有为什么，只有是什么；对于其它文件系统也是一样；b.所谓双间接指针索引和三间接指针索引指的是两级结构和三级结构，相当于linux中的根文件系统目录树一样；ext3文件系统中inode内部结构图：ext4:1).ext4文件系统采用48bit的块地址索引空间；2).在inode条目中，不在是使用指针索引的方式来进行与block的映射，而是采用extent来替代指针；此前在ext3中的15个指针被替换成5个extent，一个extent占用3byte空间；一个extent描述了一组连续的block，当不够用时extent依旧可以采用间接指针的索引，但没有个数限制。 ext3:1).最大支持的文件大小 首先要知道，在linux文件系统，一个block的大小可以为1k,2k,4k，当block的大小为4k时为最大。在linux系统中，每一个文件都要使用一个inode号，因此要想计算出单个文件所支持的最大空间，只要知道inode中能够引用多少个block，而block取最大值4k的时候计算出来的值就是所能支持的单个文件的最大空间。 从上面的硬性规定中可以看出：a.一个inode支持12个直接指针，因此就表示了12个blockb.一个inode支持一个间接指针，也就是一个指针指向了一个block块，将该block块作为指向最终block的直接指针，这里是一个block为4K，指向一个block要占用4byte的空间，因此一个block的间接指针可以指向4K/4byte的block,即2^10c.双间接指针最终则指向：2^102^10=2^20 个blockd.三间接指针最终执行：2^102^10*2^10=2^30 个block 因此最终的block的个数为：12+2^10+2^20+2^30则最终的大小为：(12+2^10+2^20+2^30)x4KByte则换算成TB的大小为：(12+2^10+2^20+2^30)x4KByte/1024/1024/1024=2TB 到此，可知ext3文件系统，在block为4K的时候，其支持的单个文件大小为最大，最大为2TB。 ext4 的一个明显差别就是它支持更大的文件系统、文件和子目录。ext4 支持的最大文件系统为 1 EB（1000 PB）。虽然根据今天的标准这个文件系统已经非常巨大，但存储空间的消费会不断增长，因此 ext4 必须考虑到未来的发展。ext4 支持最大 16 TB 的文件（假设由 4KB 的块组成），这个容量是 ext3 的 8 倍。 ext3的一个目录下最多只能有32000个子目录。ext4的子目录最高可达64000，且使用“dir_nlink”功能后可以达到更高（虽然父目录的link count会停止增加）。为了避免性能受到大量目录的影响，ext4默认打开Htree（一种特殊的B树）索引功能。该功能已经实现于Linux核心2.6.23版。 ext4 的区段采用分层的方法高效地表示小文件，并且使用区段树高效地表示大文件。例如，单个 ext4 inode 有足够的空间来引用 4 个区段（每个区段表示一组相邻的块）。对于大文件（包括片段文件），一个 inode 能够引用一个索引节点，而每个索引节点能够引用一个叶节点（引用多个区段）。这种持续的区段树为大文件（尤其是分散的文件）提供丰富的表示方式。这些节点还包含自主检查机制，以阻止文件系统损坏带来威胁。 ext4性能衡量一个新文件系统的最重要指标就是它的根本性能。这常常是最难实现的指标，因为当文件系统变得庞大并且要求实现高可靠性时，将会以损害性能为代价。但是，ext4 不仅解决了伸缩性和可靠性，它还提供各种改善性能的方法。文件级预分配某些应用程序，比如数据库或内容流，要求将文件存储在相邻的块上（利用相邻块的读优化和最大化读的命令-块比率）。尽管区段能够将相邻块划分为片段，但另一种更强大的方法是按照所需的大小预分配比较大的相邻块（XFS 以前就是采用这种方法）。ext4 通过一个新的系统调用来实现这个目的，这个调用将按照特定的大小预分配并初始化文件。然后，您就可以写入必要的数据，并为数据提供不错的读性能。延迟块分配另一个基于文件大小的优化是延迟分配。这种性能优化延迟磁盘上的物理块的分配，直到块被刷入到磁盘时才进行分配。这种优化的关键是延迟物理块的分配，直到需要在磁盘上写这些物理块时才对其进行分配并写到相邻的块。这类似于持久化预分配，惟一的区别是文件系统会自动执行这项任务。不过如果预先知道文件的大小时，持久化预分配是更好的选择。多个块分配这是最后一个与相邻块相关的优化，即针对 ext4 的块分配器。在 ext3 中，块分配器的工作方式是每次分配一个块。当需要分配多个块时，非相邻块中可能存在相邻的数据。ext4 使用块分配器修复了这个问题，它能够在磁盘上一次分配多个块。与前面其他优化一样，这个优化在磁盘上收集相关的数据，以实现相邻读优化。多个块分配的另一个方面是分配块时需要的处理量。记住，ext3 一次只分配一个块。在最简单的情况下，每个块的分配都要有一个调用。如果一次分配多个块，对块分配器的调用就会大大减少，从而加快分配并减少处理量。 ext4可靠性ext4 文件系统可能会扩展得比较大，这将导致可靠性问题。但 ext4 通过许多自主保护和自主修复机制来解决这个问题。执行文件系统日志校验和和 ext3 一样，ext4 也是一个日志文件系统。日志记录 就是通过日记（磁盘上相邻区域的专门循环记录）记录文件系统的变更的过程。因此，根据日志对物理存储执行实际变更更加可靠，并且能够确保一致性，即使在操作期间出现系统崩溃或电源中断。这样做可以减少文件系统损坏的几率。但是即使进行日志记录，如果日志出现错误仍然会导致文件系统损坏。为了解决这个问题，ext4 对日志执行校验和，确保有效变更能够在底层文件系统上正确完成。ext4 支持根据用户需求采用多种模式的日志记录。例如，ext4 支持 Writeback 模式，它仅记录元数据；或 Ordered 模式，它记录元数据，但写为元数据的数据是从日志中写入的；或 Journal 模式（最可靠的模式），它同时记录元数据和数据。注意，虽然 Journal 模式是确保文件系统一致的最佳选择，但它也是最慢的，因为所有数据都要经过日志。","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"},{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/tags/文件存储/"}]},{"title":"python的多线程和Goroutine","slug":"python的多线程和Goroutine","date":"2017-03-22T00:00:00.000Z","updated":"2017-03-22T14:13:00.610Z","comments":true,"path":"操作系统/python的多线程和Goroutine/","link":"","permalink":"https://Caden16.github.io/操作系统/python的多线程和Goroutine/","excerpt":"","text":"python多线程参考Python的GIL是什么鬼，多线程性能究竟如何GIL全称Global Interpreter Lock,一个防止多线程并发执行机器码的一个Mutex In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.) 基于pcode数量的调度方式 按照Python社区的想法，操作系统本身的线程调度已经非常成熟稳定了，没有必要自己搞一套。所以Python的线程就是C语言的一个pthread，并通过操作系统调度算法进行调度（例如linux是CFS）。为了让各个线程能够平均利用CPU时间，python会计算当前已执行的微代码数量，达到一定阈值后就强制释放GIL。而这时也会触发一次操作系统的线程调度（当然是否真正进行上下文切换由操作系统自主决定）。 伪代码123456while True: acquire GIL for i in 1000: do something release GIL /* Give Operating System a chance to do thread scheduling */ 这种模式在只有一个CPU核心的情况下毫无问题。任何一个线程被唤起时都能成功获得到GIL（因为只有释放了GIL才会引发线程调度）。但当CPU有多个核心的时候，问题就来了。从伪代码可以看到，从release GIL到acquire GIL之间几乎是没有间隙的。所以当其他在其他核心上的线程被唤醒时，大部分情况下主线程已经又再一次获取到GIL了。这个时候被唤醒执行的线程只能白白的浪费CPU时间，看着另一个线程拿着GIL欢快的执行着。然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环。GIL的存在导致多线程无法很好的立即多核CPU的并发处理能力。简单的总结下就是：Python的多线程在多核CPU上，只对于IO密集型计算产生正面效果；而当有至少有一个CPU密集型线程存在，那么多线程效率会由于GIL而大幅下降。如何避免受到GIL的影响:用multiprocessing替代Thread multiprocessing库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。 当然multiprocessing也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。就拿计数器来举例子，如果我们要多个线程累加同一个变量，对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocessing由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，put再get或者用share memory的方法。这个额外的实现成本使得本来就非常痛苦的多线程程序编码，变得更加痛苦了。 go 并发 goroutine参考goroutine背后的系统知识理解GoroutineJava里的Thread使用的是线程模型的一对一模型，每一个用户线程都对应着一个内核级线程。上图有两个CPU，然后有4个Java thread，每个Java thread其实就是一个内核级线程，由内核级线程调度器进行调度，轮流使用两个CPU。内核级线程调度器具有绝对的权力，所以把它放到了下面。内核级线程调度器使用公平的算法让四个线程使用两个CPU。 Go的Goroutine是用户级的线程。同样是4个Goroutine，可能只对应了两个内核级线程。Goroutine调度器把4个Goroutine分配到两个内核级线程上，而这两个内核级线程对CPU的使用由内核线程调度器来分配。Goroutine，在启动的内核级线程个数一定情况下（通常与CPU个数相等），那么最先启动的Goroutine会一直占据CPU，其它的Goroutine会starve，饿死.为了避免这种情况,需要协程(coroutine)Goroutine与Coroutine不一样，开发者并不需要关心Goroutine如何被调起，如何放弃控制权，而是交给Goroutine调度器来管理。开发者不用关心，但是Go语言的编译器会替你把工作做了，因为Goroutine必须主动交出控制权才能由调度器统一管理。 Go语言通过goroutine提供了目前为止所有(我所了解的)语言里对于并发编程的最清晰最直接的支持，Go语言的文档里对其特性也描述的非常全面甚至超过了，在这里，基于我们上面的系统知识介绍，列举一下goroutine的特性，算是小结： goroutine是Go语言运行库的功能，不是操作系统提供的功能，goroutine不是用线程实现的。具体可参见Go语言源码里的pkg/runtime/proc.c goroutine就是一段代码，一个函数入口，以及在堆上为其分配的一个堆栈。所以它非常廉价，我们可以很轻松的创建上万个goroutine，但它们并不是被操作系统所调度执行 除了被系统调用阻塞的线程外，Go运行库最多会启动$GOMAXPROCS个线程来运行goroutine goroutine是协作式调度的，如果goroutine会执行很长时间，而且不是通过等待读取或写入channel的数据来同步的话，就需要主动调用Gosched()来让出CPU 和所有其他并发框架里的协程一样，goroutine里所谓“无锁”的优点只在单线程下有效，如果$GOMAXPROCS &gt; 1并且协程间需要通信，Go运行库会负责加锁保护数据，这也是为什么sieve.go这样的例子在多CPU多线程时反而更慢的原因 Web等服务端程序要处理的请求从本质上来讲是并行处理的问题，每个请求基本独立，互不依赖，几乎没有数据交互，这不是一个并发编程的模型，而并发编程框架只是解决了其语义表述的复杂性，并不是从根本上提高处理的效率，也许是并发连接和并发编程的英文都是concurrent吧，很容易产生“并发编程框架和coroutine可以高效处理大量并发连接”的误解。 Go语言运行库封装了异步IO，所以可以写出貌似并发数很多的服务端，可即使我们通过调整$GOMAXPROCS来充分利用多核CPU并行处理，其效率也不如我们利用IO事件驱动设计的、按照事务类型划分好合适比例的线程池。在响应时间上，协作式调度是硬伤。 goroutine最大的价值是其实现了并发协程和实际并行执行的线程的映射以及动态扩展，随着其运行库的不断发展和完善，其性能一定会越来越好，尤其是在CPU核数越来越多的未来，终有一天我们会为了代码的简洁和可维护性而放弃那一点点性能的差别。","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"},{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"}]},{"title":"linux页缓存机制 Page Cache","slug":"linux页缓存机制 Page Cache","date":"2017-03-20T00:00:00.000Z","updated":"2017-03-25T16:06:05.768Z","comments":true,"path":"操作系统/linux页缓存机制 Page Cache/","link":"","permalink":"https://Caden16.github.io/操作系统/linux页缓存机制 Page Cache/","excerpt":"参考Linux 内核的文件 Cache 管理机制介绍Linux Page Cache机制在 Linux 中，具体文件系统，如 ext2/ext3、jfs、ntfs 等，负责在文件 Cache和存储设备之间交换 数据，位于具体文件系统之上的虚拟文件系统VFS负责在应用程序和文件 Cache 之间通过 read/write 等接口交换 数 据，而内存管理系统负责文件 Cache 的分配和回收，同时虚拟内存管理系统(VMM)则允许应用程序和文件 Cache 之间通过 memory map的方式交换数据。可见，在 Linux 系统中，文件 Cache 是内存管理系统、文件系统以及应用程序之间的一个联系枢纽。","text":"参考Linux 内核的文件 Cache 管理机制介绍Linux Page Cache机制在 Linux 中，具体文件系统，如 ext2/ext3、jfs、ntfs 等，负责在文件 Cache和存储设备之间交换 数据，位于具体文件系统之上的虚拟文件系统VFS负责在应用程序和文件 Cache 之间通过 read/write 等接口交换 数 据，而内存管理系统负责文件 Cache 的分配和回收，同时虚拟内存管理系统(VMM)则允许应用程序和文件 Cache 之间通过 memory map的方式交换数据。可见，在 Linux 系统中，文件 Cache 是内存管理系统、文件系统以及应用程序之间的一个联系枢纽。文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。内存管理系统和 VFS 只与 Page Cache 交互，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射；VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据。 在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache 项，一个是 radix tree，另一个是双向链表。 Linux内核中文件预读算法的具体过程是这样的：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面(不少于一个页面，通常是三个页面)，这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的group中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读group扩大一倍，并让底层文件系统读入group中剩下尚不在Cache中的文件数据块，这时的预读称为异步预读。无论第二次读请求是否命中，系统都要更新当前预读group的大小。此外，系统中定义了一个window，它包括前一次预读的group和本次预读的group。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读window中，这时继续进行异步预读并更新相应的window和group；第二种情况是所请求的页面处于预读window之外，这时系统就要进行同步预读并重置相应的window和group。 Linux内核中与文件Cache操作相关的API有很多，按其使用方式可以分成两类：一类是以拷贝方式操作的相关接口， 如read/write/sendfile等，其中sendfile在2.6系列的内核中已经不再支持；另一类是以地址映射方式操作的相关接口，如mmap等。第二种类型的API将Cache项映射到用户空间，使得应用程序可以像使用内存指针一样访问文件，Memory map访问Cache的方式在内核中是采用请求页面机制实现的首先，应用程序调用mmap（图中1），陷入到内核中后调用do_mmap_pgoff（图中2）。该函数从应用程序的地址空间中分配一段区域作为映射的内存地址，并使用一个VMA（vm_area_struct）结构代表该区域，之后就返回到应用程序（图中3）。当应用程序访问mmap所返回的地址指针时（图中4），由于虚实映射尚未建立，会触发缺页中断（图中5）。之后系统会调用缺页中断处理函数（图中6），在缺页中断处理函数中，内核通过相应区域的VMA结构判断出该区域属于文件映射，于是调用具体文件系统的接口读入相应的Page Cache项（图中7、8、9），并填写相应的虚实映射表。经过这些步骤之后，应用程序就可以正常访问相应的内存区域了。","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"},{"name":"linux","slug":"linux","permalink":"https://Caden16.github.io/tags/linux/"}]},{"title":"(转)Leveldb实现原理","slug":"(转)Leveldb实现原理","date":"2017-03-19T00:00:00.000Z","updated":"2017-03-19T11:47:17.060Z","comments":true,"path":"Leveldb/(转)Leveldb实现原理/","link":"","permalink":"https://Caden16.github.io/Leveldb/(转)Leveldb实现原理/","excerpt":"","text":"本文转自数据分析与处理之二（Leveldb 实现原理）郑重声明：本篇博客是自己学习 Leveldb 实现原理时参考了郎格科技系列博客整理的，原文地址：http://www.samecity.com/blog/Index.asp?SortID=12, 只是为了加深印象，本文的配图是自己重新绘制的，大部分内容与原文相似，大家可以浏览原始页面 :-)，感兴趣的话可以一起讨论 Leveldb 的实现原理！ LevelDb日知录之一：LevelDb 101 说起LevelDb也许您不清楚，但是如果作为IT工程师，不知道下面两位大神级别的工程师，那您的领导估计会Hold不住了：Jeff Dean和Sanjay Ghemawat。这两位是Google公司重量级的工程师，为数甚少的Google Fellow之二。 Jeff Dean其人：http://research.google.com/people/jeff/index.html, Google大规模分布式平台Bigtable和MapReduce主要设计和实现者。 Sanjay Ghemawat其人：http://research.google.com/people/sanjay/index.html, Google大规模分布式平台GFS，Bigtable和MapReduce主要设计和实现工程师。 LevelDb就是这两位大神级别的工程师发起的开源项目，简而言之，LevelDb是能够处理十亿级别规模Key-Value型数据持久性存储的C++ 程序库。正像上面介绍的，这二位是Bigtable的设计和实现者，如果了解Bigtable的话，应该知道在这个影响深远的分布式存储系统中有两个核心的部分：Master Server和Tablet Server。其中Master Server做一些管理数据的存储以及分布式调度工作，实际的分布式数据存储以及读写操作是由Tablet Server完成的，而LevelDb则可以理解为一个简化版的Tablet Server。 LevelDb有如下一些特点： 首先，LevelDb是一个持久化存储的KV系统，和Redis这种内存型的KV系统不同，LevelDb不会像Redis一样狂吃内存，而是将大部分数据存储到磁盘上。 其次，LevleDb在存储数据时，是根据记录的key值有序存储的，就是说相邻的key值在存储文件中是依次顺序存储的，而应用可以自定义key大小比较函数，LevleDb会按照用户定义的比较函数依序存储这些记录。 再次，像大多数KV系统一样，LevelDb的操作接口很简单，基本操作包括写记录，读记录以及删除记录。也支持针对多条操作的原子批量操作。 另外，LevelDb支持数据快照（snapshot）功能，使得读取操作不受写操作影响，可以在读操作过程中始终看到一致的数据。 除此外，LevelDb还支持数据压缩等操作，这对于减小存储空间以及增快IO效率都有直接的帮助。 LevelDb性能非常突出，官方网站报道其随机写性能达到40万条记录每秒，而随机读性能达到6万条记录每秒。总体来说，LevelDb的写操作要大大快于读操作，而顺序读写操作则大大快于随机读写操作。至于为何是这样，看了我们后续推出的LevelDb日知录，估计您会了解其内在原因。 LevelDb日知录之二：整体架构 LevelDb本质上是一套存储系统以及在这套存储系统上提供的一些操作接口。为了便于理解整个系统及其处理流程，我们可以从两个不同的角度来看待LevleDb：静态角度和动态角度。从静态角度，可以假想整个系统正在运行过程中（不断插入删除读取数据），此时我们给LevelDb照相，从照片可以看到之前系统的数据在内存和磁盘中是如何分布的，处于什么状态等；从动态的角度，主要是了解系统是如何写入一条记录，读出一条记录，删除一条记录的，同时也包括除了这些接口操作外的内部操作比如compaction，系统运行时崩溃后如何恢复系统等等方面。 本节所讲的整体架构主要从静态角度来描述，之后接下来的几节内容会详述静态结构涉及到的文件或者内存数据结构，LevelDb日知录后半部分主要介绍动态视角下的LevelDb，就是说整个系统是怎么运转起来的。 LevelDb作为存储系统，数据记录的存储介质包括内存以及磁盘文件，如果像上面说的，当LevelDb运行了一段时间，此时我们给LevelDb进行透视拍照，那么您会看到如下一番景象： 图1.1：LevelDb结构 从图中可以看出，构成LevelDb静态结构的包括六个主要部分：内存中的MemTable和Immutable MemTable以及磁盘上的几种主要文件：Current文件，Manifest文件，log文件以及SSTable文件。当然，LevelDb除了这六个主要部分还有一些辅助的文件，但是以上六个文件和数据结构是LevelDb的主体构成元素。 LevelDb的Log文件和Memtable与Bigtable论文中介绍的是一致的，当应用写入一条Key:Value记录的时候，LevelDb会先往log文件里写入，成功后将记录插进Memtable中，这样基本就算完成了写入操作，因为一次写入操作只涉及一次磁盘顺序写和一次内存写入，所以这是为何说LevelDb写入速度极快的主要原因。 Log文件在系统中的作用主要是用于系统崩溃恢复而不丢失数据，假如没有Log文件，因为写入的记录刚开始是保存在内存中的，此时如果系统崩溃，内存中的数据还没有来得及Dump到磁盘，所以会丢失数据（Redis就存在这个问题）。为了避免这种情况，LevelDb在写入内存前先将操作记录到Log文件中，然后再记入内存中，这样即使系统崩溃，也可以从Log文件中恢复内存中的Memtable，不会造成数据的丢失。 当Memtable插入的数据占用内存到了一个界限后，需要将内存的记录导出到外存文件中，LevleDb会生成新的Log文件和Memtable，原先的Memtable就成为Immutable Memtable，顾名思义，就是说这个Memtable的内容是不可更改的，只能读不能写入或者删除。新到来的数据被记入新的Log文件和Memtable，LevelDb后台调度会将Immutable Memtable的数据导出到磁盘，形成一个新的SSTable文件。SSTable就是由内存中的数据不断导出并进行Compaction操作后形成的，而且SSTable的所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，依次类推，层级逐渐增高，这也是为何称之为LevelDb的原因。 SSTable中的文件是Key有序的，就是说在文件中小key记录排在大Key记录之前，各个Level的SSTable都是如此，但是这里需要注意的一点是：Level 0的SSTable文件（后缀为.sst）和其它Level的文件相比有特殊性：这个层级内的.sst文件，两个文件可能存在key重叠，比如有两个level 0的sst文件，文件A和文件B，文件A的key范围是：{bar, car}，文件B的Key范围是{blue,samecity}，那么很可能两个文件都存在key=”blood”的记录。对于其它Level的SSTable文件来说，则不会出现同一层级内.sst文件的key重叠现象，就是说Level L中任意两个.sst文件，那么可以保证它们的key值是不会重叠的。这点需要特别注意，后面您会看到很多操作的差异都是由于这个原因造成的。 SSTable中的某个文件属于特定层级，而且其存储的记录是key有序的，那么必然有文件中的最小key和最大key，这是非常重要的信息，LevelDb应该记下这些信息。Manifest就是干这个的，它记载了SSTable各个文件的管理信息，比如属于哪个Level，文件名称叫啥，最小key和最大key各自是多少。下图是Manifest所存储内容的示意： 图2.1：Manifest存储示意图 图中只显示了两个文件（manifest会记载所有SSTable文件的这些信息），即Level 0的test.sst1和test.sst2文件，同时记载了这些文件各自对应的key范围，比如test.sstt1的key范围是“an”到 “banana”，而文件test.sst2的key范围是“baby”到“samecity”，可以看出两者的key范围是有重叠的。 Current文件是干什么的呢？这个文件的内容只有一个信息，就是记载当前的manifest文件名。因为在LevleDb的运行过程中，随着Compaction的进行，SSTable文件会发生变化，会有新的文件产生，老的文件被废弃，Manifest也会跟着反映这种变化，此时往往会新生成Manifest文件来记载这种变化，而Current则用来指出哪个Manifest文件才是我们关心的那个Manifest文件。 以上介绍的内容就构成了LevelDb的整体静态结构，在LevelDb日知录接下来的内容中，我们会首先介绍重要文件或者内存数据的具体数据布局与结构。 LevelDb日知录之三：log文件上节内容讲到log文件在LevelDb中的主要作用是系统故障恢复时，能够保证不会丢失数据。因为在将记录写入内存的Memtable之前，会先写入Log文件，这样即使系统发生故障，Memtable中的数据没有来得及Dump到磁盘的SSTable文件，LevelDB也可以根据log文件恢复内存的Memtable数据结构内容，不会造成系统丢失数据，在这点上LevelDb和Bigtable是一致的。 下面我们带大家看看log文件的具体物理和逻辑布局是怎样的，LevelDb对于一个log文件，会把它切割成以32K为单位的物理Block，每次读取的单位以一个Block作为基本读取单位，下图展示的log文件由3个Block构成，所以从物理布局来讲，一个log文件就是由连续的32K大小Block构成的。 图3.1 log文件布局在应用的视野里是看不到这些Block的，应用看到的是一系列的Key:Value对，在LevelDb内部，会将一个Key:Value对看做一条记录的数据，另外在这个数据前增加一个记录头，用来记载一些管理信息，以方便内部处理，图3.2显示了一个记录在LevelDb内部是如何表示的。 图3.2 记录结构记录头包含三个字段，ChechSum是对“类型”和“数据”字段的校验码，为了避免处理不完整或者是被破坏的数据，当LevelDb读取记录数据时候会对数据进行校验，如果发现和存储的CheckSum相同，说明数据完整无破坏，可以继续后续流程。“记录长度”记载了数据的大小，“数据”则是上面讲的Key:Value数值对，“类型”字段则指出了每条记录的逻辑结构和log文件物理分块结构之间的关系，具体而言，主要有以下四种类型：FULL/FIRST/MIDDLE/LAST。 如果记录类型是FULL，代表了当前记录内容完整地存储在一个物理Block里，没有被不同的物理Block切割开；如果记录被相邻的物理Block切割开，则类型会是其他三种类型中的一种。我们以图3.1所示的例子来具体说明。 假设目前存在三条记录，Record A，Record B和Record C，其中Record A大小为10K，Record B 大小为80K，Record C大小为12K，那么其在log文件中的逻辑布局会如图3.1所示。Record A是图中蓝色区域所示，因为大小为10K&lt;32K，能够放在一个物理Block中，所以其类型为FULL；Record B 大小为80K，而Block 1因为放入了Record A，所以还剩下22K，不足以放下Record B，所以在Block 1的剩余部分放入Record B的开头一部分，类型标识为FIRST，代表了是一个记录的起始部分；Record B还有58K没有存储，这些只能依次放在后续的物理Block里面，因为Block 2大小只有32K，仍然放不下Record B的剩余部分，所以Block 2全部用来放Record B，且标识类型为MIDDLE，意思是这是Record B中间一段数据；Record B剩下的部分可以完全放在Block 3中，类型标识为LAST，代表了这是Record B的末尾数据；图中黄色的Record C因为大小为12K，Block 3剩下的空间足以全部放下它，所以其类型标识为FULL。 从这个小例子可以看出逻辑记录和物理Block之间的关系，LevelDb一次物理读取为一个Block，然后根据类型情况拼接出逻辑记录，供后续流程处理。 LevelDb日知录之四：SSTable文件SSTable是Bigtable中至关重要的一块，对于LevelDb来说也是如此，对LevelDb的SSTable实现细节的了解也有助于了解Bigtable中一些实现细节。 本节内容主要讲述SSTable的静态布局结构，我们曾在“LevelDb日知录之二：整体架构”中说过，SSTable文件形成了不同Level的层级结构，至于这个层级结构是如何形成的我们放在后面Compaction一节细说。本节主要介绍SSTable某个文件的物理布局和逻辑布局结构，这对了解LevelDb的运行过程很有帮助。 LevelDb不同层级有很多SSTable文件（以后缀.sst为特征），所有.sst文件内部布局都是一样的。上节介绍Log文件是物理分块的，SSTable也一样会将文件划分为固定大小的物理存储块，但是两者逻辑布局大不相同，根本原因是：Log文件中的记录是Key无序的，即先后记录的key大小没有明确大小关系，而.sst文件内部则是根据记录的Key由小到大排列的，从下面介绍的SSTable布局可以体会到Key有序是为何如此设计.sst文件结构的关键。 图4.1 .sst文件的分块结构图4.1展示了一个.sst文件的物理划分结构，同Log文件一样，也是划分为固定大小的存储块，每个Block分为三个部分，红色部分是数据存储区， 蓝色的Type区用于标识数据存储区是否采用了数据压缩算法（Snappy压缩或者无压缩两种），CRC部分则是数据校验码，用于判别数据是否在生成和传输中出错。 以上是.sst的物理布局，下面介绍.sst文件的逻辑布局，所谓逻辑布局，就是说尽管大家都是物理块，但是每一块存储什么内容，内部又有什么结构等。图4.2展示了.sst文件的内部逻辑解释。 图4.2 逻辑布局从图4.2可以看出，从大的方面，可以将.sst文件划分为数据存储区和数据管理区，数据存储区存放实际的Key:Value数据，数据管理区则提供一些索引指针等管理数据，目的是更快速便捷的查找相应的记录。两个区域都是在上述的分块基础上的，就是说文件的前面若干块实际存储KV数据，后面数据管理区存储管理数据。管理数据又分为四种不同类型：紫色的Meta Block，红色的MetaBlock 索引和蓝色的数据索引块以及一个文件尾部块。 LevelDb 1.2版对于Meta Block尚无实际使用，只是保留了一个接口，估计会在后续版本中加入内容，下面我们看看数据索引区和文件尾部Footer的内部结构。 图4.3 数据索引图4.3是数据索引的内部结构示意图。再次强调一下，Data Block内的KV记录是按照Key由小到大排列的，数据索引区的每条记录是对某个Data Block建立的索引信息，每条索引信息包含三个内容，以图4.3所示的数据块i的索引Index i来说：红色部分的第一个字段记载大于等于数据块i中最大的Key值的那个Key，第二个字段指出数据块i在.sst文件中的起始位置，第三个字段指出Data Block i的大小（有时候是有数据压缩的）。后面两个字段好理解，是用于定位数据块在文件中的位置的，第一个字段需要详细解释一下，在索引里保存的这个Key值未必一定是某条记录的Key,以图4.3的例子来说，假设数据块i 的最小Key=“samecity”，最大Key=“the best”;数据块i+1的最小Key=“the fox”,最大Key=“zoo”,那么对于数据块i的索引Index i来说，其第一个字段记载大于等于数据块i的最大Key(“the best”)同时要小于数据块i+1的最小Key(“the fox”)，所以例子中Index i的第一个字段是：“the c”，这个是满足要求的；而Index i+1的第一个字段则是“zoo”，即数据块i+1的最大Key。 文件末尾Footer块的内部结构见图4.4，metaindex_handle指出了metaindex block的起始位置和大小；inex_handle指出了index Block的起始地址和大小；这两个字段可以理解为索引的索引，是为了正确读出索引值而设立的，后面跟着一个填充区和魔数。 图4.4 Footer上面主要介绍的是数据管理区的内部结构，下面我们看看数据区的一个Block的数据部分内部是如何布局的（图4.1中的红色部分），图4.5是其内部布局示意图。 图4.5 数据Block内部结构从图中可以看出，其内部也分为两个部分，前面是一个个KV记录，其顺序是根据Key值由小到大排列的，在Block尾部则是一些“重启点”（Restart Point）,其实是一些指针，指出Block内容中的一些记录位置。 “重启点”是干什么的呢？我们一再强调，Block内容里的KV记录是按照Key大小有序的，这样的话，相邻的两条记录很可能Key部分存在重叠，比如key i=“the Car”，Key i+1=“the color”,那么两者存在重叠部分“the c”，为了减少Key的存储量，Key i+1可以只存储和上一条Key不同的部分“olor”，两者的共同部分从Key i中可以获得。记录的Key在Block内容部分就是这么存储的，主要目的是减少存储开销。“重启点”的意思是：在这条记录开始，不再采取只记载不同的Key部分，而是重新记录所有的Key值，假设Key i+1是一个重启点，那么Key里面会完整存储“the color”，而不是采用简略的“olor”方式。Block尾部就是指出哪些记录是这些重启点的。 图4.6 记录格式在Block内容区，每个KV记录的内部结构是怎样的？图4.6给出了其详细结构，每个记录包含5个字段：key共享长度，比如上面的“olor”记录， 其key和上一条记录共享的Key部分长度是“the c”的长度，即5；key非共享长度，对于“olor”来说，是4；value长度指出Key:Value中Value的长度，在后面的Value内容字段中存储实际的Value值；而key非共享内容则实际存储“olor”这个Key字符串。 上面讲的这些就是.sst文件的全部内部奥秘。 LevelDb日知录之五：MemTable详解LevelDb日知录前述小节大致讲述了磁盘文件相关的重要静态结构，本小节讲述内存中的数据结构Memtable，Memtable在整个体系中的重要地位也不言而喻。总体而言，所有KV数据都是存储在Memtable，Immutable Memtable和SSTable中的，Immutable Memtable从结构上讲和Memtable是完全一样的，区别仅仅在于其是只读的，不允许写入操作，而Memtable则是允许写入和读取的。当Memtable写入的数据占用内存到达指定数量，则自动转换为Immutable Memtable，等待Dump到磁盘中，系统会自动生成新的Memtable供写操作写入新数据，理解了Memtable，那么Immutable Memtable自然不在话下。 LevelDb的MemTable提供了将KV数据写入，删除以及读取KV记录的操作接口，但是事实上Memtable并不存在真正的删除操作,删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作是Lazy的，会在以后的Compaction过程中去掉这个KV。 需要注意的是，LevelDb的Memtable中KV对是根据Key大小有序存储的，在系统插入新的KV时，LevelDb要把这个KV插到合适的位置上以保持这种Key有序性。其实，LevelDb的Memtable类只是一个接口类，真正的操作是通过背后的SkipList来做的，包括插入操作和读取操作等，所以Memtable的核心数据结构是一个SkipList。 SkipList是由William Pugh发明。他在Communications of the ACM June 1990, 33(6) 668-676 发表了Skip lists: a probabilistic alternative to balanced trees，在该论文中详细解释了SkipList的数据结构和插入删除操作。 SkipList是平衡树的一种替代数据结构，但是和红黑树不相同的是，SkipList对于树的平衡的实现是基于一种随机化的算法的，这样也就是说SkipList的插入和删除的工作是比较简单的。 关于SkipList的详细介绍可以参考这篇文章：http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html, 讲述的很清楚，LevelDb的SkipList基本上是一个具体实现，并无特殊之处。 SkipList不仅是维护有序数据的一个简单实现，而且相比较平衡树来说，在插入数据的时候可以避免频繁的树节点调整操作，所以写入效率是很高的，LevelDb整体而言是个高写入系统，SkipList在其中应该也起到了很重要的作用。Redis为了加快插入操作，也使用了SkipList来作为内部实现数据结构。 LevelDb日知录之六 写入与删除记录在之前的五节LevelDb日知录中，我们介绍了LevelDb的一些静态文件及其详细布局，从本节开始，我们看看LevelDb的一些动态操作，比如读写记录，Compaction，错误恢复等操作。 本节介绍levelDb的记录更新操作，即插入一条KV记录或者删除一条KV记录。levelDb的更新操作速度是非常快的，源于其内部机制决定了这种更新操作的简单性。 图6.1 LevelDb写入记录 图6.1是levelDb如何更新KV数据的示意图，从图中可以看出，对于一个插入操作Put(Key,Value)来说，完成插入操作包含两个具体步骤：首先是将这条KV记录以顺序写的方式追加到之前介绍过的log文件末尾，因为尽管这是一个磁盘读写操作，但是文件的顺序追加写入效率是很高的，所以并不会导致写入速度的降低；第二个步骤是:如果写入log文件成功，那么将这条KV记录插入内存中的Memtable中，前面介绍过，Memtable只是一层封装，其内部其实是一个Key有序的SkipList列表，插入一条新记录的过程也很简单，即先查找合适的插入位置，然后修改相应的链接指针将新记录插入即可。完成这一步，写入记录就算完成了，所以一个插入记录操作涉及一次磁盘文件追加写和内存SkipList插入操作，这是为何levelDb写入速度如此高效的根本原因。 从上面的介绍过程中也可以看出：log文件内是key无序的，而Memtable中是key有序的。那么如果是删除一条KV记录呢？对于levelDb来说，并不存在立即删除的操作，而是与插入操作相同的，区别是，插入操作插入的是Key:Value 值，而删除操作插入的是“Key:删除标记”，并不真正去删除记录，而是后台Compaction的时候才去做真正的删除操作。 levelDb的写入操作就是如此简单。真正的麻烦在后面将要介绍的读取操作中。 LevelDb日知录之七：读取记录LevelDb是针对大规模Key/Value数据的单机存储库，从应用的角度来看，LevelDb就是一个存储工具。而作为称职的存储工具，常见的调用接口无非是新增KV，删除KV，读取KV，更新Key对应的Value值这么几种操作。LevelDb的接口没有直接支持更新操作的接口，如果需要更新某个Key的Value,你可以选择直接生猛地插入新的KV，保持Key相同，这样系统内的key对应的value就会被更新；或者你可以先删除旧的KV， 之后再插入新的KV，这样比较委婉地完成KV的更新操作。 假设应用提交一个Key值，下面我们看看LevelDb是如何从存储的数据中读出其对应的Value值的。图7-1是LevelDb读取过程的整体示意图。 图7-1 LevelDb读取记录流程LevelDb首先会去查看内存中的Memtable，如果Memtable中包含key及其对应的value，则返回value值即可；如果在Memtable没有读到key，则接下来到同样处于内存中的Immutable Memtable中去读取，类似地，如果读到就返回，若是没有读到,那么只能万般无奈下从磁盘中的大量SSTable文件中查找。因为SSTable数量较多，而且分成多个Level，所以在SSTable中读数据是相当蜿蜒曲折的一段旅程。总的读取原则是这样的：首先从属于level 0的文件中查找，如果找到则返回对应的value值，如果没有找到那么到level 1中的文件中去找，如此循环往复，直到在某层SSTable文件中找到这个key对应的value为止（或者查到最高level，查找失败，说明整个系统中不存在这个Key)。 那么为什么是从Memtable到Immutable Memtable，再从Immutable Memtable到文件，而文件中为何是从低level到高level这么一个查询路径呢？道理何在？之所以选择这么个查询路径，是因为从信息的更新时间来说，很明显Memtable存储的是最新鲜的KV对；Immutable Memtable中存储的KV数据对的新鲜程度次之；而所有SSTable文件中的KV数据新鲜程度一定不如内存中的Memtable和Immutable Memtable的。对于SSTable文件来说，如果同时在level L和Level L+1找到同一个key，level L的信息一定比level L+1的要新。也就是说，上面列出的查找路径就是按照数据新鲜程度排列出来的，越新鲜的越先查找。 为啥要优先查找新鲜的数据呢？这个道理不言而喻，举个例子。比如我们先往levelDb里面插入一条数据 {key=”www.samecity.com” value=”我们”},过了几天，samecity网站改名为：69同城，此时我们插入数据{key=”www.samecity.com” value=”69同城”}，同样的key,不同的value；逻辑上理解好像levelDb中只有一个存储记录，即第二个记录，但是在levelDb中很可能存在两条记录，即上面的两个记录都在levelDb中存储了，此时如果用户查询key=”www.samecity.com”,我们当然希望找到最新的更新记录，也就是第二个记录返回，这就是为何要优先查找新鲜数据的原因。 前文有讲：对于SSTable文件来说，如果同时在level L和Level L+1找到同一个key，level L的信息一定比level L+1的要新。这是一个结论，理论上需要一个证明过程，否则会招致如下的问题：为神马呢？从道理上讲呢，很明白：因为Level L+1的数据不是从石头缝里蹦出来的，也不是做梦梦到的，那它是从哪里来的？Level L+1的数据是从Level L 经过Compaction后得到的（如果您不知道什么是Compaction，那么……..也许以后会知道的），也就是说，您看到的现在的Level L+1层的SSTable数据是从原来的Level L中来的，现在的Level L比原来的Level L数据要新鲜，所以可证，现在的Level L比现在的Level L+1的数据要新鲜。 SSTable文件很多，如何快速地找到key对应的value值？在LevelDb中，level 0一直都爱搞特殊化，在level 0和其它level中查找某个key的过程是不一样的。因为level 0下的不同文件可能key的范围有重叠，某个要查询的key有可能多个文件都包含，这样的话LevelDb的策略是先找出level 0中哪些文件包含这个key（manifest文件中记载了level和对应的文件及文件里key的范围信息，LevelDb在内存中保留这种映射表）， 之后按照文件的新鲜程度排序，新的文件排在前面，之后依次查找，读出key对应的value。而如果是非level 0的话，因为这个level的文件之间key是不重叠的，所以只从一个文件就可以找到key对应的value。 最后一个问题,如果给定一个要查询的key和某个key range包含这个key的SSTable文件，那么levelDb是如何进行具体查找过程的呢？levelDb一般会先在内存中的Cache中查找是否包含这个文件的缓存记录，如果包含，则从缓存中读取；如果不包含，则打开SSTable文件，同时将这个文件的索引部分加载到内存中并放入Cache中。 这样Cache里面就有了这个SSTable的缓存项，但是只有索引部分在内存中，之后levelDb根据索引可以定位到哪个内容Block会包含这条key，从文件中读出这个Block的内容，在根据记录一一比较，如果找到则返回结果，如果没有找到，那么说明这个level的SSTable文件并不包含这个key，所以到下一级别的SSTable中去查找。 从之前介绍的LevelDb的写操作和这里介绍的读操作可以看出，相对写操作，读操作处理起来要复杂很多，所以写的速度必然要远远高于读数据的速度，也就是说，LevelDb比较适合写操作多于读操作的应用场合。而如果应用是很多读操作类型的，那么顺序读取效率会比较高，因为这样大部分内容都会在缓存中找到，尽可能避免大量的随机读取操作。 LevelDb日知录之八：Compaction操作前文有述，对于LevelDb来说，写入记录操作很简单，删除记录仅仅写入一个删除标记就算完事，但是读取记录比较复杂，需要在内存以及各个层级文件中依照新鲜程度依次查找，代价很高。为了加快读取速度，levelDb采取了compaction的方式来对已有的记录进行整理压缩，通过这种方式，来删除掉一些不再有效的KV数据，减小数据规模，减少文件数量等。 levelDb的compaction机制和过程与Bigtable所讲述的是基本一致的，Bigtable中讲到三种类型的compaction: minor ，major和full。所谓minor Compaction，就是把memtable中的数据导出到SSTable文件中；major compaction就是合并不同层级的SSTable文件，而full compaction就是将所有SSTable进行合并。 LevelDb包含其中两种，minor和major。 我们将为大家详细叙述其机理。 先来看看minor Compaction的过程。Minor compaction 的目的是当内存中的memtable大小到了一定值时，将内容保存到磁盘文件中，图8.1是其机理示意图。 图8.1 minor compaction从8.1可以看出，当memtable数量到了一定程度会转换为immutable memtable，此时不能往其中写入记录，只能从中读取KV内容。之前介绍过，immutable memtable其实是一个多层级队列SkipList，其中的记录是根据key有序排列的。所以这个minor compaction实现起来也很简单，就是按照immutable memtable中记录由小到大遍历，并依次写入一个level 0 的新建SSTable文件中，写完后建立文件的index 数据，这样就完成了一次minor compaction。从图中也可以看出，对于被删除的记录，在minor compaction过程中并不真正删除这个记录，原因也很简单，这里只知道要删掉key记录，但是这个KV数据在哪里?那需要复杂的查找，所以在minor compaction的时候并不做删除，只是将这个key作为一个记录写入文件中，至于真正的删除操作，在以后更高层级的compaction中会去做。 当某个level下的SSTable文件数目超过一定设置值后，levelDb会从这个level的SSTable中选择一个文件（level&gt;0），将其和高一层级的level+1的SSTable文件合并，这就是major compaction。 我们知道在大于0的层级中，每个SSTable文件内的Key都是由小到大有序存储的，而且不同文件之间的key范围（文件内最小key和最大key之间）不会有任何重叠。Level 0的SSTable文件有些特殊，尽管每个文件也是根据Key由小到大排列，但是因为level 0的文件是通过minor compaction直接生成的，所以任意两个level 0下的两个sstable文件可能再key范围上有重叠。所以在做major compaction的时候，对于大于level 0的层级，选择其中一个文件就行，但是对于level 0来说，指定某个文件后，本level中很可能有其他SSTable文件的key范围和这个文件有重叠，这种情况下，要找出所有有重叠的文件和level 1的文件进行合并，即level 0在进行文件选择的时候，可能会有多个文件参与major compaction。 levelDb在选定某个level进行compaction后，还要选择是具体哪个文件要进行compaction，levelDb在这里有个小技巧， 就是说轮流来，比如这次是文件A进行compaction，那么下次就是在key range上紧挨着文件A的文件B进行compaction，这样每个文件都会有机会轮流和高层的level 文件进行合并。 如果选好了level L的文件A和level L+1层的文件进行合并，那么问题又来了，应该选择level L+1哪些文件进行合并？levelDb选择L+1层中和文件A在key range上有重叠的所有文件来和文件A进行合并。 也就是说，选定了level L的文件A,之后在level L+1中找到了所有需要合并的文件B,C,D…..等等。剩下的问题就是具体是如何进行major 合并的？就是说给定了一系列文件，每个文件内部是key有序的，如何对这些文件进行合并，使得新生成的文件仍然Key有序，同时抛掉哪些不再有价值的KV 数据。 图8.2说明了这一过程。 图8.2 SSTable CompactionMajor compaction的过程如下：对多个文件采用多路归并排序的方式，依次找出其中最小的Key记录，也就是对多个文件中的所有记录重新进行排序。之后采取一定的标准判断这个Key是否还需要保存，如果判断没有保存价值，那么直接抛掉，如果觉得还需要继续保存，那么就将其写入level L+1层中新生成的一个SSTable文件中。就这样对KV数据一一处理，形成了一系列新的L+1层数据文件，之前的L层文件和L+1层参与compaction 的文件数据此时已经没有意义了，所以全部删除。这样就完成了L层和L+1层文件记录的合并过程。 那么在major compaction过程中，判断一个KV记录是否抛弃的标准是什么呢？其中一个标准是:对于某个key来说，如果在小于L层中存在这个Key，那么这个KV在major compaction过程中可以抛掉。因为我们前面分析过，对于层级低于L的文件中如果存在同一Key的记录，那么说明对于Key来说，有更新鲜的Value存在，那么过去的Value就等于没有意义了，所以可以删除。 LevelDb日知录之九 levelDb中的Cache书接前文，前面讲过对于levelDb来说，读取操作如果没有在内存的memtable中找到记录，要多次进行磁盘访问操作。假设最优情况，即第一次就在level 0中最新的文件中找到了这个key，那么也需要读取2次磁盘，一次是将SSTable的文件中的index部分读入内存，这样根据这个index可以确定key是在哪个block中存储；第二次是读入这个block的内容，然后在内存中查找key对应的value。 levelDb中引入了两个不同的Cache:Table Cache和Block Cache。其中Block Cache是配置可选的，即在配置文件中指定是否打开这个功能。 图9.1 table cache图9.1是table cache的结构。在Cache中，key值是SSTable的文件名称，Value部分包含两部分，一个是指向磁盘打开的SSTable文件的文件指针，这是为了方便读取内容；另外一个是指向内存中这个SSTable文件对应的Table结构指针，table结构在内存中，保存了SSTable的index内容以及用来指示block cache用的cache_id ,当然除此外还有其它一些内容。 比如在get(key)读取操作中，如果levelDb确定了key在某个level下某个文件A的key range范围内，那么需要判断是不是文件A真的包含这个KV。此时，levelDb会首先查找Table Cache，看这个文件是否在缓存里，如果找到了，那么根据index部分就可以查找是哪个block包含这个key。如果没有在缓存中找到文件，那么打开SSTable文件，将其index部分读入内存，然后插入Cache里面，去index里面定位哪个block包含这个Key 。如果确定了文件哪个block包含这个key，那么需要读入block内容，这是第二次读取。 图9.2 block cacheBlock Cache是为了加快这个过程的，图9.2是其结构示意图。其中的key是文件的cache_id加上这个block在文件中的起始位置block_offset。而value则是这个Block的内容。 如果levelDb发现这个block在block cache中，那么可以避免读取数据，直接在cache里的block内容里面查找key的value就行，如果没找到呢？那么读入block内容并把它插入block cache中。levelDb就是这样通过两个cache来加快读取速度的。从这里可以看出，如果读取的数据局部性比较好，也就是说要读的数据大部分在cache里面都能读到，那么读取效率应该还是很高的，而如果是对key进行顺序读取效率也应该不错，因为一次读入后可以多次被复用。但是如果是随机读取，您可以推断下其效率如何。 LevelDb日知录之十 Version、VersionEdit、VersionSetVersion 保存了当前磁盘以及内存中所有的文件信息，一般只有一个Version叫做”current” version（当前版本）。Leveldb还保存了一系列的历史版本，这些历史版本有什么作用呢？ 当一个Iterator创建后，Iterator就引用到了current version(当前版本)，只要这个Iterator不被delete那么被Iterator引用的版本就会一直存活。这就意味着当你用完一个Iterator后，需要及时删除它。 当一次Compaction结束后（会生成新的文件，合并前的文件需要删除），Leveldb会创建一个新的版本作为当前版本，原先的当前版本就会变为历史版本。 VersionSet 是所有Version的集合，管理着所有存活的Version。 VersionEdit 表示Version之间的变化，相当于delta 增量，表示有增加了多少文件，删除了文件。下图表示他们之间的关系。 Version0 +VersionEdit–&gt;Version1 VersionEdit会保存到MANIFEST文件中，当做数据恢复时就会从MANIFEST文件中读出来重建数据。 leveldb的这种版本的控制，让我想到了双buffer切换，双buffer切换来自于图形学中，用于解决屏幕绘制时的闪屏问题，在服务器编程中也有用处。 比如我们的服务器上有一个字典库，每天我们需要更新这个字典库，我们可以新开一个buffer，将新的字典库加载到这个新buffer中，等到加载完毕，将字典的指针指向新的字典库。 leveldb的version管理和双buffer切换类似，但是如果原version被某个iterator引用，那么这个version会一直保持，直到没有被任何一个iterator引用，此时就可以删除这个version。 注：博文参考了郎格科技博客：http://www.samecity.com/blog/Index.asp?SortID=12","raw":null,"content":null,"categories":[{"name":"Leveldb","slug":"Leveldb","permalink":"https://Caden16.github.io/categories/Leveldb/"}],"tags":[{"name":"Leveldb","slug":"Leveldb","permalink":"https://Caden16.github.io/tags/Leveldb/"}]},{"title":"用户态到内核态切换","slug":"用户态到内核态切换","date":"2017-03-16T00:00:00.000Z","updated":"2017-03-16T02:57:57.726Z","comments":true,"path":"操作系统/用户态到内核态切换/","link":"","permalink":"https://Caden16.github.io/操作系统/用户态到内核态切换/","excerpt":"","text":"用户态 内核态概念引用《深入理解LINUX内核》的一段话:类UNIX操作系统把与计算机物理组织相关的底层细节都对用户运行的程序隐藏起来, 当程序想用硬件资源时,必须向操作系统发出一个请求. 内核对这个请求进行评估,如果允许使用这个资源,那么,内核代表应用程序与相应的硬件进行交互.硬件CPU引入至少两种不同的执行模式: 用户程序的非特权模式和内核的特权模式.unix把它们分别成为用户态和内核态. 用户态和内核态之间进行切换时的代价参考用户态到内核态切换之奥秘解析用户态到内核态切换途径： 1：系统调用 2：中断 3：异常 在X86中调用int指令型系统调用后会把用户栈的%esp的值及相关寄存器压入内核栈中，系统调用通过iret指令返回，在返回之前会从内核栈弹出用户栈的%esp和寄存器的状态，然后进行恢复。所以在进入内核态之前要保存进程的上下文，中断结束后恢复进程上下文，那靠的就是内核栈。 这里有个细节问题，就是要想在内核栈保存用户态的esp,eip等寄存器的值，首先得知道内核栈的栈指针，那在进入内核态之前，通过什么才能获得内核栈的栈指针呢？答案是：TSS(任务状态段)X86体系结构中包括了一个特殊的段类型：任务状态段（TSS），用它来存放硬件上下文。TSS反映了CPU上的当前进程的特权级。linux为每一个cpu提供一个tss段，并且在tr寄存器中保存该段。在从用户态切换到内核态时，可以通过获取TSS段中的esp0来获取当前进程的内核栈 栈顶指针，从而可以保存用户态的cs,esp,eip等上下文。 总结在进程从用户态到内核态切换过程中，Linux主要做的事： 1：读取tr寄存器，访问TSS段 2：从TSS段中的sp0获取进程内核栈的栈顶指针 3: 由控制单元在内核栈中保存当前eflags,cs,ss,eip,esp寄存器的值。 4：由SAVE_ALL保存其寄存器的值到内核栈 5：把内核代码选择符写入CS寄存器，内核栈指针写入ESP寄存器，把内核入口点的线性地址写入EIP寄存器 此时，CPU已经切换到内核态，根据EIP中的值开始执行内核入口点的第一条指令。","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"}]},{"title":"LRU缓存淘汰算法","slug":"LRU缓存淘汰算法","date":"2017-03-08T00:00:00.000Z","updated":"2017-03-08T11:39:59.802Z","comments":true,"path":"算法/LRU缓存淘汰算法/","link":"","permalink":"https://Caden16.github.io/算法/LRU缓存淘汰算法/","excerpt":"在Linux目录项高速缓存中,所有”未使用”的目录项对象都存放在一个会使用LRU(Last Recently used)算法实现的双向链表中,该链表按照插入的时间进行排序. 最后释放的目录项会放在链表的首部,最近最少使用的目录项对象靠近链表尾部,需要释放空间时,内核从链表尾部进行删除.","text":"在Linux目录项高速缓存中,所有”未使用”的目录项对象都存放在一个会使用LRU(Last Recently used)算法实现的双向链表中,该链表按照插入的时间进行排序. 最后释放的目录项会放在链表的首部,最近最少使用的目录项对象靠近链表尾部,需要释放空间时,内核从链表尾部进行删除.参考缓存淘汰算法–LRU算法,LRU算法实现: 新数据插入到链表头部； 每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 当链表满的时候，将链表尾部的数据丢弃。 缓存污染: 当存在热点数据时，LRU的效率很好,但偶发性的、周期性的批量操作会导致LRU命中率急剧下降","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://Caden16.github.io/categories/算法/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://Caden16.github.io/tags/缓存/"}]},{"title":"伪随机数","slug":"伪随机数","date":"2017-03-05T00:00:00.000Z","updated":"2017-03-05T08:56:55.648Z","comments":true,"path":"操作系统/伪随机数/","link":"","permalink":"https://Caden16.github.io/操作系统/伪随机数/","excerpt":"遇到一到面试题,其中提到Hash函数的构造方法可以使用 随机数法:选择一个随机函数，取关键字的随机函数值为它的散列地址,感觉取随机数会导致数据查找失败,不过查找了有关计算机中伪随机数的生成方法后,明白了这个方法是可行的.","text":"遇到一到面试题,其中提到Hash函数的构造方法可以使用 随机数法:选择一个随机函数，取关键字的随机函数值为它的散列地址,感觉取随机数会导致数据查找失败,不过查找了有关计算机中伪随机数的生成方法后,明白了这个方法是可行的.解释来自百度百科:12345678910111213141516171819202122//rand01.c#include &lt;stdlib.h&gt;static unsigned int RAND_SEED;unsigned int random(void)&#123; RAND_SEED=(RAND_SEED*123+59)%65536; return(RAND_SEED);&#125;void random_start(void)&#123; int temp[2]; movedata(0x0040,0x006c,FP_SEG(temp),FP_OFF(temp),4); RAND_SEED=temp[0];&#125;main()&#123; unsigned int i,n; random_start(); for(i=0;i&lt;10;i++) printf(\"%u\\t\",random()); printf(\"\\n\");&#125; 1movedata(0x0040,0x006c,FP_SEG(temp),FP_OFF(temp),4); 这个函数用来移动内存数据，其中FP_SEG（far pointer to segment）是取temp数组段地址的函数，FP_OFF（far pointer to offset）是取temp数组相对地址的函数，movedata函数的作用是把位于0040:006CH存储单元中的双字放到数组temp的声明的两个存储单元中。这样可以通过temp数组把0040:006CH处的一个16位的数送给RAND_SEED。random用来根据随机种子RAND_SEED的值计算得出随机数，其中这一句：1RAND_SEED=(RAND_SEED*123+59)%65536 是用来计算随机数的方法，随机数的计算方法在不同的计算机中是不同的，即使在相同的计算机中安装的不同的操作系统中也是不同的。我在linux和windows下分别试过，相同的随机种子在这两种操作系统中生成的随机数是不同的，这说明它们的计算方法不同。0040:006CH处其实这一段内存空间是这样定义的：TIMER_LOW DW ? ；地址为 0040:006CHTIMER_HIGH DW ? ；地址为 0040:006EHTIMER_OFT DB ? ；地址为 0040:0070H时钟中断服务程序中，每当TIMER_LOW转满时，此时，记数器也会转满，记数器的值归零，即TIMER_LOW处的16位二进制归零，而TIMER_HIGH加一。由于随机种子可以人工设定,因此每次产生的随机数都是相同的.Python例子:12345678910111213141516171819202122232425262728293031In [3]: random.seed(1)In [4]: for i in range(10): ...: print random.random() ...:0.1343642441120.8474337369370.7637746189770.2550690257390.4954350870920.4494910647890.6515929727230.7887233511360.09385958677420.028347476522In [5]: random.seed(1)In [6]: for i in range(10): ...: print random.random() ...:0.1343642441120.8474337369370.7637746189770.2550690257390.4954350870920.4494910647890.6515929727230.7887233511360.09385958677420.028347476522In [7]:","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://Caden16.github.io/tags/操作系统/"}]},{"title":"(转)文件系统vs对象存储——选型和趋势","slug":"对象存储VS文件系统","date":"2017-03-03T00:00:00.000Z","updated":"2017-03-03T11:25:09.854Z","comments":true,"path":"对象存储/对象存储VS文件系统/","link":"","permalink":"https://Caden16.github.io/对象存储/对象存储VS文件系统/","excerpt":"","text":"之前对于对象存储的定义还是比较模糊，看完文件系统vs对象存储——选型和趋势这篇文章后对文件系统和对象存储有一个比较清晰的了解，做一下简单的概括。 对象存储初期：对象存储往往指的是以类似标准化组织SNIA定义的OSD（object storage device）和MDS（Metadata Server）为基本组成部分的分布式存储，通常是分布式文件系统。后期：指的是以AWS的S3为代表的，通过HTTP接口提供访问的存储服务或者存储系统,如果我们把一个文件传到对象存储系统里面存起来，就叫做一个对象。 对象存储与文件系统的比较对于大多数文件系统来说，尤其是POSIX(表示可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ）,POSIX标准定义了操作系统应该为应用程序提供的接口标准)兼容的文件系统，提供open、close、read、write和lseek等接口。而对象存储的接口是REST风格的，通常是基于HTTP协议的RESTful Web API，通过HTTP请求中的PUT和GET等操作进行文件的上传即写入和下载即读取，通过DELETE操作删除文件。对象存储和文件系统在接口上的本质区别是对象存储不支持和fread和fwrite类似的随机位置读写操作，即一个文件PUT到对象存储里以后，如果要读取，只能GET整个文件，如果要修改一个对象，只能重新PUT一个新的到对象存储里，覆盖之前的对象或者形成一个新的版本。","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"文件系统，对象存储","slug":"文件系统，对象存储","permalink":"https://Caden16.github.io/tags/文件系统，对象存储/"}]},{"title":"C++语法记录","slug":"C++语法记录","date":"2017-03-01T00:00:00.000Z","updated":"2017-03-21T13:01:44.816Z","comments":true,"path":"C/C++语法记录/","link":"","permalink":"https://Caden16.github.io/C/C++语法记录/","excerpt":"","text":"最近遇到一些C++的代码,其中会包含一些C++11及STL的代码,对C++11的特性不太了解,记录一下. nextnext用于操作迭代器,函数解释std::nextParameters it - an iterator n - number of elements to advance使用示例:12345678910111213141516#include &lt;iostream&gt;#include &lt;iterator&gt;#include &lt;vector&gt;int main()&#123; std::vector&lt;int&gt; v&#123; 3, 1, 4,6,7 &#125;; auto it = v.begin(); auto nx = std::next(it, 3); std::cout &lt;&lt; *it &lt;&lt; &apos; &apos; &lt;&lt; *nx &lt;&lt; &apos;\\n&apos;;&#125;output:3 6 push_backSTL之vector容器详解函数将一个新的元素加到vector的最后面，位置为当前最后一个元素的下一个元素. 参考C++ vector::push_back 用法剖析 for_eachfor_each用于逐个遍历容器元素，它对迭代器区间[first，last)所指的每一个元素，执行由单参数函数对象f所定义的操作。参考简单的程序诠释C++ STL算法系列之一：for_each map参考C++ map的基本操作和使用C++中map容器提供一个键值对容器，map与multimap差别仅仅在于multimap允许一个键对应多个值。使用时需要包含头文件#include在map中插入元素,enumMap[1] = “One”;这样非常直观，但存在一个性能的问题。插入2时,先在enumMap中查找主键为2的项，没发现，然后将一个新的对象插入enumMap，键是2，值是一个空字符串，插入完成后，将字符串赋为”Two”; 该方法会将每个值都赋为缺省值，然后再赋为显示的值，如果元素是类对象，则开销比较大。我们可以用以下方法来避免开销：enumMap.insert(map :: value_type(2, “Two”))查找并获取map中的元素:CString tmp = enumMap[2];但是,只有当map中有这个键的实例时才对，否则会自动插入一个实例，值为初始化值。查找map中是否包含某个关键字条目用find()方法，传入的参数是要查找的key，在这里需要提到的是begin()和end()两个成员，分别代表map对象中第一个条目和最后一个条目，这两个数据的类型是iterator.int nFindKey = 2; //要查找的Key//定义一个条目变量(实际是指针)UDT_MAP_INT_CSTRING::iterator it= enumMap.find(nFindKey);if(it == enumMap.end()) {//没找到}else {//找到}通过map对象的方法获取的iterator数据类型是一个std::pair对象，包括两个数据 iterator-&gt;first 和 iterator-&gt;second 分别代表关键字和存储的数据//删除map::iterator iter=m_AgentClients.find(pSocket-&gt;GetName()); if(iter!=m_AgentClients.end()) { m_AgentClients.erase(iter);//列表移除 } multimap 参考c++ stl multimap基本操作使用技巧详细介绍 C++ stl Multimap 和C++ stl map 很相似，但是MultiMap允许重复的元素。","raw":null,"content":null,"categories":[{"name":"C++","slug":"C","permalink":"https://Caden16.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://Caden16.github.io/tags/C/"},{"name":"C++11","slug":"C-11","permalink":"https://Caden16.github.io/tags/C-11/"}]},{"title":"gdb调试错误-找不到文件","slug":"gdb调试错误-找不到文件","date":"2017-02-28T00:00:00.000Z","updated":"2017-02-28T09:09:13.116Z","comments":true,"path":"linux命令/gdb调试错误-找不到文件/","link":"","permalink":"https://Caden16.github.io/linux命令/gdb调试错误-找不到文件/","excerpt":"","text":"使用gdb进行调试时出现错误,错误重现:(gdb) qsh-4.3$ gdb -q aaaReading symbols from aaa…done.(gdb) l28 int base = factorial(n - 1);29 –k;30 for (int i = n -1; i &gt; 0; k %= base, base /= i, –i) {31 auto a = next(S.begin(), k / base);32 result.push_back(*a);33 S.erase(a);34 }35 cout &lt;&lt; S[0];36 auto a = S[0];37 // result.push_pack(a);(gdb) b 37Breakpoint 1 at 0x4012a2: file /home/ubuntu/workspace/leetcode/permutation_sequence.cpp, line 37.(gdb) rStarting program: /home/ubuntu/workspace/leetcode/aaaCannot exec -c exec /home/ubuntu/workspace/leetcode/aaa .Error: 没有那个文件或目录During startup program exited with code 127. 在vscode中,错误提示为:1Unable to start debugging. Unexpected GDB output from command &quot;-exec-run&quot;. During startup program exited with code 127. 解决方法:参考http://unix.stackexchange.com/questions/167918/gdb-cannot-exec-my-test-program,由于SHELL变量不存在,导致gdb抛出异常,解决方法:在/etc//etc/environment中设置全局变量123export SHELL=/bin/sh或export SHELL=/bin/bash","raw":null,"content":null,"categories":[{"name":"linux命令","slug":"linux命令","permalink":"https://Caden16.github.io/categories/linux命令/"}],"tags":[{"name":"gdb","slug":"gdb","permalink":"https://Caden16.github.io/tags/gdb/"}]},{"title":"swift-weedfs-backend diskfile代码实现","slug":"swift-weedfs-backend diskfile代码实现","date":"2017-02-26T00:00:00.000Z","updated":"2017-03-02T02:46:55.297Z","comments":true,"path":"对象存储/swift-weedfs-backend diskfile代码实现/","link":"","permalink":"https://Caden16.github.io/对象存储/swift-weedfs-backend diskfile代码实现/","excerpt":"主要修改InMemoryFileSystem中的代码,使用seaweedfs进行数据持久化,完整代码实现swift-weedfs-backend","text":"主要修改InMemoryFileSystem中的代码,使用seaweedfs进行数据持久化,完整代码实现swift-weedfs-backend1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class InMemoryFileSystem(object): \"\"\" A very simplistic in-memory file system scheme. There is one dictionary mapping a given object name to a tuple. The first entry in the tuple is the cStringIO buffer representing the file contents, the second entry is the metadata dictionary. \"\"\" def __init__(self): self._filesystem = &#123;&#125; self.seaweedfs = Seaweedfs_operation() def get_object(self, name): \"\"\" Return back an file-like object and its metadata :param name: standard object name :return (fp, metadata): fp is `StringIO` in-memory representation object (or None). metadata is a dictionary of metadata (or None) \"\"\" # val = self._filesystem.get(name) val = self.seaweedfs.GET(name) if val is None: fp, metadata = None, None else: fp, metadata = self.parse_seaweedfs_file(val) # else: # fp, metadata = val return fp, metadata def parse_seaweedfs_file(self,val): \"\"\" parse file download from seaweedfs :param val: seaweedfs file,fomat: str(metadata) + '\\n' + obj_content :return: StringIO obj_content, python dict metadata \"\"\" metadata_index = val.find('\\n') val = val.split('\\n',1) return StringIO.StringIO(val[1]),eval(val[0]) def put_object(self, name, fp, metadata): \"\"\" Store object into seaweedfs :param name: standard object name :param fp: `StringIO` in-memory representation object :param metadata: dictionary of metadata to be written \"\"\" # self._filesystem[name] = (fp, metadata) fp.seek(0) self.seaweedfs.PUT(name,str(metadata) + '\\n' + fp.read()) def del_object(self, name): \"\"\" Delete object from memory :param name: standard object name \"\"\" # import pydevd # pydevd.settrace('127.0.0.1', port=54321, stdoutToServer=True, stderrToServer=True) self.seaweedfs.DELETE(name) # del self._filesystem[name] def get_diskfile(self, account, container, obj, **kwargs): return DiskFile(self, account, container, obj) def pickle_async_update(self, *args, **kwargs): \"\"\" For now don't handle async updates. \"\"\" pass","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"},{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"},{"name":"swift-weedfs-backend","slug":"swift-weedfs-backend","permalink":"https://Caden16.github.io/tags/swift-weedfs-backend/"}]},{"title":"LeetCode解题-Next Permutation(全排列生成算法)","slug":"LeetCode解题-Permutation Sequence","date":"2017-02-26T00:00:00.000Z","updated":"2017-02-27T12:41:08.472Z","comments":true,"path":"算法/LeetCode解题-Permutation Sequence/","link":"","permalink":"https://Caden16.github.io/算法/LeetCode解题-Permutation Sequence/","excerpt":"","text":"题目:给出数字n,在1…n的全排列组合中找到第k个,如: n = 3, k=31234567全排列:123132213231312321 结果为:213 解题使用逆康托编码展开,参考全排列的编码与解码——康托展开 康托编码:{1,2,3,4,…,n}的排列总共有n!种，将它们从小到大排序，怎样知道其中一种排列是有序序列中的第几个？如 {1,2,3} 按从小到大排列一共6个：123 132 213 231 312 321。想知道321是{1,2,3}中第几个大的数。小于3的数有1和2 两个，首位确定之后后面两位有2！中情况，所以共有22！=4种。小于2的数只有一个1，所以有11！=1种情况，最后一位是1，没有比一小的数，所以是00！=0综上：小于321的数有4+1=5个，所以321是第六小的数。例如:排列3 5 7 4 1 2 9 6 8展开为98884X=28!+37!+46!+25!+04!+03!+22!+01!+00!=98884. 逆康托展开:1234567891011121314151617181920212223如何找出第16个（按字典序的）&#123;1,2,3,4,5&#125;的全排列？1. 首先用16-1得到152. 用15去除4! 得到0余153. 用15去除3! 得到2余34. 用3去除2! 得到1余15. 用1去除1! 得到1余0有0个数比它小的数是1，所以第一位是1有2个数比它小的数是3，但1已经在之前出现过了所以是4有1个数比它小的数是2，但1已经在之前出现过了所以是3有1个数比它小的数是2，但1,3,4都出现过了所以是5最后一个数只能是2所以排列为1 4 3 5 2","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://Caden16.github.io/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://Caden16.github.io/tags/LeetCode/"}]},{"title":"LeetCode解题-Next Permutation(全排列生成算法)","slug":"LeetCode解题-Next Permutation(全排列生成算法)","date":"2017-02-26T00:00:00.000Z","updated":"2017-02-27T07:37:20.507Z","comments":true,"path":"算法/LeetCode解题-Next Permutation(全排列生成算法)/","link":"","permalink":"https://Caden16.github.io/算法/LeetCode解题-Next Permutation(全排列生成算法)/","excerpt":"","text":"LeetCode题目-Next Permutation看半天连题目都看不懂,参考LeetCode 31 Next Permutation（下一个排列）,基本理解题意:数学中的排列组合，比如“1，2，3”的全排列，依次是：1234561 2 31 3 22 1 32 3 13 1 23 2 1 从上面的某一行重排到期下一行，如果已经是最后一行了，则重排成第一行。 实现思路:从后往前遍历,找到最长递增序列,结束位置为index,然后找到最长递增序列中比index-1的数大的最小的数.图片来源:http://fisherlei.blogspot.co.id/2012/12/leetcode-next-permutation.html","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://Caden16.github.io/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://Caden16.github.io/tags/LeetCode/"}]},{"title":"swift-weedfs-backend接口设计","slug":"swift-weedfs-backend接口设计","date":"2017-02-25T00:00:00.000Z","updated":"2017-02-26T13:41:57.679Z","comments":true,"path":"对象存储/swift-weedfs-backend接口设计/","link":"","permalink":"https://Caden16.github.io/对象存储/swift-weedfs-backend接口设计/","excerpt":"","text":"swift-weedfs-backend基于mem_diskfile,使用seaweedfs对mem_diskfile中的数据进行持久化.设计接口如下: 接口名称 参数类型:参数名称 返回值 接口说明 GET strng:url file_content 获取seaweedfs文件 PUT string:url,obj_content True/False 保存对象 DELETE string:url True/False 删除对象 parseURL string:url account,container,obj_name 从URL中解析得到account,container,obj_name 代码实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Seaweedfs_operation(): def __init__(self): self.seaweedfs = WeedFS(); self.filter_ip = \"127.0.0.1\" self.filter_port = \"8888\" def PUT(self,url, obj_content): \"\"\" upload file to seaweedfs :param url: :param obj_content: :return: obj size \"\"\" account,container,obj_name = self.parseURL(url) url_complete = u\"http://&#123;filter_ip&#125;:&#123;filter_port&#125;/&#123;account&#125;/&#123;container&#125;/\".format(filter_ip=self.filter_ip, filter_port=self.filter_port, account=account,container=container) return self.seaweedfs.upload_file(url_complete,obj_name,obj_content) def DELETE(self,url): \"\"\" delete a file from seaweedfs :param url: :return: Boolean: True:delete success \"\"\" url_complete = u\"http://&#123;filter_ip&#125;:&#123;filter_port&#125;&#123;url&#125;\".format(filter_ip=self.filter_ip, filter_port=self.filter_port,url=url) return self.seaweedfs.delete_file(url_complete) def GET(self,url): \"\"\" download a file from seaweedfs :param url: :return: Content of the file with provided url or None if file doesn't exist on the server \"\"\" url_complete = \"http://&#123;filter_ip&#125;:&#123;filter_port&#125;&#123;url&#125;\".format(filter_ip=self.filter_ip, filter_port=self.filter_port,url=url) return self.seaweedfs.get_file(url_complete) def parseURL(self,url): \"\"\" parse url to account, container, obj_name :param url: :return: account, container, obj_name \"\"\" url_split = url.split('/') return url_split[1],url_split[2],url_split[3]","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"},{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"openstack-swift源码阅读记录4-启用mem_diskfile","slug":"openstack-swift源码阅读记录4-启用mem_diskfile","date":"2017-02-24T00:00:00.000Z","updated":"2017-02-25T11:46:46.271Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录4-启用mem_diskfile/","link":"","permalink":"https://Caden16.github.io/对象存储/openstack-swift源码阅读记录4-启用mem_diskfile/","excerpt":"","text":"修改/etc/swift/object-server/中的文件,改为:12[app:object-server]use = egg:swift#mem_object mem_diskfile为mem_server提供内存存储后端实现,而mem_server继承自server.ObjectController,提供请求转发工作,其中,设置客户端超时时间:1self.client_timeout = int(conf.get(&apos;client_timeout&apos;, 60)) 用户上传对象过程调用mem_diskfile中的put_object方法1def put_object(self, name, fp, metadata): 参数:可以看到,name为account,container,object的组合","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"在Openstack Swift中使用多种后端存储实现","slug":"在Openstack Swift中使用多种后端存储实现","date":"2017-02-23T00:00:00.000Z","updated":"2017-02-24T06:04:21.796Z","comments":true,"path":"对象存储/在Openstack Swift中使用多种后端存储实现/","link":"","permalink":"https://Caden16.github.io/对象存储/在Openstack Swift中使用多种后端存储实现/","excerpt":"","text":"在Intel开发者社区发现这篇文章,给我很大的帮助,尝试着把它翻译成中文. 原文链接Using Multiple Backends in Openstack Swift Using Multiple Backends in Openstack SwiftBy Yuan Zhou (Intel), Added February 3, 2015 OpenStack Swift是一个高度可用的，分布式的，最终一致的对象存储实现系统. 考虑到经济效益及存储横向扩展能力,对象存储是理想的存储实现模式.它提供了一个完全分布式，API可访问的存储平台，可以直接集成到应用程序中或用于备份，归档和保存数据。有关详细信息，请参阅http://docs.openstack.org/developer/swift/。由于V2.0 Swift支持多个存储策略,这允许通过创建多个object ring来为不同目的进行不同的存储策略,从而实现某种程度的分段集群.对于帐户数据库，容器数据库有一个单独的ring，并且每个存储策略都有一个object ring。通过支持多个对象环，Swift允许应用程序和/或部署程序在单个集群中实现分离对象存储功能。然而Swift拥有另一个相当好的功能:从Juno发行版开始,支持可插拔存储后端. 得益于对象服务器中高度抽象的DiskFile API,存储设备提供商可以轻易地使用不同后端存储实现方案去存储文件对象. 这些项目有几个共同的特征: 这些项目被实现为一些新的WSGI对象服务器应用程序。Swift DiskFile抽象是这些多个后端解决方案的引擎. 这些项目正试图利用Swift / S3 API来加入对象存储市场或OpenStack生态系统. 目前这些项目大部分都在POC状态，并且不是很活跃。本地磁盘后端默认情况下，Swift将使用本地磁盘作为对象服务器中的存储设备. 在此实现中，用户上传的文件将单独存储在位于磁盘上层的本地文件系统中. 元数据将与文件一起存储为文件的扩展属性. 这需要一个支持文件扩展属性的文件系统，如xfs或ext4.对象服务器中的DiskFile API是一组RESTFul接口,如READ，WRITE和DELETE. 在这个本地磁盘后端，这些接口大多数是用POSIX API实现的. 例如，WRITE请求将调用python中的os.write().要使用此后端，您只需要复制示例object-server.conf. 注意，默认的WSGI应用程序应该是:123[app:object-server]use = egg: swift#object 其他后端解决方案需要使用自己的接口来实现这些接口. 使用内存后端这是在Swift中的样本示例. 在此实现中，用户上传的文件将与其元数据一起存储在内存的散列表(python dict)中. 每个键是accout，container和object_name的组合,相应的值是对象及其元数据的内容。1filesystem[name] = &#123;data, metadata&#125; 在DiskFile的一个PUT请求将是一个简单的python dict更新,这个解决方案目前只是一个原型，不适合在生产环境中使用. 我们可以很轻易地知道,当对象服务器关闭,所有的数据都会丢失.要使用此后端，您需要将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg: swift#mem_object 然后重新启动对象服务器. Swift-Ceph后端目前这是一个由eNovance发起的stackforge项目.这个实现使用Ceph作为Swift的存储设备. Swift对象环被配置为1x副本，而Ceph可以配置为3x副本. 这意味着从Swift的视图，只有1个对象副本存储在集群中。但是在Ceph集群中，将有3个对象的副本，并且Ceph将做一致性/复制工作.一般设计是来自DiskFile的新派生类，它将Swift读/写转换为使用librados读/写rados对象. Swift中的一个对象将被存储为Ceph中的一个文件，其名称为account，container和object name的组合.目前,account/container数据库依然以原始的方式存储在Swift当中.该项目还有一个计划，以便以后将这些SQLite DB存储到Ceph.此解决方案实现为WSGI应用程序,要使用此后端，您需要安装swift-ceph-backend项目，并将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg: swift_ceph_backend#rados_object 然后重新启动对象服务器. Swift-On-File后端Swift-on-File项目也是由Redhat发起的stackforge项目, 目前它是一个Swift对象服务器的实现, 它使用户能够访问相同的数据，既作为对象也可作为文件. 数据可以通过Swift的REST接口存储和检索，也可作为NAS接口的文件，包括本地GlusterFS，NFS和CIFS.要使用此后端，您需要安装swiftonfile项目，然后将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg:swiftonfile#object 您还需要在/mnt/swiftonfile 挂载一个NFS分区,或GlusterFS卷建议将对象环配置为仅1个副本. 所有的一致性/复制工作都在GlusterFS / NFS层中处理 Seagate kinetics后端Swift over Seagate 是由SwiftStack和Seagate开始的一个项目. 目前，它仍然在试验beta Kinetic库中. 使用Kinetic驱动器的Swift群集允许访问任何驱动器，从而访问任何对象.对于当前的Kinetic集成,对象服务器命令（对象守护程序）的一小部分被嵌入在作为逻辑构造的代理服务器中,如下所示:还有一些通过kinetic部署的设备,由于这个项目仍在开发中,没有准备过多的文档. 您需要检查最新的代码来了解详细信息. 参考文献：http://docs.openstack.org/developer/swift/https://swiftstack.com/blog/2014/02/04/swift-extensibility/https://github.com/stackforge/swift-ceph-backendhttps://github.com/stackforge/swiftonfilehttps://github.com/swiftstack/kinetic-swifthttps://developers.seagate.com/display/KV/OpenStack+Swift","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"},{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"openstack-swift源码阅读记录3-diskfile","slug":"openstack-swift源码阅读记录3-diskfile","date":"2017-02-21T00:00:00.000Z","updated":"2017-02-21T07:19:05.819Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录3-diskfile/","link":"","permalink":"https://Caden16.github.io/对象存储/openstack-swift源码阅读记录3-diskfile/","excerpt":"","text":"diskfile模块：diskfile模块为Swift对象服务器的磁盘文件接口 “DiskFile”，“DiskFileWriter”和“DiskFileReader”类组合定义用于支持对象服务器REST API的磁盘抽象层接口（不包括REPLICATE）。 其他希望提供的实现对象服务器的替代后端必须实现三个类。 mem_server.py和mem_diskfile.py模块为其中的一个实现示例。 DiskFileManager是一个参考实现特定的类，而不是部分后端API。 此模块中的其余方法被视为具体实现并且也不被视为后端API的一部分。","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"ubuntu使用问题总结","slug":"ubuntu使用问题总结","date":"2017-02-16T00:00:00.000Z","updated":"2017-02-16T13:48:09.980Z","comments":true,"path":"ubuntu/ubuntu使用问题总结/","link":"","permalink":"https://Caden16.github.io/ubuntu/ubuntu使用问题总结/","excerpt":"","text":"lightdm登录界面找不到登录用户名问题分析：直接修改/etc/passwd文件中的用户user id，想要用此方法提升普通用户权限为root权限，但把user id在/etc/passwd中重新改成不为原有user id（比如原有user id 为1000，改成0后，又改成1001）时，会导致系统找不到用户，这是再改成1000，系统也会找不到用户，因此在登录界面不显示。解决方法：使用userdel 删除用户，但不删除与用户相关配置文件，然后使用useradd添加同名用户，即可在登录页面显示。 系统登录不断循环问题分析：参考Ubuntu 14.04登陆界面无限循环的解决办法,其中提到，home目录空间满了，还有一种可能是：由于添加了同名用户，但用户的user id不一样，系统认为/home目录不属于当前登录用户，导致登录不进去。解决方法：常看当前用户的user id：1id -u &lt;username&gt; 使用ll命令查看当前用户的/home文件夹所有者的user id是否为当前用户的user id，如果不是，使用命令chown改变home目录的所有者。 无法执行/bin/bash，没有那个文件或目录问题分析：参考脚本格式之殇——/bin/bash^M: 没有那个文件或目录 ，修改过/etc/passwd文件，导致/bin/bash后面多加空格符解决方法：使用cat -A filename查看文件，把不规则的空格去掉","raw":null,"content":null,"categories":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://Caden16.github.io/categories/ubuntu/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://Caden16.github.io/tags/ubuntu/"}]},{"title":"openstack源码阅读记录2-object metadata","slug":"openstack源码阅读记录2-object metadata","date":"2017-02-13T00:00:00.000Z","updated":"2017-02-13T09:06:16.572Z","comments":true,"path":"对象存储/openstack源码阅读记录2-object metadata/","link":"","permalink":"https://Caden16.github.io/对象存储/openstack源码阅读记录2-object metadata/","excerpt":"","text":"通过调试,得到object metadata的格式:","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"openstack-swift源码阅读记录1-文件上传过程","slug":"openstack-swift源码阅读记录1-文件上传过程","date":"2017-02-12T00:00:00.000Z","updated":"2017-02-13T09:07:50.308Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录1-文件上传过程/","link":"","permalink":"https://Caden16.github.io/对象存储/openstack-swift源码阅读记录1-文件上传过程/","excerpt":"使用命令:1swift upload\n上传文件,openstack-swift调用过程\n入口函数","text":"使用命令:1swift upload 上传文件,openstack-swift调用过程 入口函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def HEAD(self, request): \"\"\"Handle HTTP HEAD requests for the Swift Object Server.\"\"\" device, partition, account, container, obj, policy = \\ get_name_and_placement(request, 5, 5, True) #从请求中获取相应信息,其中: #policy:根据request中的X-Backend-Storage-Policy-Index获得 #device, partition, account, container, obj根据request.path获得 frag_prefs = safe_json_loads( request.headers.get('X-Backend-Fragment-Preferences')) try: disk_file = self.get_diskfile( device, partition, account, container, obj, policy=policy, frag_prefs=frag_prefs) # disk_file:BaseDiskFile对象 except DiskFileDeviceUnavailable: return HTTPInsufficientStorage(drive=device, request=request) try: metadata = disk_file.read_metadata() #从object中读取metadata except DiskFileXattrNotSupported: return HTTPInsufficientStorage(drive=device, request=request) except (DiskFileNotExist, DiskFileQuarantined) as e: headers = &#123;&#125; if hasattr(e, 'timestamp'): headers['X-Backend-Timestamp'] = e.timestamp.internal return HTTPNotFound(request=request, headers=headers, conditional_response=True) conditional_etag = resolve_etag_is_at_header(request, metadata) response = Response(request=request, conditional_response=True, conditional_etag=conditional_etag) response.headers['Content-Type'] = metadata.get( 'Content-Type', 'application/octet-stream') for key, value in metadata.items(): if (is_sys_or_user_meta('object', key) or is_object_transient_sysmeta(key) or key.lower() in self.allowed_headers): response.headers[key] = value response.etag = metadata['ETag'] ts = Timestamp(metadata['X-Timestamp']) response.last_modified = math.ceil(float(ts)) # Needed for container sync feature response.headers['X-Timestamp'] = ts.normal response.headers['X-Backend-Timestamp'] = ts.internal response.headers['X-Backend-Data-Timestamp'] = \\ disk_file.data_timestamp.internal if disk_file.durable_timestamp: response.headers['X-Backend-Durable-Timestamp'] = \\ disk_file.durable_timestamp.internal response.headers['X-Backend-Fragments'] = \\ _make_backend_fragments_header(disk_file.fragments) response.content_length = int(metadata['Content-Length']) try: response.content_encoding = metadata['Content-Encoding'] except KeyError: pass return response 获取diskfile过程12345678# obj/server.py 中的get_diskfile,通过BaseDiskFileManager中的get_diskfile方法,返回BaseDiskFile对象# get_diskfile返回BaseDiskFile对象return self.diskfile_cls(self, dev_path, partition, account, container, obj, policy=policy, use_splice=self.use_splice, pipe_size=self.pipe_size, use_linkat=self.use_linkat, **kwargs) # diskfile_cls : BaseDiskFile","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"文件合并存储与单个存储优劣势分析","slug":"文件系统(seaweedfs)与关系型数据库优劣势分析","date":"2017-02-08T00:00:00.000Z","updated":"2017-02-10T15:24:26.352Z","comments":true,"path":"文件系统/文件系统(seaweedfs)与关系型数据库优劣势分析/","link":"","permalink":"https://Caden16.github.io/文件系统/文件系统(seaweedfs)与关系型数据库优劣势分析/","excerpt":"","text":"问题引入经过一段时间的学习，想要把openstack-swift与seaweedfs进行结合，单纯考虑文件存储效率，对比把openstack-swift与seaweedfs进行结合后的存储效率是否会高于openstack-swift.问题最后可以简化为文件合并存储与单个存储优劣势比较. 具体分析文件单个存储从Linux内核文件系统出发,以ext3为例,参考深入解析Linux内核I/O剖析（open,write实现）,do_filp_open函数,Ext3文件系统读写过程分析当用户执行文件读写操作时,首先需要open相应的文件，然后再进行读写操作。在open操作时，首先将用户空间的文件名参数复制到内核空间,Linux kernel会执行do_filp_open函数,在do_filp_open函数中,沿着要打开文件名的整个路径，一层层解析路径，最后得到文件的dentry和vfsmount对象，保存到一个nameidata结构中,根据获得的nameidata结构，初始化一个file对象描述这个文件,File对象和文件的dentry和inode对象建立联系，并且将ext3的文件操作方法、映射处理方法（address space）注册到file对象中。File数据结构是Linux用来描述文件的关键数据结构，该对象在一个文件被进程打开的时候被创建。当一个文件被关闭的时候，file对象也会被立即销毁。执行open的最终结果:将文件描述符fd与文件管理结构file对应起来 文件合并存储文件读写是,若文件没有关闭,只需进行一次open操作,直接以lseek为例,参考linux内核文件IO的系统调用实现分析(flseek&amp;close),使用lseek,设置文件开始读取的位置,当调用read或write时直接从该位置读取数据. 结论 存储方式 优势 劣势 文件单个存储 存储过程简单,进行读写时直接进行读取,不需要进行lseek 容易产生页面空洞,导致磁盘扇区利用率降低,大量的文件,会增加文件系统需要维护的inode及dentry,降低文件存储效率. 合并存储 多个文件合并存储,减少文件系统需要维护的inode及dentry,文件连续写入,提高扇区利用率 文件读写时,需要进行lseek,增加文件偏移量查找操作 总结对于大规模存储系统,若能把大文件与小文件进行分开存储,大文件采用单文件存储,小文件使用合并存储,理论上可以提高系统存储效率.可以把openstack-swift与seaweedfs的存储部分进行结合,优化openstack-swift对象存储效率.","raw":null,"content":null,"categories":[{"name":"文件系统","slug":"文件系统","permalink":"https://Caden16.github.io/categories/文件系统/"}],"tags":[{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"},{"name":"文件系统","slug":"文件系统","permalink":"https://Caden16.github.io/tags/文件系统/"}]},{"title":"数据结构","slug":"数据结构","date":"2017-02-07T00:00:00.000Z","updated":"2017-03-19T09:45:44.501Z","comments":true,"path":"数据结构/数据结构/","link":"","permalink":"https://Caden16.github.io/数据结构/数据结构/","excerpt":"","text":"二叉树遍历数据结构（六）——二叉树 前序、中序、后序、层次遍历及非递归实现 查找、统计个数、比较、求深度的递归实现前序遍历：根节点-&gt;左子树-&gt;右子树中序遍历：左子树-&gt;根节点-&gt;右子树后序遍历：左子树-&gt;右子树-&gt;根节点 简单清晰的B树、Trie树详解简单清晰的B树、Trie树详解 跳表 SkipList在leveldb、redis中, 为了提高数据的查找效率,使用了SkipList,参考SkipList跳表基本原理, 跳表SkipList","raw":null,"content":null,"categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://Caden16.github.io/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://Caden16.github.io/tags/数据结构/"}]},{"title":"python语法记录","slug":"python语法记录","date":"2017-02-07T00:00:00.000Z","updated":"2017-04-18T09:01:31.886Z","comments":true,"path":"python语法/python语法记录/","link":"","permalink":"https://Caden16.github.io/python语法/python语法记录/","excerpt":"","text":"记录一下忘记的Python语法 StringIO负责在内存中读写string,其中在openstack-swift的mem_diskfile.py中提到::param fp: StringIO in-memory representation objectStringIO和BytesIO os.fstat()os.fstat() 方法用于返回文件描述符fd的状态，类似 stat()。Python os.fstat() 方法 struct.pack参考Python学习——struct模块的pack、unpack示例struct.pack用于将Python的值根据格式符，转换为字符串（因为Python中没有字节 (Byte)类型，可以把这里的字符串理解为字节流，或字节数组）。其函数原型为：struct.pack(fmt, v1, v2, …)1234import struct a = 20b = 400str = struct.pack(&quot;ii&quot;, a, b) # /x14/x00/x00/x00/x90/x01/x00/x00 转换后的str虽然是字符串类型，但相当于其他语言中的字节流（字节数组），可以在网络上传输.格式符”i”表示转换为int，’ii’表示有两个int变量。进行转换后的结果长度为8个字节（int类型占用4个字节，两个int为8个字 节），可以看到输出的结果是乱码，因为结果是二进制数据，所以显示为乱码。可以使用python的内置函数repr来获取可识别的字符串，其中十六进制的 0x00000014, 0x00001009分别表示20和400。 struct.unpackstruct.unpack做的工作刚好与struct.pack相反，用于将字节流转换成python数 据类型。它的函数原型为：struct.unpack(fmt, string)，该函数返回一个元组。12345678struct.pack(&quot;ii&quot;, 20, 400) a1, a2 = struct.unpack(&quot;ii&quot;, str) print &apos;a1:&apos;, a1 print &apos;a2:&apos;, a2 #---- result: #a1: 20 #a2: 400 repr()参考Python中的repr()函数Python 有办法将任意值转为字符串：将它传入repr() 或str() 函数。函数str() 用于将值转化为适于人阅读的形式，而repr() 转化为供解释器读取的形式。repr（）函数得到的字符串通常可以用来重新获得该对象，repr（）的输入对python比较友好。通常情况下obj==eval(repr(obj))这个等式是成立的。 enumerate参考python enumerate用法总结如果对一个列表，既要遍历索引又要遍历元素时,可利用enumerate.123list1 = [\"这\", \"是\", \"一个\", \"测试\"]for index, item in enumerate(list1): print index, item 还可以接收第二个参数，用于指定索引起始值.要统计文件的行数，可以这样写：123count = -1for index, line in enumerate(open(filepath,&apos;r&apos;))： count += 1 @ decorator这个符号用于装饰器中，用于修饰一个函数，把被修饰的函数作为参数传递给装饰器，参考Python的@符号@classmethod和@staticmethod这两个含义很明显，在定义方法的时候@classmethod表示该方法是类方法,类方法必须有一个参数为cls,表示类本身，实例方法的第一个参数是self.@staticmethod修饰的方法基本上和一个全局函数相同。这两个修饰的方法通过实例和类调用都是可以的 如何在某.py文件中调用其他.py内的函数参考如何在某.py文件中调用其他.py内的函数若A.py和B.py位于不同的目录下，可以用以下方法 引用所在路径 12345import syssys.path.append('D:/')import Bif __name__==\"__main__\": print B.pr(x,y) 使用imp 12345import impB=imp.load_source('B','D:/B.py')import Bif __name__==\"__main__\": print B.pr(x,y) Python capitalize()方法参考Python capitalize()方法capitalize()方法返回字符串的一个副本，只有它的第一个字母大写。对于8位的字符串，这个方法与语言环境相关。下面的示例演示了capitalize方法的使用。123#!/usr/bin/pythonstr = &quot;this is string example....wow!!!&quot;;print &quot;str.capitalize() : &quot;, str.capitalize() 当我们运行上面的程序，它会产生以下结果：1str.capitalize() : This is string example....wow!!! Python两个内置函数——locals 和globals (学习笔记)参考Python两个内置函数——locals 和globals (学习笔记)每个函数都有着自已的名字空间，叫做局部名字空间，它记录了函数的变量，包括函数的参数和局部定义的变量。每个模块拥有它自已的名字空间，叫做全局名字空间，它记录了模块的变量，包括函数、类、其它导入的模块、模块级的变量和常量。还有就是内置名字空间，任何模块均可访问它，它存放着内置的函数和异常。123456789101112def foo(arg, a): x = 1 y = &apos;xxxxxx&apos; for i in range(10): j = 1 k = i print locals() #调用函数的打印结果 foo(1,2) #&#123;&apos;a&apos;: 2, &apos;i&apos;: 9, &apos;k&apos;: 9, &apos;j&apos;: 1, &apos;arg&apos;: 1, &apos;y&apos;: &apos;xxxxxx&apos;, &apos;x&apos;: 1&#125; locals 是只读的，globals 不是 python 列表切片切片的下标0代表顺序的第一个元素，-1代表倒序的第一个元素；且切片不包括右边界，例如[0:3]代表元素0、1、2不包括312345l=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,5]&gt;&gt;&gt; l[0:3][&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]&gt;&gt;&gt; l[:3][&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] all参考用 all 暴露接口用 all 暴露接口,如:12345678import osimport sys__all__ = [\"process_xxx\"] # 排除了 `os` 和 `sys`def process_xxx(): pass # omit 如果显式声明了 all，import * 就只会导入 all 列出的成员。如果 all 定义有误，列出的成员不存在，还会明确地抛出异常，而不是默默忽略。","raw":null,"content":null,"categories":[{"name":"python语法","slug":"python语法","permalink":"https://Caden16.github.io/categories/python语法/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"}]},{"title":"ubuntu16.04搭建openstack-swift单机开发环境","slug":"ubuntu16.04搭建openstack-swift单机开发环境","date":"2017-01-30T00:00:00.000Z","updated":"2017-02-25T09:07:08.089Z","comments":true,"path":"对象存储/ubuntu16.04搭建openstack-swift单机开发环境/","link":"","permalink":"https://Caden16.github.io/对象存储/ubuntu16.04搭建openstack-swift单机开发环境/","excerpt":"","text":"使用虚拟机进行远程调试电脑太卡，用着不爽，所以搭建单机板环境，按照SAIO搭建,在Ubuntu14.04上搭建没有啥问题，但在Ubuntu16.04上会出现问题，记录一下。 出现问题1123456789101112Traceback (most recent call last): File \"/usr/local/bin/swift-object-server\", line 6, in &lt;module&gt; exec(compile(open(__file__).read(), __file__, 'exec')) File \"/home/ubuntu/swift/bin/swift-object-server\", line 19, in &lt;module&gt; from swift.common.wsgi import run_wsgi File \"/home/ubuntu/swift/swift/common/wsgi.py\", line 41, in &lt;module&gt; from swift.common.storage_policy import BindPortsCache File \"/home/ubuntu/swift/swift/common/storage_policy.py\", line 25, in &lt;module&gt; from pyeclib.ec_iface import ECDriver, ECDriverError, VALID_EC_TYPES File \"/usr/local/lib/python2.7/dist-packages/pyeclib/ec_iface.py\", line 29, in &lt;module&gt; from pyeclib_c import check_backend_availableImportError: /usr/local/lib/python2.7/dist-packages/pyeclib_c.so: undefined symbol: liberasurecode_backend_available 系统找不到liberasurecode_backend_available。 解决方法参考openstack-swift bug反馈，得到解决方法:根据Alex Usov 的回答：Finally got it working. Had to compile liberasurecode from https://github.com/openstack/liberasurecode.git (https://github.com/openstack/liberasu…), add line /usr/local/lib to /etc/ld.so.conf, run ldconfig, and restart openstack-swift-proxy. 具体操作：1234567$ git clone https://github.com/openstack/liberasurecode.git$ cd liberasurecode$ ./autogen.sh$ ./configure$ make$ make test$ sudo make install 在 /etc/ld.so.conf中添加一行：/usr/local/lib运行 ldconfig 创建container失败错误提示: 404Container PUT failed: http://127.0.0.1:8080/v1/AUTH_test/test 404 Not Found [first 60 chars of response] Not FoundThe resource could not be found. 解决方法参考unable to create containers错误出现原因: 删除了相关存储文件夹,即/mnt/sdb1 或 /srv 中相关文件夹,按照SAIO - Swift All In One重新搭建环境即可 502 Server dropped connection发起请求时出现502错误:12$ swift statAuth GET failed: http://127.0.0.1:8080/auth/v1.0 502 Server dropped connection [first 60 chars of response] &lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//E 解决方法:把代理关掉","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"openstack-swift调试","slug":"openstack-swift调试","date":"2017-01-21T00:00:00.000Z","updated":"2017-01-29T14:29:46.391Z","comments":true,"path":"对象存储/openstack-swift调试/","link":"","permalink":"https://Caden16.github.io/对象存储/openstack-swift调试/","excerpt":"","text":"最近在学习openstack-swift的源码，想通过调试的方式弄清楚它的运行方式，记录一下，提高一下效率。 启用调试按照swift all in one的方式搭建，没遇到啥问题。调试的方案有两种（都支持远程调试），一种是采用pydev,这种方式需要禁用swift的多线程；另一种采用winpdb，这种方式支持多线程。禁用多线程：1eventlet.patcher.monkey_patch(all=False, socket=True, time=True, thread=False) 使用pydevd调试 我主要采用pycharm + pydevd + NFS的方式远程调试，具体操作参照这两篇文章：openstack调试远程调试其实只要使用NFS把代码挂载到本地，在pycharm中设置远程调试，代码中加入断点即可。加入断点代码 12import pydevdpydevd.settrace(&lt;pycharm所在机子IP&gt;, 设置端口, stdoutToServer=True, stderrToServer=True) 使用winpdb调试在代码中加入断点 12import rpdb2rpdb2.start_embedded_debugger(&apos;12345&apos;,fAllowRemote=True) start_embedded_debugger第一个参数为密码，在winpdb中attach时输入，第二个参数启用远程调试，启用远程调试时，在远程调试的机子上启动winpdb，attach时输入密码，并输入swift部署机子IP即可。 总结我喜欢用方式一，可以把调试的信息直接标注在代码旁。方式二支持分布式调试，但太轻量化，只能看，不能添加，各有优缺点，按需选择。修改代码后需要重启swift才能生效。调试记录信息会放到github上，github地址","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://Caden16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://Caden16.github.io/tags/openstack-swift/"}]},{"title":"linux文件存储机制","slug":"linux文件存储机制","date":"2017-01-21T00:00:00.000Z","updated":"2017-04-01T08:54:53.099Z","comments":true,"path":"文件存储/linux文件存储机制/","link":"","permalink":"https://Caden16.github.io/文件存储/linux文件存储机制/","excerpt":"","text":"参考:Linux 内核的文件 Cache 管理机制介绍从内核文件系统看文件读写过程Linux基础：文件系统分布式存储系统 知识体系Ext2 文件系统的数据访问方式:假设一个文件的属性和权限信息是存放在 3 号的 inode 上，而文件的实际数据是存放在 1、4、6、11 这四个 block 中，那么当操作系统要访问该文件时，就能据此来排列磁盘的阅读顺序，可以扫描一次就将 4 个 block 内容读出来。这种访问方式称为索引式文件系统（indexed allocation）。而且 ext 在每两个文件之间都留有相当巨大的空闲空间。当文件被修改、体积增加时，它们通常有足够的空间来扩展。因此在一定程度上保证了 block 的访问范围不会跨度很大，减小了磁头的移动距离。那 Windows 的文件系统是怎样的呢？ 我们以 FAT 为例说明。在往 FAT 文件系统中存入一个文件时，系统会尽量存放在靠近磁盘开始的地方。当你存入第二个文件时，它会紧挨着第一个文件。当进行频繁的删除修改后，block 就会分散的特别厉害。FAT 文件系统没有 inode 的存在，所以不能一下子将文件的所有 block 在一开始就读取出来。每个 block 号码都记录在前一个 block 当中，形成一个 block 链。当我们需要读取文件的时候，就必须一个一个地将 block 读出，例如上图的读出顺序为 1、6、3、12 。这就会导致磁头无法在磁盘转一圈就获得所有数据，有时候需要来回转好几圈才能读取到这个文件，导致文件读取性能极差。这就是 Windows 经常需要碎片整理的原因——使离散的数据汇合在一起 而 NTFS 文件系统虽然智能了一点，在文件周围分配了一些“缓冲”的空间，但经过一段时间的使用后， NTFS 文件系统还是会形成碎片。由于 ext 是索引式文件系统，所以基本上不太需要经常进行磁盘碎片整理。ext2/ext3 文件系统我们知道文件数据除了文件的实际内容外，通常还包括非常多的属性，例如 Linux 中的文件权限（rwx）和文件属性（拥有者、用户组、时间、大小等）。ext 文件系统将这两部分存放在不同的块，权限和属性存放在 inode 中，至于文件的实际数据则存放在 block 块中。另外还有一个超级块（super block）会记录整个文件系统的整体系统。每个 inode 和 block 都有自己的编号。 ext 文件系统在格式化的时候基本上是区分为多个块组（block group）的，每个块组都有独立的 inode/block/super block 系统。其整体展示图如下所示：其中各个块的含义如下： super block：记录此文件系统的整体系统，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统类型等。file system description：文件系统描述说明。描述每个 block group 的开始与结束的 block 号码。block bitmap：块对照表。用来快速寻找可用的 block 块。inode bitmap：inode对照表。用来快速寻找可用的 inode 块。inode table：存放 inode 块的地方。它们是文件系统的关键。记录了文件的属性，一个文件占用一个 inode，同时包含多个指针，指向了属于该文件的各个 data block 块data block：真正存放数据的地方。文件太大会占用多个 block 。","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/tags/文件存储/"},{"name":"linux","slug":"linux","permalink":"https://Caden16.github.io/tags/linux/"}]},{"title":"kafka学习笔记","slug":"kafka学习笔记","date":"2017-01-11T00:00:00.000Z","updated":"2017-01-21T11:58:44.205Z","comments":true,"path":"kafka/kafka学习笔记/","link":"","permalink":"https://Caden16.github.io/kafka/kafka学习笔记/","excerpt":"","text":"学习资源kafka入门介绍 学习目的构建日志流处理系统，初步实现使用logstash进行日志采集，kafka作为缓存队列，flink进行实时数据分析处理，seaweedfs作为后端存储。 笔记核心API类型应用程序使用 Producer API 发布消息到1个或多个topic（主题）。应用程序使用 Consumer API 来订阅一个或多个topic，并处理产生的消息。应用程序使用 Streams API 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。Connector API允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。 基本术语Topic Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).Producer 发布消息的对象称之为主题生产者(Kafka topic producer)Consumer 订阅消息并处理发布的消息的种子的对象称之为主题消费者(consumers)Broker 已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。 消费者通常来讲，消息模型可以分为两种， 队列和发布-订阅式。 队列的处理方式是 一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。在发布-订阅模型中，消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。Kafka为这两种模型提供了单一的消费者抽象模型： 消费者组 （consumer group）。 消费者用一个消费者组名标记自己。 一个发布在Topic上消息被分发给此消费者组中的一个消费者。 假如所有的消费者都在一个组中，那么这就变成了queue模型。 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 kafka有比传统的消息系统更强的顺序保证如果多个消费者从队列消费，则服务器按存储的顺序发送消息，但是，尽管服务器按顺序发送，消息异步传递到消费者，因此消息可能乱序到达消费者。kafka通过并行topic的parition —— kafka提供了顺序保证和负载均衡。每个partition仅由同一个消费者组中的一个消费者消费到。并确保消费者是该partition的唯一消费者，并按顺序消费数据。每个topic有多个分区，则需要对多个消费者做负载均衡，但请注意，相同的消费者组中不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息。 kafka可作为存储系统","raw":null,"content":null,"categories":[{"name":"kafka","slug":"kafka","permalink":"https://Caden16.github.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://Caden16.github.io/tags/kafka/"}]},{"title":"linux内核学习-数据结构","slug":"linux内核学习-数据结构","date":"2017-01-04T00:00:00.000Z","updated":"2017-01-21T13:35:37.846Z","comments":true,"path":"linux内核/linux内核学习-数据结构/","link":"","permalink":"https://Caden16.github.io/linux内核/linux内核学习-数据结构/","excerpt":"","text":"container_of用于从包含在某个结构中的指针获得结构本身的指针，通俗地讲就是通过结构体变量中某个成员的首地址进而获得整个结构体变量的首地址。Linux内核中的常用宏container_of其实很简单 linux内核Hash 链表Linux内核哈希表分析与应用 Hash应用:有一个庞大的字符串数组，然后给你一个单独的字符串，让你从这个数组中查找是否有这个字符串并找到它暴雪公司关于字符串匹配的hash算法 典型的应用场景(Hbase，Accumulo，Leveldb)：某些存储系统的设计中，会存在空查询缺陷：当查询一个不存在的key时，需要访问慢设备，导致效率低下。比如一个前端页面的缓存系统，可能这样设计：先查询某个页面在本地是否存在，如果存在就直接返回，如果不存在，就从后端获取。但是当频繁从缓存系统查询一个页面时，缓存系统将会频繁请求后端，把压力导入后端。这是只要增加一个bloom算法的服务，后端插入一个key时，在这个服务中设置一次需要查询后端时，先判断key在后端是否存在，这样就能避免后端的压力。布隆过滤器(Bloom Filter)详解算法学习 - Bloom Filter(布隆过滤器)学习实现(C++实现) RadixTree（基数树）应用：Linux radix树最广泛的用途是用于内存管理，结构address_space通过radix树跟踪绑定到地址映射上的核心页，该radix树允许内存管理代码快速查找标识为dirty或writeback的页。其使用的是数据类型unsigned long的固定长度输入的版本。每级代表了输入空间固定位数。Linux radix树的API函数在lib/radix-tree.c中实现。（把页指针和描述页状态的结构映射起来，使能快速查询一个页的信息。）RadixTree（基数树）","raw":null,"content":null,"categories":[{"name":"linux内核","slug":"linux内核","permalink":"https://Caden16.github.io/categories/linux内核/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://Caden16.github.io/tags/数据结构/"},{"name":"linux","slug":"linux","permalink":"https://Caden16.github.io/tags/linux/"},{"name":"内核","slug":"内核","permalink":"https://Caden16.github.io/tags/内核/"}]},{"title":"ELKStack搭建问题总结","slug":"ELKStack搭建问题总结","date":"2017-01-02T00:00:00.000Z","updated":"2017-01-02T15:58:17.559Z","comments":true,"path":"ELKStack/ELKStack搭建问题总结/","link":"","permalink":"https://Caden16.github.io/ELKStack/ELKStack搭建问题总结/","excerpt":"","text":"使用Docker搭建ELKStack时,elasticsearch自动退出,使用1docker logs [dockerName] 问题查看日志, 日志输出为12ERROR: bootstrap checks failedmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案Elasticsearch5.0 安装问题集锦 切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置： vm.max_map_count=655360 并执行命令： sysctl -p 然后，重新启动elasticsearch，即可启动成功。","raw":null,"content":null,"categories":[{"name":"ELKStack","slug":"ELKStack","permalink":"https://Caden16.github.io/categories/ELKStack/"}],"tags":[{"name":"ELKStack","slug":"ELKStack","permalink":"https://Caden16.github.io/tags/ELKStack/"},{"name":"日志分析","slug":"日志分析","permalink":"https://Caden16.github.io/tags/日志分析/"},{"name":"流处理","slug":"流处理","permalink":"https://Caden16.github.io/tags/流处理/"}]},{"title":"linux命令学习","slug":"linux命令学习","date":"2017-01-02T00:00:00.000Z","updated":"2017-04-24T12:29:32.739Z","comments":true,"path":"linux命令/linux命令学习/","link":"","permalink":"https://Caden16.github.io/linux命令/linux命令学习/","excerpt":"","text":"虽然使用linux有很长一段时间,但对于一些平时用不到的命令,还是比较生疏,记录一下 awkAWK是一种处理文本文件的语言，是一个强大的文本分析工具。awk使用介绍awk print 学习 sort用于排序linux之sort用法 uniq报告或删除文件中重复的行。linux uniq 命令详解 tee读取标准输入的数据，并将其内容输出成文件linux tee 命令详解 /dev/null可以把/dev/null看作一个”黑洞”，它非常等价于一个只写文件，所有写入它的内容都会永远丢失。linux下/dev/null的用途Linux下” &gt;/dev/null 2&gt;&amp;1 “相关知识说明 nohup程序后台运行,如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令.命令格式 : nohup command &amp;linux nohup命令详解 screenscreen 算是 linux 运维一个中高级技巧。通过 screen 命令创建的环境下运行的终端命令，其父进程不是 sshd 登录会话，而是 screen 。这样就可以即避免用户退出进程消失的问题，又随时能重新接管回终端继续操作。创建独立的 screen 命令如下：screen -dmS elkscreen_1接管连入创建的 elkscreen_1 命令如下：screen -r elkscreen_1然后你可以看到一个一模一样的终端，运行 logstash 之后，不要按 Ctrl+C，而是按 Ctrl+A+D 键，断开环境。想重新接管，依然 screen -r elkscreen_1 即可。如果创建了多个 screen，查看列表命令如下：screen -list需要长期后台运行的大量程序,使用daemontools xargs参考管道命令和xargs的区别(经典解释)管道是实现“将前面的标准输出作为后面的标准输入”xargs是实现“将标准输入作为命令的参数”运行:12echo &quot;--help&quot;|catecho &quot;--help&quot;|xargs cat 得到结果:123456789101112131415161718192021222324252627282930ubuntu@ubuntu-Aspire-V3-571G:~$ echo &quot;--help&quot;|cat--helpubuntu@ubuntu-Aspire-V3-571G:~$ echo &quot;--help&quot;|xargs cat用法：cat [选项]... [文件]...Concatenate FILE(s) to standard output.如果没有指定文件，或者文件为&quot;-&quot;，则从标准输入读取。 -A, --show-all equivalent to -vET -b, --number-nonblank number nonempty output lines, overrides -n -e equivalent to -vE -E, --show-ends display $ at end of each line -n, --number number all output lines -s, --squeeze-blank suppress repeated empty output lines -t 与-vT 等价 -T, --show-tabs 将跳格字符显示为^I -u (被忽略) -v, --show-nonprinting 使用^ 和M- 引用，除了LFD和 TAB 之外 --help 显示此帮助信息并退出 --version 显示版本信息并退出示例： cat f - g 先输出f 的内容，然后输出标准输入的内容，最后输出g 的内容。 cat 将标准输入的内容复制到标准输出。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告cat 的翻译错误Full documentation at: &lt;http://www.gnu.org/software/coreutils/cat&gt;or available locally via: info &apos;(coreutils) cat invocation&apos;ubuntu@ubuntu-Aspire-V3-571G:~$ sed批量替换字符串,如:1find /etc/swift/ -name \\*.conf | xargs sudo sed -i &quot;s/&lt;your-user-name&gt;/$&#123;USER&#125;/&quot; 把/etc/swift/文件夹下 *.conf 文件中的批量替换为计算机用户名参考linux sed 批量替换字符串 找出占用端口的程序netstat -ap | grep 8080lsof i:8080 linux 查看目录下所有文件(包含子文件夹)ls -aR","raw":null,"content":null,"categories":[{"name":"linux命令","slug":"linux命令","permalink":"https://Caden16.github.io/categories/linux命令/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://Caden16.github.io/tags/linux/"}]},{"title":"linux学习-linux文件存储","slug":"linux学习-linux文件存储","date":"2017-01-01T00:00:00.000Z","updated":"2017-04-04T14:11:08.565Z","comments":true,"path":"文件存储/linux学习-linux文件存储/","link":"","permalink":"https://Caden16.github.io/文件存储/linux学习-linux文件存储/","excerpt":"","text":"linux文件存储一直对文件存储过程不太理解,估计是操作系统没学好,今天看了这篇文章Linux文件存储结构，包括目录项、inode、数据块,感觉思路一下子清晰了. 根据linux一切皆文件的思想,目录项也作为一个文件存储,存储的内容为inode和文件名. linux文件查找文件系统中的目录查找Linux中文件名解析处理源码分析 linux 文件seek效率问题参考How to estimate the seek speed in file system 纠删码参考Erasure Coding（纠删码）深入分析小文件大问题——海量小文件解决方案初探","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://Caden16.github.io/tags/linux/"}]},{"title":"seaweedfs源码阅读记录9-生成fid过程","slug":"seaweedfs源码阅读记录9-生成fid过程","date":"2016-12-16T00:00:00.000Z","updated":"2016-12-16T14:27:23.010Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录9-生成fid过程/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读记录9-生成fid过程/","excerpt":"","text":"使用命令 : curl -X POST http://localhost:9333/dir/assign 在topology.go 中12345678func (t *Topology) PickForWrite(count uint64, option *VolumeGrowOption) (string, uint64, *DataNode, error) &#123;truevid, count, datanodes, err := t.GetVolumeLayout(option.Collection, option.ReplicaPlacement, option.Ttl).PickForWrite(count, option)trueif err != nil || datanodes.Length() == 0 &#123;truetruereturn \"\", 0, nil, errors.New(\"No writable volumes available!\")true&#125;truefileId, count := t.Sequence.NextFileId(count) // fileId = 1050682, count = 1truereturn storage.NewFileId(*vid, fileId, rand.Uint32()).String(), count, datanodes.Head(), nil //调用file_id.go中的NewFileId函数&#125; 在file_id.go 中123456789type FileId struct &#123;trueVolumeId VolumeIdtrueKey uint64 // fileId = 1050682trueHashcode uint32 // rand.Uint32()&#125;func NewFileId(VolumeId VolumeId, Key uint64, Hashcode uint32) *FileId &#123;truereturn &amp;FileId&#123;VolumeId: VolumeId, Key: Key, Hashcode: Hashcode&#125;&#125; 使用memory_sequencer.go中的函数1234567func (m *MemorySequencer) NextFileId(count uint64) (uint64, uint64) &#123; // count = 1truem.sequenceLock.Lock()truedefer m.sequenceLock.Unlock()trueret := m.countertruem.counter += uint64(count)truereturn ret, count&#125; 调试信息1234(dlv) p m*github.com/chrislusf/seaweedfs/weed/sequence.MemorySequencer &#123;truecounter: 1050683,truesequenceLock: sync.Mutex &#123;state: 1, sema: 0&#125;,&#125; 在 master_server_handlers.go 中封装信息123456fid, count, dn, err := ms.Topo.PickForWrite(requestedCount, option)trueif err == nil &#123;truetruewriteJsonQuiet(w, r, http.StatusOK, operation.AssignResult&#123;Fid: fid, Url: dn.Url(), PublicUrl: dn.PublicUrl, Count: count&#125;)true&#125; else &#123;truetruewriteJsonQuiet(w, r, http.StatusNotAcceptable, operation.AssignResult&#123;Error: err.Error()&#125;)true&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读8-GET&HEAD获取文件过程","slug":"seaweedfs源码阅读8-GET&HEAD获取文件过程","date":"2016-12-15T00:00:00.000Z","updated":"2016-12-15T12:08:29.759Z","comments":true,"path":"文件存储/seaweedfs源码阅读8-GET&HEAD获取文件过程/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读8-GET&HEAD获取文件过程/","excerpt":"","text":"GET 文件请求1http://127.0.0.1:8080/27542,10088ee11dccb9 先生成一个新的needle,然后根据fid:10088ee11dccb9 , 其中,前8位使用16进制转换为uint64 ==&gt; key, 后6位使用16进制转换为uint32 ==&gt; hash,解析结果给新生成的needle赋值,n.Id=key, n.Cookie=hash 如果当前的volumeServer没有找到请求的volumeId123456789101112131415161718192021222324if !vs.store.HasVolume(volumeId) &#123;truetrueif !vs.ReadRedirect &#123;truetruetrueglog.V(2).Infoln(\"volume is not local:\", err, r.URL.Path)truetruetruew.WriteHeader(http.StatusNotFound)truetruetruereturntruetrue&#125;truetruelookupResult, err := operation.Lookup(vs.GetMasterNode(), volumeId.String())truetrueglog.V(2).Infoln(\"volume\", volumeId, \"found on\", lookupResult, \"error\", err)truetrueif err == nil &amp;&amp; len(lookupResult.Locations) &gt; 0 &#123;truetruetrueu, _ := url.Parse(util.NormalizeUrl(lookupResult.Locations[0].PublicUrl))truetruetrueu.Path = r.URL.Pathtruetruetruearg := url.Values&#123;&#125;truetruetrueif c := r.FormValue(\"collection\"); c != \"\" &#123;truetruetruetruearg.Set(\"collection\", c)truetruetrue&#125;truetruetrueu.RawQuery = arg.Encode()truetruetruehttp.Redirect(w, r, u.String(), http.StatusMovedPermanently)truetrue&#125; else &#123;truetruetrueglog.V(2).Infoln(\"lookup error:\", err, r.URL.Path)truetruetruew.WriteHeader(http.StatusNotFound)truetrue&#125;truetruereturntrue&#125; 在volume_read_write.go 中,调用readNeedle,通过已知的n.Id ,获取存储的needle信息,操作在needle_map_memory.go 中1234func (nm *NeedleMap) Get(key uint64) (element *NeedleValue, ok bool) &#123;trueelement, ok = nm.m.Get(Key(key))truereturn&#125; 12(dlv) p element*github.com/chrislusf/seaweedfs/weed/storage.NeedleValue &#123;Key: 1050766, Offset: 1, Size: 529810&#125; 与上传信息对比上传时返回信息:{“fid”:”27542,10088ee11dccb9”,”fileName”:”raft.pdf”,”fileUrl”:”127.0.0.1:8080/27542,10088ee11dccb9”,”size”:529766}此时信息{Key: 1050766, Offset: 1, Size: 529810}存储时以needle为单位,增加的大小为needle中其他数据的大小,如n.Id,n.Cookie 获取数据123456789101112131415161718192021222324252627func (n *Needle) ReadData(r *os.File, offset int64, size uint32, version Version) (err error) &#123;truebytes, block, err := ReadNeedleBlob(r, offset, size)trueif err != nil &#123;truetruereturn errtrue&#125;truen.rawBlock = blocktruen.ParseNeedleHeader(bytes)trueif n.Size != size &#123;truetruereturn fmt.Errorf(\"File Entry Not Found. Needle %d Memory %d\", n.Size, size)true&#125;trueswitch version &#123;truecase Version1:truetruen.Data = bytes[NeedleHeaderSize : NeedleHeaderSize+size]truecase Version2:truetruen.readNeedleDataVersion2(bytes[NeedleHeaderSize : NeedleHeaderSize+int(n.Size)]) // 从bytes中读取存储数据,并设置needle的属性true&#125;trueif size == 0 &#123;truetruereturn niltrue&#125;truechecksum := util.BytesToUint32(bytes[NeedleHeaderSize+size : NeedleHeaderSize+size+NeedleChecksumSize])truenewChecksum := NewCRC(n.Data)trueif checksum != newChecksum.Value() &#123;truetruereturn errors.New(\"CRC error! Data On Disk Corrupted\")true&#125;truen.Checksum = newChecksumtruereturn nil&#125; 123456789101112131415161718192021222324252627282930313233343536func (n *Needle) readNeedleDataVersion2(bytes []byte) &#123;trueindex, lenBytes := 0, len(bytes)trueif index &lt; lenBytes &#123;truetruen.DataSize = util.BytesToUint32(bytes[index : index+4])truetrueindex = index + 4truetrueif int(n.DataSize)+index &gt; lenBytes &#123;truetruetrue// this if clause is due to bug #87 and #93, fixed in v0.69truetruetrue// remove this clause latertruetruetruereturntruetrue&#125;truetruen.Data = bytes[index : index+int(n.DataSize)]truetrueindex = index + int(n.DataSize)truetruen.Flags = bytes[index]truetrueindex = index + 1true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasName() &#123;truetruen.NameSize = uint8(bytes[index])truetrueindex = index + 1truetruen.Name = bytes[index : index+int(n.NameSize)]truetrueindex = index + int(n.NameSize)true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasMime() &#123;truetruen.MimeSize = uint8(bytes[index])truetrueindex = index + 1truetruen.Mime = bytes[index : index+int(n.MimeSize)]truetrueindex = index + int(n.MimeSize)true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasLastModifiedDate() &#123;truetruen.LastModified = util.BytesToUint64(bytes[index : index+LastModifiedBytesLength])truetrueindex = index + LastModifiedBytesLengthtrue&#125;trueif index &lt; lenBytes &amp;&amp; n.HasTtl() &#123;truetruen.Ttl = LoadTTLFromBytes(bytes[index : index+TtlBytesLength])truetrueindex = index + TtlBytesLengthtrue&#125;&#125; 总结根据请求URL中带有的fid, 解析,得到n.Id, n.Cookie,其中,n.Id 作为needle的唯一标识,在NeedleMapper中找到存储的needle信息,n.Cookie 作为数据验证信息,若找到的needle中的cookie于URL中的cookie不一致,返回错误信息.","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"go结构体大小","slug":"go结构体大小","date":"2016-12-14T00:00:00.000Z","updated":"2017-04-01T12:29:04.653Z","comments":true,"path":"文件存储/go结构体大小/","link":"","permalink":"https://Caden16.github.io/文件存储/go结构体大小/","excerpt":"","text":"在seaweedfs中,存储数据使用的核心结构体为needle,而对于golang中的结构体,计算它的内存占用大小和C是一样的,会使用内存对齐的方法,计算结构体大小的方式参考Sizeof struct in GoC语言结构体占用空间内存大小解析The size depends on the types it consists of and the order of the fields in the struct (because different padding will be used). This means that two structs with the same fields can have different size. For example this struct will have a size of 3212345struct &#123; a bool b string c bool&#125; and a slight modification will have a size of 24 (a 25% difference just due to a more compact ordering of fields)12345struct &#123; a bool c bool b string&#125; As you see from the pictures, in the second example we removed one of the paddings and moved a field to take advantage of the previous padding. An alignment can be 1, 2, 4, or 8. A padding is the space that was used to fill in the variable to fill the alignment (basically wasted space). Knowing this rule and remembering that: bool, int8/uint8 take 1 chunkint16, uint16 - 2 chunksint32, uint32, float32 - 4 chunksint64, uint64, float64, pointer - 8 chunksstring - 16 chunks (2 alignments of 8 chunks)any slice takes 24 chunks (3 alignments of 8 chunks). So []bool, [][][]string are the same (do not forget to reread the citation I added in the beginning)array of length n takes n * type it takes of chunks. 1234567891011121314151617181920type Needle struct &#123;trueCookie uint32 `comment:\"random number to mitigate brute force lookups\"`trueId uint64 `comment:\"needle id\"`trueSize uint32 `comment:\"sum of DataSize,Data,NameSize,Name,MimeSize,Mime\"`trueDataSize uint32 `comment:\"Data size\"` //version2trueData []byte `comment:\"The actual file data\"`trueFlags byte `comment:\"boolean flags\"` //version2trueNameSize uint8 //version2trueName []byte `comment:\"maximum 256 characters\"` //version2trueMimeSize uint8 //version2trueMime []byte `comment:\"maximum 256 characters\"` //version2trueLastModified uint64 //only store LastModifiedBytesLength bytes, which is 5 bytes to disktrueTtl *TTLtrueChecksum CRC `comment:\"CRC32 to check integrity\"`truePadding []byte `comment:\"Aligned to 8 bytes\"`truerawBlock *Block // underlying supporing []byte, fetched and released into a pool&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读7-文件存储过程","slug":"seaweedfs源码阅读7-文件存储过程","date":"2016-12-13T00:00:00.000Z","updated":"2017-04-01T12:55:01.553Z","comments":true,"path":"文件存储/seaweedfs源码阅读7-文件存储过程/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读7-文件存储过程/","excerpt":"","text":"文件在volume_server_handlers_write.go 中的topology.ReplicatedWrite中以needle的形式存储,在store.go 的Write方法中调用writeNeedle写入文件.写入时使用append的方法,在文件中追加123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111// needle_read_write.gofunc (n *Needle) Append(w io.Writer, version Version) (size uint32, err error) &#123;trueif s, ok := w.(io.Seeker); ok &#123;truetrueif end, e := s.Seek(0, 1); e == nil &#123;truetruetruedefer func(s io.Seeker, off int64) &#123;truetruetruetrueif err != nil &#123;truetruetruetruetrueif _, e = s.Seek(off, 0); e != nil &#123;truetruetruetruetruetrueglog.V(0).Infof(\"Failed to seek %s back to %d with error: %v\", w, off, e)truetruetruetruetrue&#125;truetruetruetrue&#125;truetruetrue&#125;(s, end)truetrue&#125; else &#123;truetruetrueerr = fmt.Errorf(\"Cannot Read Current Volume Position: %v\", e)truetruetruereturntruetrue&#125;true&#125;trueswitch version &#123;truecase Version1:truetrueheader := make([]byte, NeedleHeaderSize)truetrueutil.Uint32toBytes(header[0:4], n.Cookie)truetrueutil.Uint64toBytes(header[4:12], n.Id)truetruen.Size = uint32(len(n.Data))truetruesize = n.Sizetruetrueutil.Uint32toBytes(header[12:16], n.Size)truetrueif _, err = w.Write(header); err != nil &#123;truetruetruereturntruetrue&#125;truetrueif _, err = w.Write(n.Data); err != nil &#123;truetruetruereturntruetrue&#125;truetruepadding := NeedlePaddingSize - ((NeedleHeaderSize + n.Size + NeedleChecksumSize) % NeedlePaddingSize)truetrueutil.Uint32toBytes(header[0:NeedleChecksumSize], n.Checksum.Value())truetrue_, err = w.Write(header[0 : NeedleChecksumSize+padding])truetruereturntruecase Version2:truetrueheader := make([]byte, NeedleHeaderSize)truetrueutil.Uint32toBytes(header[0:4], n.Cookie)truetrueutil.Uint64toBytes(header[4:12], n.Id)truetruen.DataSize, n.NameSize, n.MimeSize = uint32(len(n.Data)), uint8(len(n.Name)), uint8(len(n.Mime))truetrueif n.DataSize &gt; 0 &#123;truetruetruen.Size = 4 + n.DataSize + 1truetruetrueif n.HasName() &#123;truetruetruetruen.Size = n.Size + 1 + uint32(n.NameSize)truetruetrue&#125;truetruetrueif n.HasMime() &#123;truetruetruetruen.Size = n.Size + 1 + uint32(n.MimeSize)truetruetrue&#125;truetruetrueif n.HasLastModifiedDate() &#123;truetruetruetruen.Size = n.Size + LastModifiedBytesLengthtruetruetrue&#125;truetruetrueif n.HasTtl() &#123;truetruetruetruen.Size = n.Size + TtlBytesLengthtruetruetrue&#125;truetrue&#125; else &#123;truetruetruen.Size = 0truetrue&#125;truetruesize = n.DataSizetruetrueutil.Uint32toBytes(header[12:16], n.Size)truetrueif _, err = w.Write(header); err != nil &#123;truetruetruereturntruetrue&#125;truetrueif n.DataSize &gt; 0 &#123;truetruetrueutil.Uint32toBytes(header[0:4], n.DataSize)truetruetrueif _, err = w.Write(header[0:4]); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueif _, err = w.Write(n.Data); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueutil.Uint8toBytes(header[0:1], n.Flags)truetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueif n.HasName() &#123;truetruetruetrueutil.Uint8toBytes(header[0:1], n.NameSize)truetruetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetruetrueif _, err = w.Write(n.Name); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasMime() &#123;truetruetruetrueutil.Uint8toBytes(header[0:1], n.MimeSize)truetruetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetruetrueif _, err = w.Write(n.Mime); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasLastModifiedDate() &#123;truetruetruetrueutil.Uint64toBytes(header[0:8], n.LastModified)truetruetruetrueif _, err = w.Write(header[8-LastModifiedBytesLength : 8]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasTtl() &amp;&amp; n.Ttl != nil &#123;truetruetruetruen.Ttl.ToBytes(header[0:TtlBytesLength])truetruetruetrueif _, err = w.Write(header[0:TtlBytesLength]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetrue&#125;truetruepadding := NeedlePaddingSize - ((NeedleHeaderSize + n.Size + NeedleChecksumSize) % NeedlePaddingSize)truetrueutil.Uint32toBytes(header[0:NeedleChecksumSize], n.Checksum.Value())truetrue_, err = w.Write(header[0 : NeedleChecksumSize+padding])truetruereturn n.DataSize, errtrue&#125;truereturn 0, fmt.Errorf(\"Unsupported Version! (%d)\", version)&#125; Weed-FS 的备份实现是强一致性的。 当一个 VolumeServer 接受到上传文件的 POST 请求时， 将该文件作为一个 Needle 写入本地 Volume 之后， 会根据该文件所分配的 VolumeId 判断是否需要备份， 如果需要备份，则进行备份（需要请求另外其它的 VolumeServer 服务器）。 过程详见 ReplicatedWrite (topology/store_replicate.go)。 当备份完毕后，再对该 POST 请求进行答复。 所以用户每次上传图片时，当收到了答复之后， 则可以认为此备份已完成。这个和最终一致性不同，属于强一致性。 上述实现强一致性的过程中， 有个必要条件就是【 VolumeServer 需要知道往其它那些 VolumeServer 备份】。 在 Weed-FS 的实现中是借助 MasterServer 来实现， 因为备份的基本单位是 Volume, 在 MasterServer 中，对每个 VolumeId 都维护对应的备份机器列表。","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读6-文件存储格式","slug":"seaweedfs源码阅读6-文件存储格式","date":"2016-12-12T00:00:00.000Z","updated":"2016-12-13T03:26:44.809Z","comments":true,"path":"文件存储/seaweedfs源码阅读6-文件存储格式/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读6-文件存储格式/","excerpt":"","text":"使用put 上传文件到seaweedfs , 具体显示结果 上传的所有文件都以单个文件进行存储,后缀为 .dat 和 .idx","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读4-volume启动过程","slug":"seaweedfs源码阅读4-volume启动","date":"2016-12-11T00:00:00.000Z","updated":"2017-02-08T12:23:41.872Z","comments":true,"path":"文件存储/seaweedfs源码阅读4-volume启动/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读4-volume启动/","excerpt":"","text":"根据文章使用delve调试Golang程序技巧使用go install -gcflags “-N -l” weed.go 对程序进行重新编译,方便调试 通过weed.go 调用volume.go ,参数处理完成后,生成一个ServeMux实例,有关go http ServeMux介绍,12345volumeMux := http.NewServeMux()publicVolumeMux := volumeMuxif isSeperatedPublicPort &#123;truepublicVolumeMux = http.NewServeMux()&#125; 根据参数VolumeServerOptions 中的 indexType,选择volume Needle Map 的存储位置,默认使用内存1234567volumeNeedleMapKind := storage.NeedleMapInMemoryswitch *v.indexType &#123;case \"leveldb\": volumeNeedleMapKind = storage.NeedleMapLevelDbcase \"boltdb\": volumeNeedleMapKind = storage.NeedleMapBoltDb&#125; 调试信息12(dlv) p *v.indexType\"memory\" 根据参数生成volumeServer,使用volume_server.go 中的NewVolumeServer 生成volumeServer在volume_server.go 中,设置masterNode ,store, guard1234vs.SetMasterNode(masterNode)vs.store = storage.NewStore(port, ip, publicUrl, folders, maxCounts, vs.needleMapKind)vs.guard = security.NewGuard(whiteList, \"\") 生成store时会加载已有的volume123456789101112// store.gofunc NewStore(port int, ip, publicUrl string, dirnames []string, maxVolumeCounts []int, needleMapKind NeedleMapType) (s *Store) &#123;trues = &amp;Store&#123;Port: port, Ip: ip, PublicUrl: publicUrl&#125;trues.Locations = make([]*DiskLocation, 0)truefor i := 0; i &lt; len(dirnames); i++ &#123;truetruelocation := NewDiskLocation(dirnames[i], maxVolumeCounts[i])truetruelocation.loadExistingVolumes(needleMapKind)truetrues.Locations = append(s.Locations, location)true&#125;truereturn&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读5-文件PUT过程","slug":"seaweedfs源码阅读5-文件PUT过程","date":"2016-12-11T00:00:00.000Z","updated":"2016-12-11T13:30:05.384Z","comments":true,"path":"文件存储/seaweedfs源码阅读5-文件PUT过程/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读5-文件PUT过程/","excerpt":"","text":"使用命令1234&gt; curl -X POST http://localhost:9333/dir/assign&#123;\"count\":1,\"fid\":\"3,01637037d6\",\"url\":\"127.0.0.1:8080\",\"publicUrl\":\"localhost:8080\"&#125;&gt; curl -X PUT -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6&#123;\"size\": 43234&#125; 上传文件,程序调用volume_server_handlers_write.go 中的PostHandler进行处理,根据URL,提取vid,生成新的volumeId12vid, _, _, _, _ := parseURLPath(r.URL.Path) //vid 为3volumeId, ve := storage.NewVolumeId(vid) // volumeId : 7 根据请求参数,生成needle1needle, ne := storage.NewNeedle(r, vs.FixJpgOrientation) 使用multipartReader读取请求中的数据,有关multipart的介绍: golang的multipart包使用needle.go 中的ParseUpload方法解析请求,得到上传的文件名和数据;如果上传的数据类型是JPG或jpeg,调用 images.FixJpgOrientation(n.Data)对数据进行处理生成needle过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func NewNeedle(r *http.Request, fixJpgOrientation bool) (n *Needle, e error) &#123;truefname, mimeType, isGzipped, isChunkedFile := \"\", \"\", false, falsetruen = new(Needle)truefname, n.Data, mimeType, isGzipped, n.LastModified, n.Ttl, isChunkedFile, e = ParseUpload(r)trueif e != nil &#123;truetruereturntrue&#125;trueif len(fname) &lt; 256 &#123;truetruen.Name = []byte(fname)truetruen.SetHasName()true&#125;trueif len(mimeType) &lt; 256 &#123;truetruen.Mime = []byte(mimeType)truetruen.SetHasMime()true&#125;trueif isGzipped &#123;truetruen.SetGzipped()true&#125;trueif n.LastModified == 0 &#123;truetruen.LastModified = uint64(time.Now().Unix())true&#125;truen.SetHasLastModifiedDate()trueif n.Ttl != EMPTY_TTL &#123;truetruen.SetHasTtl()true&#125;trueif isChunkedFile &#123;truetruen.SetIsChunkManifest()true&#125;trueif fixJpgOrientation &#123;truetrueloweredName := strings.ToLower(fname)truetrueif mimeType == \"image/jpeg\" || strings.HasSuffix(loweredName, \".jpg\") || strings.HasSuffix(loweredName, \".jpeg\") &#123;truetruetruen.Data = images.FixJpgOrientation(n.Data)truetrue&#125;true&#125;truen.Checksum = NewCRC(n.Data)truecommaSep := strings.LastIndex(r.URL.Path, \",\")truedotSep := strings.LastIndex(r.URL.Path, \".\")truefid := r.URL.Path[commaSep+1:]trueif dotSep &gt; 0 &#123;truetruefid = r.URL.Path[commaSep+1 : dotSep]true&#125;truee = n.ParsePath(fid)truereturn&#125; 把数据及needle相关属性填充完成后,同步到其他volumeServer中,已needle作为传输载体1size, errorStatus := topology.ReplicatedWrite(vs.GetMasterNode(),vs.store, volumeId, needle, r)","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"golang调试技巧","slug":"golang调试技巧","date":"2016-12-10T00:00:00.000Z","updated":"2016-12-11T02:52:49.574Z","comments":true,"path":"go/golang调试技巧/","link":"","permalink":"https://Caden16.github.io/go/golang调试技巧/","excerpt":"","text":"在阅读seaweedfs过程中,发现对于复杂程序,跟踪调试相当困难,不过,在看了使用delve调试Golang程序技巧这篇文章后,调试问题得到很好的改善. 首先,liteIDE简直让人眼前一亮,使用它并结合delve实现图形化界面调试,使用命令行多少有点不太方便,特别是当你想在源码中加入注释的时候. 具体实现 安装delve,liteIDE 加入参数关闭编译器优化,如 go install -gcflags “-N -l” 程序名称 按照文章使用delve调试Golang程序技巧, 调试外部程序 调试启动后,可在Console设置断点, 命令为 : b packageName.functionName 或 b lineNum 使用命令c ,运行到断点停止,进行操作,具体命令可参照delve 还不清楚liteIDE能不能使用delve 进行图形化attach,如果可以就非常完美","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"}]},{"title":"golang 反射机制","slug":"golang 反射机制","date":"2016-12-02T00:00:00.000Z","updated":"2016-12-04T07:55:20.022Z","comments":true,"path":"go/golang 反射机制/","link":"","permalink":"https://Caden16.github.io/go/golang 反射机制/","excerpt":"","text":"在阅读seaweedfs过程中,当程序在运行过程中,想要进行跟踪调试不好实现,目前也没找到很好的解决方案,只能跟踪程序的启动过程.不过回归最原始的方法,使用printf倒是可以查看变量的值,因此打算编写程序,把struct中的变量转化为json,发送给搭建的服务器,实现查看struct变量的方法.其中就了解到go的反射机制. laws-of-reflectionGolang之反射reflect包 使用反射可以得到struct中的变量及变量的值,前提是该变量是export的,即首字母大写,类似java中的public.","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"}]},{"title":"golang学习","slug":"golang学习","date":"2016-11-29T00:00:00.000Z","updated":"2016-12-15T03:15:17.470Z","comments":true,"path":"go/golang学习/","link":"","permalink":"https://Caden16.github.io/go/golang学习/","excerpt":"","text":"在看seaweedfs过程中遇到的go 语法,不会的记录一下. interface: 是一组method的组合,通过interface来定义对象的一组行为.12345type Sequencer interface &#123;trueNextFileId(count uint64) (uint64, uint64)trueSetMax(uint64)truePeek() uint64&#125; go map1t.children = make(map[NodeId]Node) // NodeId --&gt; Node go sync.RWMutex和sync.Mutexgolang中sync包实现了两种锁Mutex （互斥锁）和RWMutex（读写锁），其中RWMutex是基于Mutex实现的，只读锁的实现使用类似引用计数器的功能．1234type Mutex func (m *Mutex) Lock() func (m *Mutex) Unlock() Mutex为互斥锁，Lock()加锁，Unlock()解锁，使用Lock()加锁后，便不能再次对其进行加锁，直到利用Unlock()解锁对其解锁后，才能再次加锁．适用于读写不确定场景，即读写次数没有明显的区别，并且只允许只有一个读或者写的场景，所以该锁也叫做全局锁． 123456type RWMutex func (rw *RWMutex) Lock() func (rw *RWMutex) RLock() func (rw *RWMutex) RLocker() Locker func (rw *RWMutex) RUnlock() func (rw *RWMutex) Unlock() func (rw RWMutex) Lock() 写锁，如果在添加写锁之前已经有其他的读锁和写锁，则lock就会阻塞直到该锁可用，为确保该锁最终可用，已阻塞的 Lock 调用会从获得的锁中排除新的读取器，即写锁权限高于读锁，有写锁时优先进行写锁定 func (rw RWMutex) Unlock() 写锁解锁，如果没有进行写锁定，则就会引起一个运行时错误． func (rw *RWMutex) RLock() 读锁，当有写锁时，无法加载读锁，当只有读锁或者没有锁时，可以加载读锁，读锁可以加载多个，所以适用于＂读多写少＂的场景 func (rw *RWMutex)RUnlock() 读锁解锁，RUnlock 撤销单次 RLock 调用，它对于其它同时存在的读取器则没有效果。若 rw 并没有为读取而锁定，调用 RUnlock 就会引发一个运行时错误(注：这种说法在go1.3版本中是不对的，例如下面这个例子)。 go Routine和Channelgo学习笔记_Routine和Channel上 goroutine 类似开辟进程、线程做法语法： 1. 定义一个函数functionName，要异步调用时使用语句go functionName即可。 2. 使用匿名函数，用法为go func(参数列表){函数执行体}()，说明最后一个()作用就是让该函数执行。 代码： 123456789101112131415/////////第一种示例代码：///////////func sayHello(name string)&#123; fmt.Println(\"hello\"+name)&#125;//主程序入口func main()&#123; go sayHello(\"PMST\")&#125;/////////第二种示例代码：////////////主程序入口func main()&#123; go func()&#123; fmt.Println(\"hello world\") &#125;() //别忘记这里的()&#125; 一旦将go放在函数之前，意味分配一个子routine让这个函数自个玩去(有点自身自灭的感觉),而主routine则继续该干嘛干嘛。 channelgoroutine 之间进行数据通信方式： 共用内存内存空间。 Go语言推荐的通信机制channel。 通过make来创建channel,例如无缓存ci := make(chan int),指定缓存cib := make(chan int,2)。给这个通道分类了2个缓存空间 通道的接收和发送都是阻塞的，除非与之对应的一端已经准备好阻塞状态： 数据写入channel（或缓存已满）却没读出 channel中没有数据，读channel会阻塞。 go反引号参考文章:GoLang获取struct的tag123456789type AppendEntriesRequest struct &#123;trueTerm *uint64 `protobuf:\"varint,1,req\" json:\"Term,omitempty\"`truePrevLogIndex *uint64 `protobuf:\"varint,2,req\" json:\"PrevLogIndex,omitempty\"`truePrevLogTerm *uint64 `protobuf:\"varint,3,req\" json:\"PrevLogTerm,omitempty\"`trueCommitIndex *uint64 `protobuf:\"varint,4,req\" json:\"CommitIndex,omitempty\"`trueLeaderName *string `protobuf:\"bytes,5,req\" json:\"LeaderName,omitempty\"`trueEntries []*LogEntry `protobuf:\"bytes,6,rep\" json:\"Entries,omitempty\"`trueXXX_unrecognized []byte `json:\"-\"`&#125; 其中,反引号表示字符串,struct后面的字符串用于reflect,具体用法s := AppendEntriesRequest{}st := reflect.TypeOf(s)field := st.Field(0)field.Tag.Get(“protobuf”) // varint,1,reqfield.Tag.Get(“json”) // Term,omitempty go get 安装程序错误错误提示:123unrecognized import path \"code.google.com/p/goprotobuf/proto\"parse https://code.google.com/p/goprotobuf?go-get=1: no go-import meta tags 错误原因:依赖包已从code.google.com移除, 已重定向到github.com/golang/protobuf/proto,修改程序中的代码即可 strconv.ParseInt(s string, base int, bitSize int) (i int64, err error) 或strconv.ParseUint把字符串转换为整数,参数1 数字的字符串形式 参数2 数字字符串的进制 比如二进制 八进制 十进制 十六进制 参数3 返回结果的bit大小 也就是int8 int16 int32 int64","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"}]},{"title":"seaweedfs源码阅读记录3-raft协议理解","slug":"seaweedfs源码阅读记录3-raft协议理解","date":"2016-11-28T00:00:00.000Z","updated":"2017-03-06T13:17:24.039Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录3-raft协议理解/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读记录3-raft协议理解/","excerpt":"","text":"raft用于seaweedfs的多个master server间进行leader选举,选出leader对其他master server进行管理. 参考文章Raft一致性算法raft动画演示raft介绍go-raft源码解析go-raft文档goraft的简单实现分布式一致性，Raft以及其它 阅读记录本文按照参考文章中的go-raft源码解析中的文章阅读,记录阅读过程.12345678910111213141516// The request sent to a server to append entries to the log.type AppendEntriesRequest struct &#123;trueTerm uint64truePrevLogIndex uint64truePrevLogTerm uint64trueCommitIndex uint64trueLeaderName stringtrueEntries []*protobuf.LogEntry // 定义在protobuf中的LogEntry&#125;// The response returned from a server appending entries to the log.type AppendEntriesResponse struct &#123;truepb *protobuf.AppendEntriesResponsetruepeer stringtrueappend bool&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"},{"name":"raft","slug":"raft","permalink":"https://Caden16.github.io/tags/raft/"}]},{"title":"seaweedfs源码阅读记录1","slug":"seaweedfs源码阅读记录","date":"2016-11-22T00:00:00.000Z","updated":"2017-02-25T11:47:17.603Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读记录/","excerpt":"","text":"接下来的日子都会抽出部分时间学习文件存储,目标是修改openstack-swift的源码,通过源码学习文件存储知识.目前学习对象:seaweedfs. 目标:学习seaweedfs 的文件合并存储文件合并后必然会带来的一堆问题待解决,比如文件索引,响应速率等. 学习方式: google + 调试github 上能找到项目的wiki文档,会介绍简单的使用.调试方案: IDEA/pycharm , 需要结合atom/vscode 的delve调试go程序,各有利弊,结合使用. 测试用命令启动:master : weed master -mdir=/home/ubuntu/weedfsvolume : weed volume -dir=”/home/ubuntu/weedfs/data1” -mserver=”localhost:9333” -port=8080启用目录filter: weed filer -port=8888 -dir=/home/ubuntu/weedfs/filter1 -master=localhost:9333使用:curl -X POST http://localhost:9333/dir/assign 获取fid 参考文章分布式存储Seaweedfs源码分析 tonybai的个人blog weed-fs 源码解读—分布式处理过程 weed-fs 源码解读","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读记录2","slug":"seaweedfs源码阅读记录2","date":"2016-11-22T00:00:00.000Z","updated":"2016-11-28T11:57:03.000Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录2/","link":"","permalink":"https://Caden16.github.io/文件存储/seaweedfs源码阅读记录2/","excerpt":"","text":"master启动过程使用pycharm , 入口为weed.go, 根据参数调用command文件夹下的文件.opology 核心模块，主要包括 【DataCenter, Rack, DataNode】 三层拓扑结构,参考文章： weed-fs 源码解读 12345type Sequencer interface &#123;trueNextFileId(count uint64) (uint64, uint64)trueSetMax(uint64)truePeek() uint64&#125; topology中包含Sequencer , sequence 负责FileID的全局有序生成 12345678910111213141516171819type Topology struct &#123;trueNodeImpl //指向NodeImpl对象，即Topology和node相互指向truecollectionMap *util.ConcurrentReadMaptruepulse int64truevolumeSizeLimit uint64trueSequence sequence.SequencertruechanDeadDataNodes chan *DataNodetruechanRecoveredDataNodes chan *DataNodetruechanFullVolumes chan storage.VolumeInfotrueconfiguration *ConfigurationtrueRaftServer raft.Server&#125; NodeImpl结构1234567891011121314type NodeImpl struct &#123;trueid NodeIdtruevolumeCount inttrueactiveVolumeCount inttruemaxVolumeCount inttrueparent Nodetruesync.RWMutex // lock childrentruechildren map[NodeId]NodetruemaxVolumeId storage.VolumeIdtrue//for rack, data center, topologytruenodeType stringtruevalue interface&#123;&#125; //指向Topology对象，即Topology和node相互指向&#125; DataNode数据结构123456789type DataNode struct &#123;trueNodeImpltruevolumes map[storage.VolumeId]storage.VolumeInfotrueIp stringtruePort inttruePublicUrl stringtrueLastSeen int64 // unix time in secondstrueDead bool&#125; 123456789101112type VolumeInfo struct &#123;trueId VolumeIdtrueSize uint64trueReplicaPlacement *ReplicaPlacementtrueTtl *TTLtrueCollection stringtrueVersion VersiontrueFileCount inttrueDeleteCount inttrueDeletedByteCount uint64trueReadOnly bool&#125; 通过RaftServer的raft协议，完成多个weedmaster间投票选leader的事情,当启动多个ServerMaster时，它们之间会进行通信，通过raft协议选举出一个Leader，对所有的master进行管理。weed-fs中，通过使用raftServer完成上述选举过程；而raftServer则是用到了第三方资源，即goRaft（参照http://ayende.com/blog/165858/reviewing-go-raft-part-i）。12345678type RaftServer struct &#123;truepeers []string // initial peers to join withtrueraftServer raft.Server //使用goraft //type Server interface 包含实现raft的方法truedataDir stringtruehttpAddr stringtruerouter *mux.Routertruetopo *topology.Topology&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://Caden16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://Caden16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://Caden16.github.io/tags/seaweedfs/"}]},{"title":"nodeJS入门总结","slug":"nodeJS入门总结","date":"2016-11-20T00:00:00.000Z","updated":"2016-11-24T14:55:44.836Z","comments":true,"path":"网站相关/nodeJS入门总结/","link":"","permalink":"https://Caden16.github.io/网站相关/nodeJS入门总结/","excerpt":"","text":"刚做完nodeJS的课设,写了个小程序,总结一下 程序功能实现简单的电商网站,能登陆,注册,浏览商品,购物车操作. 使用技术 nodeJS + Express + ejs mongoDB + mongoose bootstrap + jquery (前端页面是在网上找的,随便改了一下) 实现代码github 有关mongoosemongoose实现了把mongodb中的数据进行映射,可以直接使用mongoose对数据库进行操作,比较方便.使用嵌套document时,需要创建多个Schema(类似于Java中的POJO吧).12345678910111213141516171819202122232425var contactInformationSchema = new Schema(&#123; address: String, phone: String&#125;)var alreadyPaidSchema = new Schema(&#123; productID: Schema.Types.ObjectId, price: Number, address: String, phone: String, userName: String&#125;)var unpaidSchema = new Schema(&#123; productID: Schema.Types.ObjectId, price: Number&#125;)var schema = new Schema(&#123; username: String, password: String, contactInformation: [contactInformationSchema], alreadyPaid: [alreadyPaidSchema], unpaid: [unpaidSchema]&#125;); 有关nodeJS最大的优点就是回调,实现网站的并发访问. 不过缺点也不少,可能是我经验不足,记录一下掉过的坑. 1. 回调,感觉就像是不负责任地甩锅.1234567var test;for (var i = 0; i &lt; array.length; i++) &#123; test = array[i]; mongooseModel.find(&#123;\"something\":test&#125;).exec(function(err,document)&#123; var test1 = test; //此时的test可能已经是下一循环的值 &#125;)&#125; 2. 回调,导致代码层层嵌套3. 单进程,一旦进程发生阻塞,这个程序都会阻塞123while (true) &#123; //整个程序陷入死循环&#125; 4. 还是回调,导致数据库跨collection查询困难5. Express 中的模板应谨慎使用.我在项目中大量使用了ejs模板,当初就是为了图方便,直接使用ejs,实际上模板只应在静态文件中使用,也就是能保证模板中的内容在多个页面中同时适用,对于内容变化比较的页面,还是乖乖地写接口,返回JSON数据比较靠谱. 总结项目总体还是比较失败,不过也能学点东西. 比如 nodeJS , mongodb, 还有一点前端知识","raw":null,"content":null,"categories":[{"name":"网站相关","slug":"网站相关","permalink":"https://Caden16.github.io/categories/网站相关/"}],"tags":[{"name":"nodeJS","slug":"nodeJS","permalink":"https://Caden16.github.io/tags/nodeJS/"},{"name":"mongodb","slug":"mongodb","permalink":"https://Caden16.github.io/tags/mongodb/"},{"name":"Express","slug":"Express","permalink":"https://Caden16.github.io/tags/Express/"},{"name":"mongoose","slug":"mongoose","permalink":"https://Caden16.github.io/tags/mongoose/"}]},{"title":"cloudstack 搭建总结","slug":"cloudstack搭建总结","date":"2016-11-20T00:00:00.000Z","updated":"2017-02-14T04:09:05.448Z","comments":true,"path":"cloudsatck搭建/cloudstack搭建总结/","link":"","permalink":"https://Caden16.github.io/cloudsatck搭建/cloudstack搭建总结/","excerpt":"","text":"按照官网的教程搭建cloudstack,稍不注意,就出现错误.总结一下. 子节点状态不对123[root@node3 ~]# service cloudstack-agent statuscloudstack-agent dead but subsys locked 解决：管理节点防火墙问题，正常状态下计算节点应通过NFS挂载主存储,管理节点应开放8250端口 执行完后把cloudstack-agent 重启一下，其状态应为running 系统VM 状态为Starting解决：在数据库中将这个虚拟机的状态由“Starting”更改成“Stopped”，重新启动虚拟机即可。 1MySQL -uroot -p -e \"update cloud.vm_instance set state='Stopped' where name=VMNAME 系统VM 状态为Running , 代理状态为空（centos6.5 图形化界面下的防火墙重启会清空iptables 文件下的规则）防火墙问题 管理节点也用作计算节点，防火墙状态应为 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# Generated by iptables-save v1.4.7 on Thu Jun 2 13:23:26 2016*nat:PREROUTING ACCEPT [187042:40599771]:POSTROUTING ACCEPT [36644:2281945]:OUTPUT ACCEPT [36644:2281945]COMMIT# Completed on Thu Jun 2 13:23:26 2016# Generated by iptables-save v1.4.7 on Thu Jun 2 13:23:26 2016*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [13422:54204084]:BF-cloud0 - [0:0]:BF-cloud0-IN - [0:0]:BF-cloud0-OUT - [0:0]-A INPUT -p tcp -m tcp --dport 49152:49216 -j ACCEPT-A INPUT -p tcp -m tcp --dport 5900:6100 -j ACCEPT-A INPUT -p tcp -m tcp --dport 16509 -j ACCEPT-A INPUT -p tcp -m tcp --dport 1798 -j ACCEPT-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5900 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5901 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5902 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8250 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 111 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 111 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 2049 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 32803 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 32769 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 892 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 892 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 875 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 875 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 662 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 662 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -o cloud0 -m physdev --physdev-is-bridged -j BF-cloud0-A FORWARD -i cloud0 -m physdev --physdev-is-bridged -j BF-cloud0-A FORWARD -o cloud0 -j DROP-A FORWARD -i cloud0 -j DROP-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A BF-cloud0 -m state --state RELATED,ESTABLISHED -j ACCEPT-A BF-cloud0 -m physdev --physdev-is-in --physdev-is-bridged -j BF-cloud0-IN-A BF-cloud0 -m physdev --physdev-is-out --physdev-is-bridged -j BF-cloud0-OUT-A BF-cloud0 -m physdev --physdev-out vnet0 --physdev-is-bridged -j ACCEPTCOMMIT# Completed on Thu Jun 2 13:23:26 2016 计算节点防火墙状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*mangle:PREROUTING ACCEPT [654:130068]:INPUT ACCEPT [210:107800]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [143:8276]:POSTROUTING ACCEPT [143:8276]-A POSTROUTING -o virbr0 -p udp -m udp --dport 68 -j CHECKSUM --checksum-fill-A POSTROUTING -o virbr0 -p udp -m udp --dport 68 -j CHECKSUM --checksum-fillCOMMIT# Completed on Wed Jun 1 19:37:24 2016# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*nat:PREROUTING ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:OUTPUT ACCEPT [0:0]COMMIT# Completed on Wed Jun 1 19:37:24 2016# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -p tcp -m tcp --dport 49152:49216 -j ACCEPT-A INPUT -p tcp -m tcp --dport 5900:6100 -j ACCEPT-A INPUT -p tcp -m tcp --dport 16509 -j ACCEPT-A INPUT -p tcp -m tcp --dport 1798 -j ACCEPT-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 5900 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5901 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8250 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -i virbr0 -o virbr0 -j ACCEPT-A FORWARD -o virbr0 -j REJECT --reject-with icmp-port-unreachable-A FORWARD -i virbr0 -j REJECT --reject-with icmp-port-unreachableCOMMIT# Completed on Wed Jun 1 19:37:24 2016 二级存储及主存储路径需要设置权限，否则二级存储虽能挂载，但无法写入文件注意看日志文件，里面有详细的输出说明","raw":null,"content":null,"categories":[{"name":"cloudsatck搭建","slug":"cloudsatck搭建","permalink":"https://Caden16.github.io/categories/cloudsatck搭建/"}],"tags":[{"name":"cloudsatck","slug":"cloudsatck","permalink":"https://Caden16.github.io/tags/cloudsatck/"}]},{"title":"ubuntu下如何优雅地使用翻译","slug":"ubuntu下如何优雅地使用翻译","date":"2016-10-26T00:00:00.000Z","updated":"2017-03-01T03:03:27.140Z","comments":true,"path":"有道字典修改/ubuntu下如何优雅地使用翻译/","link":"","permalink":"https://Caden16.github.io/有道字典修改/ubuntu下如何优雅地使用翻译/","excerpt":"","text":"最近看英文文档比较多，但英语水平不咋地，需要借助翻译工具。在ubuntu下，有startdict、goldendict等字典，但字典毕竟是字典，解释太多，用着不太爽。平时喜欢用谷歌翻译，最近谷歌翻译的水平也的确提升了不少，可惜没有客户端，平时看个PDF啥的也用不了，github 上的发现mtranslate模块，把网址改为中国的网址，得到结果还挺快. 本来想写个接口封装一下，直接用goldendict显示的，无奈网络延迟太大，谷歌翻译都没出结果，字典的弹框就出来了，能找到goldendict的源码，但看到那一坨代码，实在没有修改的欲望。偶然的机会，发现了某道有ubuntu的客户端，解压出来，居然是python的代码，还是python大法好，这样就来优雅地改一下代码吧。最后实现功能：在弹框中显示调用mtranslate模块显示的翻译信息 点击保存，将所翻译的单词保存到指定目录的translate.csv文件中 调整弹框显示，解决翻译文本过长导致弹框显示不全的问题 实现过程：下载mtranslate模块配置运行环境使用python3，先安装youdao的客户端，解决依赖关系，然后把youdao卸载。 代码实现过程下载.deb包，解压，参考文章http://www.cnblogs.com/scplee/archive/2016/05/13/5489024.html 在dae/utils.py增加代码123456def get_conf(): import json import os with open('configuration.json', 'r') as f: conf = json.load(f) return conf 修改translate.py文件修改get_translate方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546def get_translate(self, text): data = &#123; \"keyfrom\" : \"deskdict.linux\", \"q\" : text.encode(\"utf-8\"), \"doctype\" : \"xml\", \"xmlVersion\" : 8.2, \"client\" : const.client, \"id\" : \"cee84504d9984f1b2\", \"vendor\": \"deskdict.linux\", \"in\" : \"YoudaoDict\", \"appVer\" : \"5.4.46.5554\", \"appZengqiang\" : 0, \"le\" : \"eng\", \"LTH\" : 40&#125; # self.clear_translate() # try: ret = requests.get(\"http://dict.youdao.com/search\", params=data).text ret = ret.encode('utf-8') pq = PyQuery(ret, parser=\"xml\") test_data = &#123;\"q\": text, \"type\": 1, \"pos\": -1, \"client\": const.client&#125; test_ret = json.loads(requests.get(\"http://dict.youdao.com/jsonresult\", params=test_data).text) self.translate_info.text = text text = str(text).replace('\\n',' ') from dae.utils import get_conf conf = get_conf() self.translate_info.webtrans = \"谷歌翻译:\\n\" if (str(conf['useTranslateModule']).upper() == 'TRUE' ): self.translate_info.webtrans = self.translate_info.webtrans + useTranslateComponent(text) + \"\\n\" # if self.translate_info.webtrans: self.translate_info.webtrans =self.translate_info.webtrans + \"有道:\\n\" self.translate_info.trans = '\\n'.join([PyQuery(l)(\"i\").text() for l in pq('trs l')]) self.translate_info.phonetic = test_ret.get(\"ussm\", \"\") self.translate_info.webtrans = self.translate_info.webtrans + self.wrap_web_trans(pq) # self.translate_info.lang = test_ret.get(\"lang\", \"\") # # except: # with open_offline_dict() as obj: # ret = obj.query(text) # if ret: # self.translate_info.text = text # self.translate_info.trans = ret[1].replace(\"\\\\n\", \"\\n\") # self.translate_info.phonetic = ret[0][1:-1] # self.translate_info.webtrans = \"抱歉，从网络获取结果失败，请检测网络重试\" # self.translate_info.lang = \"eng\" # self.translate_info.voices = get_voice_simple(text) # if not text: # return #self.clear_translate() #self.translate_info.text = text if not self.translate_info.webtrans: self.translate_info.webtrans = \"查询失败\" if self.translate_info.webtrans: self.translateFinished.emit() 在translate.py中添加代码：12345678def useTranslateComponent(text): import os from dae.utils import get_conf conf = get_conf() toLang = conf['toLang'] from mtranslate import translate translation = translate(text,toLang) return translation 在windows.py添加类：12345678910111213141516171819202122232425262728293031323334353637383940#@ 保存到文件 class saveToFile(QtCore.QObject): @QtCore.pyqtSlot(str, str) def saveToFile(self,fromText,toText): import os import csv from dae.utils import get_conf toText = str(toText).replace('谷歌翻译:','') toText = toText.split('有道:') firstText = '' if toText[0]: firstText = toText[0].strip('\\n') lastText = toText[1].replace('有道:','').strip('\\n').lstrip('w. ') if (firstText or lastText): if not firstText: firstText = ' ' if not lastText: lastText = ' ' conf = get_conf() savePath = str(conf['savePath']).rstrip('/') + '/translate.csv' if not os.path.exists(savePath): with open(savePath,'a+') as f: writer = csv.writer(f) writer.writerow(['翻译内容','谷歌翻译','有道词典']) writeData = [ fromText, firstText, lastText ] writer.writerow(writeData) f.close() return with open(savePath,'a+') as f: writer = csv.writer(f) writeData = [ fromText, firstText, lastText ] writer.writerow(writeData) f.close() return return 在window.py 的init()方法中添加代码123#@ 单词保存到文件 self.saveToFile = saveToFile() self.qml_context.setContextProperty(\"saveToFile\", self.saveToFile) #把saveToFile类暴露给qml文件 在TranslateContent.qml 添加TextEdit，位置自己看着办就行1234567891011121314151617181920212223242526TextEdit&#123; color: \"#ff0000\" anchors.verticalCenter: parent.verticalCenter text: \" 保存\" selectByMouse: true readOnly: true font.pixelSize: 15 MouseArea &#123; anchors.fill: parent hoverEnabled: true onExited: &#123; cursorShape = Qt.ArrowCursor &#125; onClicked: &#123; saveToFile.saveToFile(translateInfo.text, translateInfo.webtrans) if (parent.color == \"#2699eb\")&#123; parent.color = \"#ff0000\"; &#125; else&#123; if(parent.color == \"#ff0000\")&#123; parent.color = \"#2699eb\" &#125; &#125; &#125; &#125; &#125; 修改翻译内容显示方式1234567891011TextEdit&#123; id: keywordsText width: parent.width //anchors.verticalCenter: parent.verticalCenter selectByMouse: true readOnly: true text: translateInfo.text wrapMode: Text.WordWrap font.pixelSize: 13 font.bold: true &#125; 添加配置文件在main.py所在文件夹下添加配置文件configuration.json，配置文件，可以选择是否启用translate模块，配置保存翻译信息文件位置，使用translate时系统调用的命令123456&#123; \"useTranslateModule\": \"true\", \"savePath\": \"/home/ubuntu/Desktop\", \"cmd\": \"translate -f en -t zh \", \"toLang\": \"zh\"&#125; 运行直接运行main.py youdao-dict-backend.py就行, 可写个简单的脚本来实现 总结直接利用youdao原有的事件处理，总体能用，但没有startdict或goldendict流畅，如果能直接修改startdict或goldendict的代码，利用它们的事件处理，估计会更稳定，不过最近比较忙,先凑合着用吧.","raw":null,"content":null,"categories":[{"name":"有道字典修改","slug":"有道字典修改","permalink":"https://Caden16.github.io/categories/有道字典修改/"}],"tags":[{"name":"python","slug":"python","permalink":"https://Caden16.github.io/tags/python/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://Caden16.github.io/tags/ubuntu/"}]},{"title":"github目录","slug":"README","date":"2016-01-01T00:00:00.000Z","updated":"2017-04-29T14:13:04.558Z","comments":true,"path":"uncategorized/README/","link":"","permalink":"https://Caden16.github.io/uncategorized/README/","excerpt":"","text":"blogMarkdownFilemyblog(转)Leveldb实现原理Leveldb实现原理.md)C++语法记录ELKStack搭建问题总结LRU缓存淘汰算法LeetCode解题-Next Permutation(全排列生成算法).md)LeetCode解题-Permutation Sequencecloudstack搭建总结gdb调试错误-找不到文件git使用golang 反射机制golang学习golang调试技巧go结构体大小kafka存储实现kafka学习笔记linux IO学习linux内核学习-数据结构linux单文件大小限制linux命令学习linux学习-linux文件存储linux文件存储机制linux页缓存机制 Page Cachemalloc vs newnodeJS入门总结openstack-swift源码阅读记录1-文件上传过程openstack-swift源码阅读记录3-diskfileopenstack-swift源码阅读记录4-启用mem_diskfileopenstack-swift调试openstack源码阅读记录2-object metadatapython inner functionpython string internpython流量控制python的多线程和Goroutinepython语法记录seaweedfs源码阅读4-volume启动seaweedfs源码阅读5-文件PUT过程seaweedfs源码阅读6-文件存储格式seaweedfs源码阅读7-文件存储过程seaweedfs源码阅读8-GET&amp;HEAD获取文件过程seaweedfs源码阅读记录seaweedfs源码阅读记录2seaweedfs源码阅读记录3-raft协议理解seaweedfs源码阅读记录9-生成fid过程swift-weedfs-backend diskfile代码实现swift-weedfs-backend接口设计ubuntu下如何优雅地使用翻译ubuntu使用问题总结伪随机数在Openstack Swift中使用多种后端存储实现对大量的不重复数进行排序(查找).md)对象存储VS文件系统数据结构文件系统(seaweedfs)与关系型数据库优劣势分析与关系型数据库优劣势分析.md)用户态到内核态切换自旋锁spinlock剖析与改进","raw":null,"content":null,"categories":[],"tags":[]}]}