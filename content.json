{"meta":{"title":"MakeItPossible16","subtitle":"寻找实习单位,详情请看个人简介","description":"闲着没事写点东西","author":"MakeItPossible16","url":"https://makeitpossible16.github.io"},"posts":[{"title":"LRU缓存淘汰算法","slug":"LRU缓存淘汰算法","date":"2017-03-08T00:00:00.000Z","updated":"2017-03-08T11:39:59.802Z","comments":true,"path":"算法/LRU缓存淘汰算法/","link":"","permalink":"https://makeitpossible16.github.io/算法/LRU缓存淘汰算法/","excerpt":"在Linux目录项高速缓存中,所有”未使用”的目录项对象都存放在一个会使用LRU(Last Recently used)算法实现的双向链表中,该链表按照插入的时间进行排序. 最后释放的目录项会放在链表的首部,最近最少使用的目录项对象靠近链表尾部,需要释放空间时,内核从链表尾部进行删除.","text":"在Linux目录项高速缓存中,所有”未使用”的目录项对象都存放在一个会使用LRU(Last Recently used)算法实现的双向链表中,该链表按照插入的时间进行排序. 最后释放的目录项会放在链表的首部,最近最少使用的目录项对象靠近链表尾部,需要释放空间时,内核从链表尾部进行删除.参考缓存淘汰算法–LRU算法,LRU算法实现: 新数据插入到链表头部； 每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 当链表满的时候，将链表尾部的数据丢弃。 缓存污染: 当存在热点数据时，LRU的效率很好,但偶发性的、周期性的批量操作会导致LRU命中率急剧下降","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://makeitpossible16.github.io/categories/算法/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://makeitpossible16.github.io/tags/缓存/"}]},{"title":"伪随机数","slug":"伪随机数","date":"2017-03-05T00:00:00.000Z","updated":"2017-03-05T08:56:55.648Z","comments":true,"path":"操作系统/伪随机数/","link":"","permalink":"https://makeitpossible16.github.io/操作系统/伪随机数/","excerpt":"遇到一到面试题,其中提到Hash函数的构造方法可以使用 随机数法:选择一个随机函数，取关键字的随机函数值为它的散列地址,感觉取随机数会导致数据查找失败,不过查找了有关计算机中伪随机数的生成方法后,明白了这个方法是可行的.","text":"遇到一到面试题,其中提到Hash函数的构造方法可以使用 随机数法:选择一个随机函数，取关键字的随机函数值为它的散列地址,感觉取随机数会导致数据查找失败,不过查找了有关计算机中伪随机数的生成方法后,明白了这个方法是可行的.解释来自百度百科:12345678910111213141516171819202122//rand01.c#include &lt;stdlib.h&gt;static unsigned int RAND_SEED;unsigned int random(void)&#123; RAND_SEED=(RAND_SEED*123+59)%65536; return(RAND_SEED);&#125;void random_start(void)&#123; int temp[2]; movedata(0x0040,0x006c,FP_SEG(temp),FP_OFF(temp),4); RAND_SEED=temp[0];&#125;main()&#123; unsigned int i,n; random_start(); for(i=0;i&lt;10;i++) printf(\"%u\\t\",random()); printf(\"\\n\");&#125; 1movedata(0x0040,0x006c,FP_SEG(temp),FP_OFF(temp),4); 这个函数用来移动内存数据，其中FP_SEG（far pointer to segment）是取temp数组段地址的函数，FP_OFF（far pointer to offset）是取temp数组相对地址的函数，movedata函数的作用是把位于0040:006CH存储单元中的双字放到数组temp的声明的两个存储单元中。这样可以通过temp数组把0040:006CH处的一个16位的数送给RAND_SEED。random用来根据随机种子RAND_SEED的值计算得出随机数，其中这一句：1RAND_SEED=(RAND_SEED*123+59)%65536 是用来计算随机数的方法，随机数的计算方法在不同的计算机中是不同的，即使在相同的计算机中安装的不同的操作系统中也是不同的。我在linux和windows下分别试过，相同的随机种子在这两种操作系统中生成的随机数是不同的，这说明它们的计算方法不同。0040:006CH处其实这一段内存空间是这样定义的：TIMER_LOW DW ? ；地址为 0040:006CHTIMER_HIGH DW ? ；地址为 0040:006EHTIMER_OFT DB ? ；地址为 0040:0070H时钟中断服务程序中，每当TIMER_LOW转满时，此时，记数器也会转满，记数器的值归零，即TIMER_LOW处的16位二进制归零，而TIMER_HIGH加一。由于随机种子可以人工设定,因此每次产生的随机数都是相同的.Python例子:12345678910111213141516171819202122232425262728293031In [3]: random.seed(1)In [4]: for i in range(10): ...: print random.random() ...:0.1343642441120.8474337369370.7637746189770.2550690257390.4954350870920.4494910647890.6515929727230.7887233511360.09385958677420.028347476522In [5]: random.seed(1)In [6]: for i in range(10): ...: print random.random() ...:0.1343642441120.8474337369370.7637746189770.2550690257390.4954350870920.4494910647890.6515929727230.7887233511360.09385958677420.028347476522In [7]:","raw":null,"content":null,"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://makeitpossible16.github.io/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://makeitpossible16.github.io/tags/操作系统/"}]},{"title":"(转)文件系统vs对象存储——选型和趋势","slug":"对象存储VS文件系统","date":"2017-03-03T00:00:00.000Z","updated":"2017-03-03T09:30:14.817Z","comments":true,"path":"对象存储/对象存储VS文件系统/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/对象存储VS文件系统/","excerpt":"","text":"之前对于对象存储的定义还是比较模糊，看完文件系统vs对象存储——选型和趋势这篇文章后对文件系统和对象存储有一个比较清晰的了解，做一下简单的概括。 对象存储初期：对象存储往往指的是以类似标准化组织SNIA定义的OSD（object storage device）和MDS（Metadata Server）为基本组成部分的分布式存储，通常是分布式文件系统。后期：指的是以AWS的S3为代表的，通过HTTP接口提供访问的存储服务或者存储系统,如果我们把一个文件传到对象存储系统里面存起来，就叫做一个对象。 对象存储与文件系统的比较对于大多数文件系统来说，尤其是POSIX(表示可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ）,POSIX标准定义了操作系统应该为应用程序提供的接口标准)兼容的文件系统，提供open、close、read、write和lseek等接口。而对象存储的接口是REST风格的，通常是基于HTTP协议的RESTful Web API，通过HTTP请求中的PUT和GET等操作进行文件的上传即写入和下载即读取，通过DELETE操作删除文件。对象存储和文件系统在接口上的本质区别是对象存储不支持和fread和fwrite类似的随机位置读写操作，即一个文件PUT到对象存储里以后，如果要读取，只能GET整个文件，如果要修改一个对象，只能重新PUT一个新的到对象存储里，覆盖之前的对象或者形成一个新的版本。","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"文件系统，对象存储","slug":"文件系统，对象存储","permalink":"https://makeitpossible16.github.io/tags/文件系统，对象存储/"}]},{"title":"C++语法记录","slug":"C++语法记录","date":"2017-03-01T00:00:00.000Z","updated":"2017-03-03T07:15:07.058Z","comments":true,"path":"C/C++语法记录/","link":"","permalink":"https://makeitpossible16.github.io/C/C++语法记录/","excerpt":"","text":"最近遇到一些C++的代码,其中会包含一些C++11及STL的代码,对C++11的特性不太了解,记录一下. nextnext用于操作迭代器,函数解释std::nextParameters it - an iterator n - number of elements to advance使用示例:12345678910111213141516#include &lt;iostream&gt;#include &lt;iterator&gt;#include &lt;vector&gt;int main()&#123; std::vector&lt;int&gt; v&#123; 3, 1, 4,6,7 &#125;; auto it = v.begin(); auto nx = std::next(it, 3); std::cout &lt;&lt; *it &lt;&lt; &apos; &apos; &lt;&lt; *nx &lt;&lt; &apos;\\n&apos;;&#125;output:3 6 push_back函数将一个新的元素加到vector的最后面，位置为当前最后一个元素的下一个元素. 参考C++ vector::push_back 用法剖析 for_eachfor_each用于逐个遍历容器元素，它对迭代器区间[first，last)所指的每一个元素，执行由单参数函数对象f所定义的操作。参考简单的程序诠释C++ STL算法系列之一：for_each","raw":null,"content":null,"categories":[{"name":"C++","slug":"C","permalink":"https://makeitpossible16.github.io/categories/C/"}],"tags":[{"name":"C++11","slug":"C-11","permalink":"https://makeitpossible16.github.io/tags/C-11/"},{"name":"C++","slug":"C","permalink":"https://makeitpossible16.github.io/tags/C/"}]},{"title":"gdb调试错误-找不到文件","slug":"gdb调试错误-找不到文件","date":"2017-02-28T00:00:00.000Z","updated":"2017-02-28T09:09:13.116Z","comments":true,"path":"linux命令/gdb调试错误-找不到文件/","link":"","permalink":"https://makeitpossible16.github.io/linux命令/gdb调试错误-找不到文件/","excerpt":"","text":"使用gdb进行调试时出现错误,错误重现:(gdb) qsh-4.3$ gdb -q aaaReading symbols from aaa…done.(gdb) l28 int base = factorial(n - 1);29 –k;30 for (int i = n -1; i &gt; 0; k %= base, base /= i, –i) {31 auto a = next(S.begin(), k / base);32 result.push_back(*a);33 S.erase(a);34 }35 cout &lt;&lt; S[0];36 auto a = S[0];37 // result.push_pack(a);(gdb) b 37Breakpoint 1 at 0x4012a2: file /home/ubuntu/workspace/leetcode/permutation_sequence.cpp, line 37.(gdb) rStarting program: /home/ubuntu/workspace/leetcode/aaaCannot exec -c exec /home/ubuntu/workspace/leetcode/aaa .Error: 没有那个文件或目录During startup program exited with code 127. 在vscode中,错误提示为:1Unable to start debugging. Unexpected GDB output from command &quot;-exec-run&quot;. During startup program exited with code 127. 解决方法:参考http://unix.stackexchange.com/questions/167918/gdb-cannot-exec-my-test-program,由于SHELL变量不存在,导致gdb抛出异常,解决方法:在/etc//etc/environment中设置全局变量123export SHELL=/bin/sh或export SHELL=/bin/bash","raw":null,"content":null,"categories":[{"name":"linux命令","slug":"linux命令","permalink":"https://makeitpossible16.github.io/categories/linux命令/"}],"tags":[{"name":"gdb","slug":"gdb","permalink":"https://makeitpossible16.github.io/tags/gdb/"}]},{"title":"LeetCode解题-Next Permutation(全排列生成算法)","slug":"LeetCode解题-Next Permutation(全排列生成算法)","date":"2017-02-26T00:00:00.000Z","updated":"2017-02-27T07:37:20.507Z","comments":true,"path":"算法/LeetCode解题-Next Permutation(全排列生成算法)/","link":"","permalink":"https://makeitpossible16.github.io/算法/LeetCode解题-Next Permutation(全排列生成算法)/","excerpt":"","text":"LeetCode题目-Next Permutation看半天连题目都看不懂,参考LeetCode 31 Next Permutation（下一个排列）,基本理解题意:数学中的排列组合，比如“1，2，3”的全排列，依次是：1234561 2 31 3 22 1 32 3 13 1 23 2 1 从上面的某一行重排到期下一行，如果已经是最后一行了，则重排成第一行。 实现思路:从后往前遍历,找到最长递增序列,结束位置为index,然后找到最长递增序列中比index-1的数大的最小的数.图片来源:http://fisherlei.blogspot.co.id/2012/12/leetcode-next-permutation.html","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://makeitpossible16.github.io/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://makeitpossible16.github.io/tags/LeetCode/"}]},{"title":"LeetCode解题-Next Permutation(全排列生成算法)","slug":"LeetCode解题-Permutation Sequence","date":"2017-02-26T00:00:00.000Z","updated":"2017-02-27T12:41:08.472Z","comments":true,"path":"算法/LeetCode解题-Permutation Sequence/","link":"","permalink":"https://makeitpossible16.github.io/算法/LeetCode解题-Permutation Sequence/","excerpt":"","text":"题目:给出数字n,在1…n的全排列组合中找到第k个,如: n = 3, k=31234567全排列:123132213231312321 结果为:213 解题使用逆康托编码展开,参考全排列的编码与解码——康托展开 康托编码:{1,2,3,4,…,n}的排列总共有n!种，将它们从小到大排序，怎样知道其中一种排列是有序序列中的第几个？如 {1,2,3} 按从小到大排列一共6个：123 132 213 231 312 321。想知道321是{1,2,3}中第几个大的数。小于3的数有1和2 两个，首位确定之后后面两位有2！中情况，所以共有22！=4种。小于2的数只有一个1，所以有11！=1种情况，最后一位是1，没有比一小的数，所以是00！=0综上：小于321的数有4+1=5个，所以321是第六小的数。例如:排列3 5 7 4 1 2 9 6 8展开为98884X=28!+37!+46!+25!+04!+03!+22!+01!+00!=98884. 逆康托展开:1234567891011121314151617181920212223如何找出第16个（按字典序的）&#123;1,2,3,4,5&#125;的全排列？1. 首先用16-1得到152. 用15去除4! 得到0余153. 用15去除3! 得到2余34. 用3去除2! 得到1余15. 用1去除1! 得到1余0有0个数比它小的数是1，所以第一位是1有2个数比它小的数是3，但1已经在之前出现过了所以是4有1个数比它小的数是2，但1已经在之前出现过了所以是3有1个数比它小的数是2，但1,3,4都出现过了所以是5最后一个数只能是2所以排列为1 4 3 5 2","raw":null,"content":null,"categories":[{"name":"算法","slug":"算法","permalink":"https://makeitpossible16.github.io/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://makeitpossible16.github.io/tags/LeetCode/"}]},{"title":"swift-weedfs-backend diskfile代码实现","slug":"swift-weedfs-backend diskfile代码实现","date":"2017-02-26T00:00:00.000Z","updated":"2017-03-02T02:46:55.297Z","comments":true,"path":"对象存储/swift-weedfs-backend diskfile代码实现/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/swift-weedfs-backend diskfile代码实现/","excerpt":"主要修改InMemoryFileSystem中的代码,使用seaweedfs进行数据持久化,完整代码实现swift-weedfs-backend","text":"主要修改InMemoryFileSystem中的代码,使用seaweedfs进行数据持久化,完整代码实现swift-weedfs-backend1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class InMemoryFileSystem(object): \"\"\" A very simplistic in-memory file system scheme. There is one dictionary mapping a given object name to a tuple. The first entry in the tuple is the cStringIO buffer representing the file contents, the second entry is the metadata dictionary. \"\"\" def __init__(self): self._filesystem = &#123;&#125; self.seaweedfs = Seaweedfs_operation() def get_object(self, name): \"\"\" Return back an file-like object and its metadata :param name: standard object name :return (fp, metadata): fp is `StringIO` in-memory representation object (or None). metadata is a dictionary of metadata (or None) \"\"\" # val = self._filesystem.get(name) val = self.seaweedfs.GET(name) if val is None: fp, metadata = None, None else: fp, metadata = self.parse_seaweedfs_file(val) # else: # fp, metadata = val return fp, metadata def parse_seaweedfs_file(self,val): \"\"\" parse file download from seaweedfs :param val: seaweedfs file,fomat: str(metadata) + '\\n' + obj_content :return: StringIO obj_content, python dict metadata \"\"\" metadata_index = val.find('\\n') val = val.split('\\n',1) return StringIO.StringIO(val[1]),eval(val[0]) def put_object(self, name, fp, metadata): \"\"\" Store object into seaweedfs :param name: standard object name :param fp: `StringIO` in-memory representation object :param metadata: dictionary of metadata to be written \"\"\" # self._filesystem[name] = (fp, metadata) fp.seek(0) self.seaweedfs.PUT(name,str(metadata) + '\\n' + fp.read()) def del_object(self, name): \"\"\" Delete object from memory :param name: standard object name \"\"\" # import pydevd # pydevd.settrace('127.0.0.1', port=54321, stdoutToServer=True, stderrToServer=True) self.seaweedfs.DELETE(name) # del self._filesystem[name] def get_diskfile(self, account, container, obj, **kwargs): return DiskFile(self, account, container, obj) def pickle_async_update(self, *args, **kwargs): \"\"\" For now don't handle async updates. \"\"\" pass","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"},{"name":"swift-weedfs-backend","slug":"swift-weedfs-backend","permalink":"https://makeitpossible16.github.io/tags/swift-weedfs-backend/"}]},{"title":"swift-weedfs-backend接口设计","slug":"swift-weedfs-backend接口设计","date":"2017-02-25T00:00:00.000Z","updated":"2017-02-26T13:41:57.679Z","comments":true,"path":"对象存储/swift-weedfs-backend接口设计/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/swift-weedfs-backend接口设计/","excerpt":"","text":"swift-weedfs-backend基于mem_diskfile,使用seaweedfs对mem_diskfile中的数据进行持久化.设计接口如下: 接口名称 参数类型:参数名称 返回值 接口说明 GET strng:url file_content 获取seaweedfs文件 PUT string:url,obj_content True/False 保存对象 DELETE string:url True/False 删除对象 parseURL string:url account,container,obj_name 从URL中解析得到account,container,obj_name 代码实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Seaweedfs_operation(): def __init__(self): self.seaweedfs = WeedFS(); self.filter_ip = \"127.0.0.1\" self.filter_port = \"8888\" def PUT(self,url, obj_content): \"\"\" upload file to seaweedfs :param url: :param obj_content: :return: obj size \"\"\" account,container,obj_name = self.parseURL(url) url_complete = u\"http://&#123;filter_ip&#125;:&#123;filter_port&#125;/&#123;account&#125;/&#123;container&#125;/\".format(filter_ip=self.filter_ip, filter_port=self.filter_port, account=account,container=container) return self.seaweedfs.upload_file(url_complete,obj_name,obj_content) def DELETE(self,url): \"\"\" delete a file from seaweedfs :param url: :return: Boolean: True:delete success \"\"\" url_complete = u\"http://&#123;filter_ip&#125;:&#123;filter_port&#125;&#123;url&#125;\".format(filter_ip=self.filter_ip, filter_port=self.filter_port,url=url) return self.seaweedfs.delete_file(url_complete) def GET(self,url): \"\"\" download a file from seaweedfs :param url: :return: Content of the file with provided url or None if file doesn't exist on the server \"\"\" url_complete = \"http://&#123;filter_ip&#125;:&#123;filter_port&#125;&#123;url&#125;\".format(filter_ip=self.filter_ip, filter_port=self.filter_port,url=url) return self.seaweedfs.get_file(url_complete) def parseURL(self,url): \"\"\" parse url to account, container, obj_name :param url: :return: account, container, obj_name \"\"\" url_split = url.split('/') return url_split[1],url_split[2],url_split[3]","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"openstack-swift源码阅读记录4-启用mem_diskfile","slug":"openstack-swift源码阅读记录4-启用mem_diskfile","date":"2017-02-24T00:00:00.000Z","updated":"2017-02-25T11:46:46.271Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录4-启用mem_diskfile/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/openstack-swift源码阅读记录4-启用mem_diskfile/","excerpt":"","text":"修改/etc/swift/object-server/中的文件,改为:12[app:object-server]use = egg:swift#mem_object mem_diskfile为mem_server提供内存存储后端实现,而mem_server继承自server.ObjectController,提供请求转发工作,其中,设置客户端超时时间:1self.client_timeout = int(conf.get(&apos;client_timeout&apos;, 60)) 用户上传对象过程调用mem_diskfile中的put_object方法1def put_object(self, name, fp, metadata): 参数:可以看到,name为account,container,object的组合","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"在Openstack Swift中使用多种后端存储实现","slug":"在Openstack Swift中使用多种后端存储实现","date":"2017-02-23T00:00:00.000Z","updated":"2017-02-24T06:04:21.796Z","comments":true,"path":"对象存储/在Openstack Swift中使用多种后端存储实现/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/在Openstack Swift中使用多种后端存储实现/","excerpt":"","text":"在Intel开发者社区发现这篇文章,给我很大的帮助,尝试着把它翻译成中文. 原文链接Using Multiple Backends in Openstack Swift Using Multiple Backends in Openstack SwiftBy Yuan Zhou (Intel), Added February 3, 2015 OpenStack Swift是一个高度可用的，分布式的，最终一致的对象存储实现系统. 考虑到经济效益及存储横向扩展能力,对象存储是理想的存储实现模式.它提供了一个完全分布式，API可访问的存储平台，可以直接集成到应用程序中或用于备份，归档和保存数据。有关详细信息，请参阅http://docs.openstack.org/developer/swift/。由于V2.0 Swift支持多个存储策略,这允许通过创建多个object ring来为不同目的进行不同的存储策略,从而实现某种程度的分段集群.对于帐户数据库，容器数据库有一个单独的ring，并且每个存储策略都有一个object ring。通过支持多个对象环，Swift允许应用程序和/或部署程序在单个集群中实现分离对象存储功能。然而Swift拥有另一个相当好的功能:从Juno发行版开始,支持可插拔存储后端. 得益于对象服务器中高度抽象的DiskFile API,存储设备提供商可以轻易地使用不同后端存储实现方案去存储文件对象. 这些项目有几个共同的特征: 这些项目被实现为一些新的WSGI对象服务器应用程序。Swift DiskFile抽象是这些多个后端解决方案的引擎. 这些项目正试图利用Swift / S3 API来加入对象存储市场或OpenStack生态系统. 目前这些项目大部分都在POC状态，并且不是很活跃。本地磁盘后端默认情况下，Swift将使用本地磁盘作为对象服务器中的存储设备. 在此实现中，用户上传的文件将单独存储在位于磁盘上层的本地文件系统中. 元数据将与文件一起存储为文件的扩展属性. 这需要一个支持文件扩展属性的文件系统，如xfs或ext4.对象服务器中的DiskFile API是一组RESTFul接口,如READ，WRITE和DELETE. 在这个本地磁盘后端，这些接口大多数是用POSIX API实现的. 例如，WRITE请求将调用python中的os.write().要使用此后端，您只需要复制示例object-server.conf. 注意，默认的WSGI应用程序应该是:123[app:object-server]use = egg: swift#object 其他后端解决方案需要使用自己的接口来实现这些接口. 使用内存后端这是在Swift中的样本示例. 在此实现中，用户上传的文件将与其元数据一起存储在内存的散列表(python dict)中. 每个键是accout，container和object_name的组合,相应的值是对象及其元数据的内容。1filesystem[name] = &#123;data, metadata&#125; 在DiskFile的一个PUT请求将是一个简单的python dict更新,这个解决方案目前只是一个原型，不适合在生产环境中使用. 我们可以很轻易地知道,当对象服务器关闭,所有的数据都会丢失.要使用此后端，您需要将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg: swift#mem_object 然后重新启动对象服务器. Swift-Ceph后端目前这是一个由eNovance发起的stackforge项目.这个实现使用Ceph作为Swift的存储设备. Swift对象环被配置为1x副本，而Ceph可以配置为3x副本. 这意味着从Swift的视图，只有1个对象副本存储在集群中。但是在Ceph集群中，将有3个对象的副本，并且Ceph将做一致性/复制工作.一般设计是来自DiskFile的新派生类，它将Swift读/写转换为使用librados读/写rados对象. Swift中的一个对象将被存储为Ceph中的一个文件，其名称为account，container和object name的组合.目前,account/container数据库依然以原始的方式存储在Swift当中.该项目还有一个计划，以便以后将这些SQLite DB存储到Ceph.此解决方案实现为WSGI应用程序,要使用此后端，您需要安装swift-ceph-backend项目，并将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg: swift_ceph_backend#rados_object 然后重新启动对象服务器. Swift-On-File后端Swift-on-File项目也是由Redhat发起的stackforge项目, 目前它是一个Swift对象服务器的实现, 它使用户能够访问相同的数据，既作为对象也可作为文件. 数据可以通过Swift的REST接口存储和检索，也可作为NAS接口的文件，包括本地GlusterFS，NFS和CIFS.要使用此后端，您需要安装swiftonfile项目，然后将object-server.conf中的默认WSGI应用程序更改为:12[app:object-server]use = egg:swiftonfile#object 您还需要在/mnt/swiftonfile 挂载一个NFS分区,或GlusterFS卷建议将对象环配置为仅1个副本. 所有的一致性/复制工作都在GlusterFS / NFS层中处理 Seagate kinetics后端Swift over Seagate 是由SwiftStack和Seagate开始的一个项目. 目前，它仍然在试验beta Kinetic库中. 使用Kinetic驱动器的Swift群集允许访问任何驱动器，从而访问任何对象.对于当前的Kinetic集成,对象服务器命令（对象守护程序）的一小部分被嵌入在作为逻辑构造的代理服务器中,如下所示:还有一些通过kinetic部署的设备,由于这个项目仍在开发中,没有准备过多的文档. 您需要检查最新的代码来了解详细信息. 参考文献：http://docs.openstack.org/developer/swift/https://swiftstack.com/blog/2014/02/04/swift-extensibility/https://github.com/stackforge/swift-ceph-backendhttps://github.com/stackforge/swiftonfilehttps://github.com/swiftstack/kinetic-swifthttps://developers.seagate.com/display/KV/OpenStack+Swift","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"openstack-swift源码阅读记录3-diskfile","slug":"openstack-swift源码阅读记录3-diskfile","date":"2017-02-21T00:00:00.000Z","updated":"2017-02-21T07:19:05.819Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录3-diskfile/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/openstack-swift源码阅读记录3-diskfile/","excerpt":"","text":"diskfile模块：diskfile模块为Swift对象服务器的磁盘文件接口 “DiskFile”，“DiskFileWriter”和“DiskFileReader”类组合定义用于支持对象服务器REST API的磁盘抽象层接口（不包括REPLICATE）。 其他希望提供的实现对象服务器的替代后端必须实现三个类。 mem_server.py和mem_diskfile.py模块为其中的一个实现示例。 DiskFileManager是一个参考实现特定的类，而不是部分后端API。 此模块中的其余方法被视为具体实现并且也不被视为后端API的一部分。","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"ubuntu使用问题总结","slug":"ubuntu使用问题总结","date":"2017-02-16T00:00:00.000Z","updated":"2017-02-16T13:48:09.980Z","comments":true,"path":"ubuntu/ubuntu使用问题总结/","link":"","permalink":"https://makeitpossible16.github.io/ubuntu/ubuntu使用问题总结/","excerpt":"","text":"lightdm登录界面找不到登录用户名问题分析：直接修改/etc/passwd文件中的用户user id，想要用此方法提升普通用户权限为root权限，但把user id在/etc/passwd中重新改成不为原有user id（比如原有user id 为1000，改成0后，又改成1001）时，会导致系统找不到用户，这是再改成1000，系统也会找不到用户，因此在登录界面不显示。解决方法：使用userdel 删除用户，但不删除与用户相关配置文件，然后使用useradd添加同名用户，即可在登录页面显示。 系统登录不断循环问题分析：参考Ubuntu 14.04登陆界面无限循环的解决办法,其中提到，home目录空间满了，还有一种可能是：由于添加了同名用户，但用户的user id不一样，系统认为/home目录不属于当前登录用户，导致登录不进去。解决方法：常看当前用户的user id：1id -u &lt;username&gt; 使用ll命令查看当前用户的/home文件夹所有者的user id是否为当前用户的user id，如果不是，使用命令chown改变home目录的所有者。 无法执行/bin/bash，没有那个文件或目录问题分析：参考脚本格式之殇——/bin/bash^M: 没有那个文件或目录 ，修改过/etc/passwd文件，导致/bin/bash后面多加空格符解决方法：使用cat -A filename查看文件，把不规则的空格去掉","raw":null,"content":null,"categories":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://makeitpossible16.github.io/categories/ubuntu/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://makeitpossible16.github.io/tags/ubuntu/"}]},{"title":"openstack源码阅读记录2-object metadata","slug":"openstack源码阅读记录2-object metadata","date":"2017-02-13T00:00:00.000Z","updated":"2017-02-13T09:06:16.572Z","comments":true,"path":"对象存储/openstack源码阅读记录2-object metadata/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/openstack源码阅读记录2-object metadata/","excerpt":"","text":"通过调试,得到object metadata的格式:","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"openstack-swift源码阅读记录1-文件上传过程","slug":"openstack-swift源码阅读记录1-文件上传过程","date":"2017-02-12T00:00:00.000Z","updated":"2017-02-13T09:07:50.308Z","comments":true,"path":"对象存储/openstack-swift源码阅读记录1-文件上传过程/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/openstack-swift源码阅读记录1-文件上传过程/","excerpt":"使用命令:1swift upload\n上传文件,openstack-swift调用过程\n入口函数","text":"使用命令:1swift upload 上传文件,openstack-swift调用过程 入口函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def HEAD(self, request): \"\"\"Handle HTTP HEAD requests for the Swift Object Server.\"\"\" device, partition, account, container, obj, policy = \\ get_name_and_placement(request, 5, 5, True) #从请求中获取相应信息,其中: #policy:根据request中的X-Backend-Storage-Policy-Index获得 #device, partition, account, container, obj根据request.path获得 frag_prefs = safe_json_loads( request.headers.get('X-Backend-Fragment-Preferences')) try: disk_file = self.get_diskfile( device, partition, account, container, obj, policy=policy, frag_prefs=frag_prefs) # disk_file:BaseDiskFile对象 except DiskFileDeviceUnavailable: return HTTPInsufficientStorage(drive=device, request=request) try: metadata = disk_file.read_metadata() #从object中读取metadata except DiskFileXattrNotSupported: return HTTPInsufficientStorage(drive=device, request=request) except (DiskFileNotExist, DiskFileQuarantined) as e: headers = &#123;&#125; if hasattr(e, 'timestamp'): headers['X-Backend-Timestamp'] = e.timestamp.internal return HTTPNotFound(request=request, headers=headers, conditional_response=True) conditional_etag = resolve_etag_is_at_header(request, metadata) response = Response(request=request, conditional_response=True, conditional_etag=conditional_etag) response.headers['Content-Type'] = metadata.get( 'Content-Type', 'application/octet-stream') for key, value in metadata.items(): if (is_sys_or_user_meta('object', key) or is_object_transient_sysmeta(key) or key.lower() in self.allowed_headers): response.headers[key] = value response.etag = metadata['ETag'] ts = Timestamp(metadata['X-Timestamp']) response.last_modified = math.ceil(float(ts)) # Needed for container sync feature response.headers['X-Timestamp'] = ts.normal response.headers['X-Backend-Timestamp'] = ts.internal response.headers['X-Backend-Data-Timestamp'] = \\ disk_file.data_timestamp.internal if disk_file.durable_timestamp: response.headers['X-Backend-Durable-Timestamp'] = \\ disk_file.durable_timestamp.internal response.headers['X-Backend-Fragments'] = \\ _make_backend_fragments_header(disk_file.fragments) response.content_length = int(metadata['Content-Length']) try: response.content_encoding = metadata['Content-Encoding'] except KeyError: pass return response 获取diskfile过程12345678# obj/server.py 中的get_diskfile,通过BaseDiskFileManager中的get_diskfile方法,返回BaseDiskFile对象# get_diskfile返回BaseDiskFile对象return self.diskfile_cls(self, dev_path, partition, account, container, obj, policy=policy, use_splice=self.use_splice, pipe_size=self.pipe_size, use_linkat=self.use_linkat, **kwargs) # diskfile_cls : BaseDiskFile","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"文件合并存储与单个存储优劣势分析","slug":"文件系统(seaweedfs)与关系型数据库优劣势分析","date":"2017-02-08T00:00:00.000Z","updated":"2017-02-10T15:24:26.352Z","comments":true,"path":"文件系统/文件系统(seaweedfs)与关系型数据库优劣势分析/","link":"","permalink":"https://makeitpossible16.github.io/文件系统/文件系统(seaweedfs)与关系型数据库优劣势分析/","excerpt":"","text":"问题引入经过一段时间的学习，想要把openstack-swift与seaweedfs进行结合，单纯考虑文件存储效率，对比把openstack-swift与seaweedfs进行结合后的存储效率是否会高于openstack-swift.问题最后可以简化为文件合并存储与单个存储优劣势比较. 具体分析文件单个存储从Linux内核文件系统出发,以ext3为例,参考深入解析Linux内核I/O剖析（open,write实现）,do_filp_open函数,Ext3文件系统读写过程分析当用户执行文件读写操作时,首先需要open相应的文件，然后再进行读写操作。在open操作时，首先将用户空间的文件名参数复制到内核空间,Linux kernel会执行do_filp_open函数,在do_filp_open函数中,沿着要打开文件名的整个路径，一层层解析路径，最后得到文件的dentry和vfsmount对象，保存到一个nameidata结构中,根据获得的nameidata结构，初始化一个file对象描述这个文件,File对象和文件的dentry和inode对象建立联系，并且将ext3的文件操作方法、映射处理方法（address space）注册到file对象中。File数据结构是Linux用来描述文件的关键数据结构，该对象在一个文件被进程打开的时候被创建。当一个文件被关闭的时候，file对象也会被立即销毁。执行open的最终结果:将文件描述符fd与文件管理结构file对应起来 文件合并存储文件读写是,若文件没有关闭,只需进行一次open操作,直接以lseek为例,参考linux内核文件IO的系统调用实现分析(flseek&amp;close),使用lseek,设置文件开始读取的位置,当调用read或write时直接从该位置读取数据. 结论 存储方式 优势 劣势 文件单个存储 存储过程简单,进行读写时直接进行读取,不需要进行lseek 容易产生页面空洞,导致磁盘扇区利用率降低,大量的文件,会增加文件系统需要维护的inode及dentry,降低文件存储效率. 合并存储 多个文件合并存储,减少文件系统需要维护的inode及dentry,文件连续写入,提高扇区利用率 文件读写时,需要进行lseek,增加文件偏移量查找操作 总结对于大规模存储系统,若能把大文件与小文件进行分开存储,大文件采用单文件存储,小文件使用合并存储,理论上可以提高系统存储效率.可以把openstack-swift与seaweedfs的存储部分进行结合,优化openstack-swift对象存储效率.","raw":null,"content":null,"categories":[{"name":"文件系统","slug":"文件系统","permalink":"https://makeitpossible16.github.io/categories/文件系统/"}],"tags":[{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"},{"name":"文件系统","slug":"文件系统","permalink":"https://makeitpossible16.github.io/tags/文件系统/"}]},{"title":"python语法记录","slug":"python语法记录","date":"2017-02-07T00:00:00.000Z","updated":"2017-02-13T08:36:26.483Z","comments":true,"path":"python语法/python语法记录/","link":"","permalink":"https://makeitpossible16.github.io/python语法/python语法记录/","excerpt":"","text":"记录一下忘记的Python语法 StringIO负责在内存中读写string,其中在openstack-swift的mem_diskfile.py中提到::param fp: StringIO in-memory representation objectStringIO和BytesIO os.fstat()os.fstat() 方法用于返回文件描述符fd的状态，类似 stat()。Python os.fstat() 方法","raw":null,"content":null,"categories":[{"name":"python语法","slug":"python语法","permalink":"https://makeitpossible16.github.io/categories/python语法/"}],"tags":[{"name":"python","slug":"python","permalink":"https://makeitpossible16.github.io/tags/python/"}]},{"title":"数据结构","slug":"数据结构","date":"2017-02-07T00:00:00.000Z","updated":"2017-02-07T13:37:16.495Z","comments":true,"path":"数据结构/数据结构/","link":"","permalink":"https://makeitpossible16.github.io/数据结构/数据结构/","excerpt":"","text":"数据结构都忘得差不多了,记录一下 二叉树遍历数据结构（六）——二叉树 前序、中序、后序、层次遍历及非递归实现 查找、统计个数、比较、求深度的递归实现前序遍历：根节点-&gt;左子树-&gt;右子树中序遍历：左子树-&gt;根节点-&gt;右子树后序遍历：左子树-&gt;右子树-&gt;根节点","raw":null,"content":null,"categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://makeitpossible16.github.io/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://makeitpossible16.github.io/tags/数据结构/"}]},{"title":"ubuntu16.04搭建openstack-swift单机开发环境","slug":"ubuntu16.04搭建openstack-swift单机开发环境","date":"2017-01-30T00:00:00.000Z","updated":"2017-02-25T09:07:08.089Z","comments":true,"path":"对象存储/ubuntu16.04搭建openstack-swift单机开发环境/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/ubuntu16.04搭建openstack-swift单机开发环境/","excerpt":"","text":"使用虚拟机进行远程调试电脑太卡，用着不爽，所以搭建单机板环境，按照SAIO搭建,在Ubuntu14.04上搭建没有啥问题，但在Ubuntu16.04上会出现问题，记录一下。 出现问题1123456789101112Traceback (most recent call last): File \"/usr/local/bin/swift-object-server\", line 6, in &lt;module&gt; exec(compile(open(__file__).read(), __file__, 'exec')) File \"/home/ubuntu/swift/bin/swift-object-server\", line 19, in &lt;module&gt; from swift.common.wsgi import run_wsgi File \"/home/ubuntu/swift/swift/common/wsgi.py\", line 41, in &lt;module&gt; from swift.common.storage_policy import BindPortsCache File \"/home/ubuntu/swift/swift/common/storage_policy.py\", line 25, in &lt;module&gt; from pyeclib.ec_iface import ECDriver, ECDriverError, VALID_EC_TYPES File \"/usr/local/lib/python2.7/dist-packages/pyeclib/ec_iface.py\", line 29, in &lt;module&gt; from pyeclib_c import check_backend_availableImportError: /usr/local/lib/python2.7/dist-packages/pyeclib_c.so: undefined symbol: liberasurecode_backend_available 系统找不到liberasurecode_backend_available。 解决方法参考openstack-swift bug反馈，得到解决方法:根据Alex Usov 的回答：Finally got it working. Had to compile liberasurecode from https://github.com/openstack/liberasurecode.git (https://github.com/openstack/liberasu…), add line /usr/local/lib to /etc/ld.so.conf, run ldconfig, and restart openstack-swift-proxy. 具体操作：1234567$ git clone https://github.com/openstack/liberasurecode.git$ cd liberasurecode$ ./autogen.sh$ ./configure$ make$ make test$ sudo make install 在 /etc/ld.so.conf中添加一行：/usr/local/lib运行 ldconfig 创建container失败错误提示: 404Container PUT failed: http://127.0.0.1:8080/v1/AUTH_test/test 404 Not Found [first 60 chars of response] Not FoundThe resource could not be found. 解决方法参考unable to create containers错误出现原因: 删除了相关存储文件夹,即/mnt/sdb1 或 /srv 中相关文件夹,按照SAIO - Swift All In One重新搭建环境即可 502 Server dropped connection发起请求时出现502错误:12$ swift statAuth GET failed: http://127.0.0.1:8080/auth/v1.0 502 Server dropped connection [first 60 chars of response] &lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//E 解决方法:把代理关掉","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"查找-数据结构学习","slug":"查找-数据结构学习","date":"2017-01-21T00:00:00.000Z","updated":"2017-02-14T04:08:27.481Z","comments":true,"path":"数据结构/查找-数据结构学习/","link":"","permalink":"https://makeitpossible16.github.io/数据结构/查找-数据结构学习/","excerpt":"","text":"简单清晰的B树、Trie树详解简单清晰的B树、Trie树详解","raw":null,"content":null,"categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://makeitpossible16.github.io/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://makeitpossible16.github.io/tags/数据结构/"}]},{"title":"linux文件存储机制","slug":"linux文件存储机制","date":"2017-01-21T00:00:00.000Z","updated":"2017-01-21T14:05:03.896Z","comments":true,"path":"文件存储/linux文件存储机制/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/linux文件存储机制/","excerpt":"","text":"Linux 内核的文件 Cache 管理机制介绍从内核文件系统看文件读写过程","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://makeitpossible16.github.io/tags/linux/"},{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/tags/文件存储/"}]},{"title":"openstack-swift调试","slug":"openstack-swift调试","date":"2017-01-21T00:00:00.000Z","updated":"2017-01-29T14:29:46.391Z","comments":true,"path":"对象存储/openstack-swift调试/","link":"","permalink":"https://makeitpossible16.github.io/对象存储/openstack-swift调试/","excerpt":"","text":"最近在学习openstack-swift的源码，想通过调试的方式弄清楚它的运行方式，记录一下，提高一下效率。 启用调试按照swift all in one的方式搭建，没遇到啥问题。调试的方案有两种（都支持远程调试），一种是采用pydev,这种方式需要禁用swift的多线程；另一种采用winpdb，这种方式支持多线程。禁用多线程：1eventlet.patcher.monkey_patch(all=False, socket=True, time=True, thread=False) 使用pydevd调试 我主要采用pycharm + pydevd + NFS的方式远程调试，具体操作参照这两篇文章：openstack调试远程调试其实只要使用NFS把代码挂载到本地，在pycharm中设置远程调试，代码中加入断点即可。加入断点代码 12import pydevdpydevd.settrace(&lt;pycharm所在机子IP&gt;, 设置端口, stdoutToServer=True, stderrToServer=True) 使用winpdb调试在代码中加入断点 12import rpdb2rpdb2.start_embedded_debugger(&apos;12345&apos;,fAllowRemote=True) start_embedded_debugger第一个参数为密码，在winpdb中attach时输入，第二个参数启用远程调试，启用远程调试时，在远程调试的机子上启动winpdb，attach时输入密码，并输入swift部署机子IP即可。 总结我喜欢用方式一，可以把调试的信息直接标注在代码旁。方式二支持分布式调试，但太轻量化，只能看，不能添加，各有优缺点，按需选择。修改代码后需要重启swift才能生效。调试记录信息会放到github上，github地址","raw":null,"content":null,"categories":[{"name":"对象存储","slug":"对象存储","permalink":"https://makeitpossible16.github.io/categories/对象存储/"}],"tags":[{"name":"openstack-swift","slug":"openstack-swift","permalink":"https://makeitpossible16.github.io/tags/openstack-swift/"}]},{"title":"kafka学习笔记","slug":"kafka学习笔记","date":"2017-01-11T00:00:00.000Z","updated":"2017-01-21T11:58:44.205Z","comments":true,"path":"kafka/kafka学习笔记/","link":"","permalink":"https://makeitpossible16.github.io/kafka/kafka学习笔记/","excerpt":"","text":"学习资源kafka入门介绍 学习目的构建日志流处理系统，初步实现使用logstash进行日志采集，kafka作为缓存队列，flink进行实时数据分析处理，seaweedfs作为后端存储。 笔记核心API类型应用程序使用 Producer API 发布消息到1个或多个topic（主题）。应用程序使用 Consumer API 来订阅一个或多个topic，并处理产生的消息。应用程序使用 Streams API 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。Connector API允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。 基本术语Topic Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).Producer 发布消息的对象称之为主题生产者(Kafka topic producer)Consumer 订阅消息并处理发布的消息的种子的对象称之为主题消费者(consumers)Broker 已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。 消费者通常来讲，消息模型可以分为两种， 队列和发布-订阅式。 队列的处理方式是 一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。在发布-订阅模型中，消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。Kafka为这两种模型提供了单一的消费者抽象模型： 消费者组 （consumer group）。 消费者用一个消费者组名标记自己。 一个发布在Topic上消息被分发给此消费者组中的一个消费者。 假如所有的消费者都在一个组中，那么这就变成了queue模型。 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 kafka有比传统的消息系统更强的顺序保证如果多个消费者从队列消费，则服务器按存储的顺序发送消息，但是，尽管服务器按顺序发送，消息异步传递到消费者，因此消息可能乱序到达消费者。kafka通过并行topic的parition —— kafka提供了顺序保证和负载均衡。每个partition仅由同一个消费者组中的一个消费者消费到。并确保消费者是该partition的唯一消费者，并按顺序消费数据。每个topic有多个分区，则需要对多个消费者做负载均衡，但请注意，相同的消费者组中不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息。 kafka可作为存储系统","raw":null,"content":null,"categories":[{"name":"kafka","slug":"kafka","permalink":"https://makeitpossible16.github.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://makeitpossible16.github.io/tags/kafka/"}]},{"title":"linux内核学习-数据结构","slug":"linux内核学习-数据结构","date":"2017-01-04T00:00:00.000Z","updated":"2017-01-21T13:35:37.846Z","comments":true,"path":"linux内核/linux内核学习-数据结构/","link":"","permalink":"https://makeitpossible16.github.io/linux内核/linux内核学习-数据结构/","excerpt":"","text":"container_of用于从包含在某个结构中的指针获得结构本身的指针，通俗地讲就是通过结构体变量中某个成员的首地址进而获得整个结构体变量的首地址。Linux内核中的常用宏container_of其实很简单 linux内核Hash 链表Linux内核哈希表分析与应用 Hash应用:有一个庞大的字符串数组，然后给你一个单独的字符串，让你从这个数组中查找是否有这个字符串并找到它暴雪公司关于字符串匹配的hash算法 典型的应用场景(Hbase，Accumulo，Leveldb)：某些存储系统的设计中，会存在空查询缺陷：当查询一个不存在的key时，需要访问慢设备，导致效率低下。比如一个前端页面的缓存系统，可能这样设计：先查询某个页面在本地是否存在，如果存在就直接返回，如果不存在，就从后端获取。但是当频繁从缓存系统查询一个页面时，缓存系统将会频繁请求后端，把压力导入后端。这是只要增加一个bloom算法的服务，后端插入一个key时，在这个服务中设置一次需要查询后端时，先判断key在后端是否存在，这样就能避免后端的压力。布隆过滤器(Bloom Filter)详解算法学习 - Bloom Filter(布隆过滤器)学习实现(C++实现) RadixTree（基数树）应用：Linux radix树最广泛的用途是用于内存管理，结构address_space通过radix树跟踪绑定到地址映射上的核心页，该radix树允许内存管理代码快速查找标识为dirty或writeback的页。其使用的是数据类型unsigned long的固定长度输入的版本。每级代表了输入空间固定位数。Linux radix树的API函数在lib/radix-tree.c中实现。（把页指针和描述页状态的结构映射起来，使能快速查询一个页的信息。）RadixTree（基数树）","raw":null,"content":null,"categories":[{"name":"linux内核","slug":"linux内核","permalink":"https://makeitpossible16.github.io/categories/linux内核/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://makeitpossible16.github.io/tags/linux/"},{"name":"内核","slug":"内核","permalink":"https://makeitpossible16.github.io/tags/内核/"},{"name":"数据结构","slug":"数据结构","permalink":"https://makeitpossible16.github.io/tags/数据结构/"}]},{"title":"linux命令学习","slug":"linux命令学习","date":"2017-01-02T00:00:00.000Z","updated":"2017-02-25T04:00:15.707Z","comments":true,"path":"linux命令/linux命令学习/","link":"","permalink":"https://makeitpossible16.github.io/linux命令/linux命令学习/","excerpt":"","text":"虽然使用linux有很长一段时间,但对于一些平时用不到的命令,还是比较生疏,记录一下 awkAWK是一种处理文本文件的语言，是一个强大的文本分析工具。awk使用介绍awk print 学习 sort用于排序linux之sort用法 uniq报告或删除文件中重复的行。linux uniq 命令详解 tee读取标准输入的数据，并将其内容输出成文件linux tee 命令详解 /dev/null可以把/dev/null看作一个”黑洞”，它非常等价于一个只写文件，所有写入它的内容都会永远丢失。linux下/dev/null的用途Linux下” &gt;/dev/null 2&gt;&amp;1 “相关知识说明 nohup程序后台运行,如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令.命令格式 : nohup command &amp;linux nohup命令详解 screenscreen 算是 linux 运维一个中高级技巧。通过 screen 命令创建的环境下运行的终端命令，其父进程不是 sshd 登录会话，而是 screen 。这样就可以即避免用户退出进程消失的问题，又随时能重新接管回终端继续操作。创建独立的 screen 命令如下：screen -dmS elkscreen_1接管连入创建的 elkscreen_1 命令如下：screen -r elkscreen_1然后你可以看到一个一模一样的终端，运行 logstash 之后，不要按 Ctrl+C，而是按 Ctrl+A+D 键，断开环境。想重新接管，依然 screen -r elkscreen_1 即可。如果创建了多个 screen，查看列表命令如下：screen -list需要长期后台运行的大量程序,使用daemontools xargs参考管道命令和xargs的区别(经典解释)管道是实现“将前面的标准输出作为后面的标准输入”xargs是实现“将标准输入作为命令的参数”运行:12echo &quot;--help&quot;|catecho &quot;--help&quot;|xargs cat 得到结果:123456789101112131415161718192021222324252627282930ubuntu@ubuntu-Aspire-V3-571G:~$ echo &quot;--help&quot;|cat--helpubuntu@ubuntu-Aspire-V3-571G:~$ echo &quot;--help&quot;|xargs cat用法：cat [选项]... [文件]...Concatenate FILE(s) to standard output.如果没有指定文件，或者文件为&quot;-&quot;，则从标准输入读取。 -A, --show-all equivalent to -vET -b, --number-nonblank number nonempty output lines, overrides -n -e equivalent to -vE -E, --show-ends display $ at end of each line -n, --number number all output lines -s, --squeeze-blank suppress repeated empty output lines -t 与-vT 等价 -T, --show-tabs 将跳格字符显示为^I -u (被忽略) -v, --show-nonprinting 使用^ 和M- 引用，除了LFD和 TAB 之外 --help 显示此帮助信息并退出 --version 显示版本信息并退出示例： cat f - g 先输出f 的内容，然后输出标准输入的内容，最后输出g 的内容。 cat 将标准输入的内容复制到标准输出。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告cat 的翻译错误Full documentation at: &lt;http://www.gnu.org/software/coreutils/cat&gt;or available locally via: info &apos;(coreutils) cat invocation&apos;ubuntu@ubuntu-Aspire-V3-571G:~$ sed批量替换字符串,如:1find /etc/swift/ -name \\*.conf | xargs sudo sed -i &quot;s/&lt;your-user-name&gt;/$&#123;USER&#125;/&quot; 把/etc/swift/文件夹下 *.conf 文件中的批量替换为计算机用户名参考linux sed 批量替换字符串","raw":null,"content":null,"categories":[{"name":"linux命令","slug":"linux命令","permalink":"https://makeitpossible16.github.io/categories/linux命令/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://makeitpossible16.github.io/tags/linux/"}]},{"title":"ELKStack搭建问题总结","slug":"ELKStack搭建问题总结","date":"2017-01-02T00:00:00.000Z","updated":"2017-01-02T15:58:17.559Z","comments":true,"path":"ELKStack/ELKStack搭建问题总结/","link":"","permalink":"https://makeitpossible16.github.io/ELKStack/ELKStack搭建问题总结/","excerpt":"","text":"使用Docker搭建ELKStack时,elasticsearch自动退出,使用1docker logs [dockerName] 问题查看日志, 日志输出为12ERROR: bootstrap checks failedmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案Elasticsearch5.0 安装问题集锦 切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置： vm.max_map_count=655360 并执行命令： sysctl -p 然后，重新启动elasticsearch，即可启动成功。","raw":null,"content":null,"categories":[{"name":"ELKStack","slug":"ELKStack","permalink":"https://makeitpossible16.github.io/categories/ELKStack/"}],"tags":[{"name":"ELKStack","slug":"ELKStack","permalink":"https://makeitpossible16.github.io/tags/ELKStack/"},{"name":"日志分析","slug":"日志分析","permalink":"https://makeitpossible16.github.io/tags/日志分析/"},{"name":"流处理","slug":"流处理","permalink":"https://makeitpossible16.github.io/tags/流处理/"}]},{"title":"linux学习-linux文件存储","slug":"linux学习-linux文件存储","date":"2017-01-01T00:00:00.000Z","updated":"2017-02-14T04:08:59.965Z","comments":true,"path":"文件存储/linux学习-linux文件存储/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/linux学习-linux文件存储/","excerpt":"","text":"linux文件存储一直对文件存储过程不太理解,估计是操作系统没学好,今天看了这篇文章Linux文件存储结构，包括目录项、inode、数据块,感觉思路一下子清晰了. 根据linux一切皆文件的思想,目录项也作为一个文件存储,存储的内容为inode和文件名. linux文件查找文件系统中的目录查找Linux中文件名解析处理源码分析","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://makeitpossible16.github.io/tags/linux/"}]},{"title":"seaweedfs源码阅读记录9-生成fid过程","slug":"seaweedfs源码阅读记录9-生成fid过程","date":"2016-12-16T00:00:00.000Z","updated":"2016-12-16T14:27:23.010Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录9-生成fid过程/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读记录9-生成fid过程/","excerpt":"","text":"使用命令 : curl -X POST http://localhost:9333/dir/assign 在topology.go 中12345678func (t *Topology) PickForWrite(count uint64, option *VolumeGrowOption) (string, uint64, *DataNode, error) &#123;truevid, count, datanodes, err := t.GetVolumeLayout(option.Collection, option.ReplicaPlacement, option.Ttl).PickForWrite(count, option)trueif err != nil || datanodes.Length() == 0 &#123;truetruereturn \"\", 0, nil, errors.New(\"No writable volumes available!\")true&#125;truefileId, count := t.Sequence.NextFileId(count) // fileId = 1050682, count = 1truereturn storage.NewFileId(*vid, fileId, rand.Uint32()).String(), count, datanodes.Head(), nil //调用file_id.go中的NewFileId函数&#125; 在file_id.go 中123456789type FileId struct &#123;trueVolumeId VolumeIdtrueKey uint64 // fileId = 1050682trueHashcode uint32 // rand.Uint32()&#125;func NewFileId(VolumeId VolumeId, Key uint64, Hashcode uint32) *FileId &#123;truereturn &amp;FileId&#123;VolumeId: VolumeId, Key: Key, Hashcode: Hashcode&#125;&#125; 使用memory_sequencer.go中的函数1234567func (m *MemorySequencer) NextFileId(count uint64) (uint64, uint64) &#123; // count = 1truem.sequenceLock.Lock()truedefer m.sequenceLock.Unlock()trueret := m.countertruem.counter += uint64(count)truereturn ret, count&#125; 调试信息1234(dlv) p m*github.com/chrislusf/seaweedfs/weed/sequence.MemorySequencer &#123;truecounter: 1050683,truesequenceLock: sync.Mutex &#123;state: 1, sema: 0&#125;,&#125; 在 master_server_handlers.go 中封装信息123456fid, count, dn, err := ms.Topo.PickForWrite(requestedCount, option)trueif err == nil &#123;truetruewriteJsonQuiet(w, r, http.StatusOK, operation.AssignResult&#123;Fid: fid, Url: dn.Url(), PublicUrl: dn.PublicUrl, Count: count&#125;)true&#125; else &#123;truetruewriteJsonQuiet(w, r, http.StatusNotAcceptable, operation.AssignResult&#123;Error: err.Error()&#125;)true&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读8-GET&HEAD获取文件过程","slug":"seaweedfs源码阅读8-GET&HEAD获取文件过程","date":"2016-12-15T00:00:00.000Z","updated":"2016-12-15T12:08:29.759Z","comments":true,"path":"文件存储/seaweedfs源码阅读8-GET&HEAD获取文件过程/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读8-GET&HEAD获取文件过程/","excerpt":"","text":"GET 文件请求1http://127.0.0.1:8080/27542,10088ee11dccb9 先生成一个新的needle,然后根据fid:10088ee11dccb9 , 其中,前8位使用16进制转换为uint64 ==&gt; key, 后6位使用16进制转换为uint32 ==&gt; hash,解析结果给新生成的needle赋值,n.Id=key, n.Cookie=hash 如果当前的volumeServer没有找到请求的volumeId123456789101112131415161718192021222324if !vs.store.HasVolume(volumeId) &#123;truetrueif !vs.ReadRedirect &#123;truetruetrueglog.V(2).Infoln(\"volume is not local:\", err, r.URL.Path)truetruetruew.WriteHeader(http.StatusNotFound)truetruetruereturntruetrue&#125;truetruelookupResult, err := operation.Lookup(vs.GetMasterNode(), volumeId.String())truetrueglog.V(2).Infoln(\"volume\", volumeId, \"found on\", lookupResult, \"error\", err)truetrueif err == nil &amp;&amp; len(lookupResult.Locations) &gt; 0 &#123;truetruetrueu, _ := url.Parse(util.NormalizeUrl(lookupResult.Locations[0].PublicUrl))truetruetrueu.Path = r.URL.Pathtruetruetruearg := url.Values&#123;&#125;truetruetrueif c := r.FormValue(\"collection\"); c != \"\" &#123;truetruetruetruearg.Set(\"collection\", c)truetruetrue&#125;truetruetrueu.RawQuery = arg.Encode()truetruetruehttp.Redirect(w, r, u.String(), http.StatusMovedPermanently)truetrue&#125; else &#123;truetruetrueglog.V(2).Infoln(\"lookup error:\", err, r.URL.Path)truetruetruew.WriteHeader(http.StatusNotFound)truetrue&#125;truetruereturntrue&#125; 在volume_read_write.go 中,调用readNeedle,通过已知的n.Id ,获取存储的needle信息,操作在needle_map_memory.go 中1234func (nm *NeedleMap) Get(key uint64) (element *NeedleValue, ok bool) &#123;trueelement, ok = nm.m.Get(Key(key))truereturn&#125; 12(dlv) p element*github.com/chrislusf/seaweedfs/weed/storage.NeedleValue &#123;Key: 1050766, Offset: 1, Size: 529810&#125; 与上传信息对比上传时返回信息:{“fid”:”27542,10088ee11dccb9”,”fileName”:”raft.pdf”,”fileUrl”:”127.0.0.1:8080/27542,10088ee11dccb9”,”size”:529766}此时信息{Key: 1050766, Offset: 1, Size: 529810}存储时以needle为单位,增加的大小为needle中其他数据的大小,如n.Id,n.Cookie 获取数据123456789101112131415161718192021222324252627func (n *Needle) ReadData(r *os.File, offset int64, size uint32, version Version) (err error) &#123;truebytes, block, err := ReadNeedleBlob(r, offset, size)trueif err != nil &#123;truetruereturn errtrue&#125;truen.rawBlock = blocktruen.ParseNeedleHeader(bytes)trueif n.Size != size &#123;truetruereturn fmt.Errorf(\"File Entry Not Found. Needle %d Memory %d\", n.Size, size)true&#125;trueswitch version &#123;truecase Version1:truetruen.Data = bytes[NeedleHeaderSize : NeedleHeaderSize+size]truecase Version2:truetruen.readNeedleDataVersion2(bytes[NeedleHeaderSize : NeedleHeaderSize+int(n.Size)]) // 从bytes中读取存储数据,并设置needle的属性true&#125;trueif size == 0 &#123;truetruereturn niltrue&#125;truechecksum := util.BytesToUint32(bytes[NeedleHeaderSize+size : NeedleHeaderSize+size+NeedleChecksumSize])truenewChecksum := NewCRC(n.Data)trueif checksum != newChecksum.Value() &#123;truetruereturn errors.New(\"CRC error! Data On Disk Corrupted\")true&#125;truen.Checksum = newChecksumtruereturn nil&#125; 123456789101112131415161718192021222324252627282930313233343536func (n *Needle) readNeedleDataVersion2(bytes []byte) &#123;trueindex, lenBytes := 0, len(bytes)trueif index &lt; lenBytes &#123;truetruen.DataSize = util.BytesToUint32(bytes[index : index+4])truetrueindex = index + 4truetrueif int(n.DataSize)+index &gt; lenBytes &#123;truetruetrue// this if clause is due to bug #87 and #93, fixed in v0.69truetruetrue// remove this clause latertruetruetruereturntruetrue&#125;truetruen.Data = bytes[index : index+int(n.DataSize)]truetrueindex = index + int(n.DataSize)truetruen.Flags = bytes[index]truetrueindex = index + 1true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasName() &#123;truetruen.NameSize = uint8(bytes[index])truetrueindex = index + 1truetruen.Name = bytes[index : index+int(n.NameSize)]truetrueindex = index + int(n.NameSize)true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasMime() &#123;truetruen.MimeSize = uint8(bytes[index])truetrueindex = index + 1truetruen.Mime = bytes[index : index+int(n.MimeSize)]truetrueindex = index + int(n.MimeSize)true&#125;trueif index &lt; lenBytes &amp;&amp; n.HasLastModifiedDate() &#123;truetruen.LastModified = util.BytesToUint64(bytes[index : index+LastModifiedBytesLength])truetrueindex = index + LastModifiedBytesLengthtrue&#125;trueif index &lt; lenBytes &amp;&amp; n.HasTtl() &#123;truetruen.Ttl = LoadTTLFromBytes(bytes[index : index+TtlBytesLength])truetrueindex = index + TtlBytesLengthtrue&#125;&#125; 总结根据请求URL中带有的fid, 解析,得到n.Id, n.Cookie,其中,n.Id 作为needle的唯一标识,在NeedleMapper中找到存储的needle信息,n.Cookie 作为数据验证信息,若找到的needle中的cookie于URL中的cookie不一致,返回错误信息.","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读7-文件存储过程","slug":"seaweedfs源码阅读7-文件存储过程","date":"2016-12-13T00:00:00.000Z","updated":"2016-12-15T03:13:10.345Z","comments":true,"path":"文件存储/seaweedfs源码阅读7-文件存储过程/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读7-文件存储过程/","excerpt":"","text":"文件在volume_server_handlers_write.go 中的topology.ReplicatedWrite中以needle的形式存储,在store.go 的Write方法中调用writeNeedle写入文件.写入时使用append的方法,在文件中追加123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111// needle_read_write.gofunc (n *Needle) Append(w io.Writer, version Version) (size uint32, err error) &#123;trueif s, ok := w.(io.Seeker); ok &#123;truetrueif end, e := s.Seek(0, 1); e == nil &#123;truetruetruedefer func(s io.Seeker, off int64) &#123;truetruetruetrueif err != nil &#123;truetruetruetruetrueif _, e = s.Seek(off, 0); e != nil &#123;truetruetruetruetruetrueglog.V(0).Infof(\"Failed to seek %s back to %d with error: %v\", w, off, e)truetruetruetruetrue&#125;truetruetruetrue&#125;truetruetrue&#125;(s, end)truetrue&#125; else &#123;truetruetrueerr = fmt.Errorf(\"Cannot Read Current Volume Position: %v\", e)truetruetruereturntruetrue&#125;true&#125;trueswitch version &#123;truecase Version1:truetrueheader := make([]byte, NeedleHeaderSize)truetrueutil.Uint32toBytes(header[0:4], n.Cookie)truetrueutil.Uint64toBytes(header[4:12], n.Id)truetruen.Size = uint32(len(n.Data))truetruesize = n.Sizetruetrueutil.Uint32toBytes(header[12:16], n.Size)truetrueif _, err = w.Write(header); err != nil &#123;truetruetruereturntruetrue&#125;truetrueif _, err = w.Write(n.Data); err != nil &#123;truetruetruereturntruetrue&#125;truetruepadding := NeedlePaddingSize - ((NeedleHeaderSize + n.Size + NeedleChecksumSize) % NeedlePaddingSize)truetrueutil.Uint32toBytes(header[0:NeedleChecksumSize], n.Checksum.Value())truetrue_, err = w.Write(header[0 : NeedleChecksumSize+padding])truetruereturntruecase Version2:truetrueheader := make([]byte, NeedleHeaderSize)truetrueutil.Uint32toBytes(header[0:4], n.Cookie)truetrueutil.Uint64toBytes(header[4:12], n.Id)truetruen.DataSize, n.NameSize, n.MimeSize = uint32(len(n.Data)), uint8(len(n.Name)), uint8(len(n.Mime))truetrueif n.DataSize &gt; 0 &#123;truetruetruen.Size = 4 + n.DataSize + 1truetruetrueif n.HasName() &#123;truetruetruetruen.Size = n.Size + 1 + uint32(n.NameSize)truetruetrue&#125;truetruetrueif n.HasMime() &#123;truetruetruetruen.Size = n.Size + 1 + uint32(n.MimeSize)truetruetrue&#125;truetruetrueif n.HasLastModifiedDate() &#123;truetruetruetruen.Size = n.Size + LastModifiedBytesLengthtruetruetrue&#125;truetruetrueif n.HasTtl() &#123;truetruetruetruen.Size = n.Size + TtlBytesLengthtruetruetrue&#125;truetrue&#125; else &#123;truetruetruen.Size = 0truetrue&#125;truetruesize = n.DataSizetruetrueutil.Uint32toBytes(header[12:16], n.Size)truetrueif _, err = w.Write(header); err != nil &#123;truetruetruereturntruetrue&#125;truetrueif n.DataSize &gt; 0 &#123;truetruetrueutil.Uint32toBytes(header[0:4], n.DataSize)truetruetrueif _, err = w.Write(header[0:4]); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueif _, err = w.Write(n.Data); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueutil.Uint8toBytes(header[0:1], n.Flags)truetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruereturntruetruetrue&#125;truetruetrueif n.HasName() &#123;truetruetruetrueutil.Uint8toBytes(header[0:1], n.NameSize)truetruetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetruetrueif _, err = w.Write(n.Name); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasMime() &#123;truetruetruetrueutil.Uint8toBytes(header[0:1], n.MimeSize)truetruetruetrueif _, err = w.Write(header[0:1]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetruetrueif _, err = w.Write(n.Mime); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasLastModifiedDate() &#123;truetruetruetrueutil.Uint64toBytes(header[0:8], n.LastModified)truetruetruetrueif _, err = w.Write(header[8-LastModifiedBytesLength : 8]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetruetrueif n.HasTtl() &amp;&amp; n.Ttl != nil &#123;truetruetruetruen.Ttl.ToBytes(header[0:TtlBytesLength])truetruetruetrueif _, err = w.Write(header[0:TtlBytesLength]); err != nil &#123;truetruetruetruetruereturntruetruetruetrue&#125;truetruetrue&#125;truetrue&#125;truetruepadding := NeedlePaddingSize - ((NeedleHeaderSize + n.Size + NeedleChecksumSize) % NeedlePaddingSize)truetrueutil.Uint32toBytes(header[0:NeedleChecksumSize], n.Checksum.Value())truetrue_, err = w.Write(header[0 : NeedleChecksumSize+padding])truetruereturn n.DataSize, errtrue&#125;truereturn 0, fmt.Errorf(\"Unsupported Version! (%d)\", version)&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读6-文件存储格式","slug":"seaweedfs源码阅读6-文件存储格式","date":"2016-12-12T00:00:00.000Z","updated":"2016-12-13T03:26:44.809Z","comments":true,"path":"文件存储/seaweedfs源码阅读6-文件存储格式/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读6-文件存储格式/","excerpt":"","text":"使用put 上传文件到seaweedfs , 具体显示结果 上传的所有文件都以单个文件进行存储,后缀为 .dat 和 .idx","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读5-文件PUT过程","slug":"seaweedfs源码阅读5-文件PUT过程","date":"2016-12-11T00:00:00.000Z","updated":"2016-12-11T13:30:05.384Z","comments":true,"path":"文件存储/seaweedfs源码阅读5-文件PUT过程/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读5-文件PUT过程/","excerpt":"","text":"使用命令1234&gt; curl -X POST http://localhost:9333/dir/assign&#123;\"count\":1,\"fid\":\"3,01637037d6\",\"url\":\"127.0.0.1:8080\",\"publicUrl\":\"localhost:8080\"&#125;&gt; curl -X PUT -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6&#123;\"size\": 43234&#125; 上传文件,程序调用volume_server_handlers_write.go 中的PostHandler进行处理,根据URL,提取vid,生成新的volumeId12vid, _, _, _, _ := parseURLPath(r.URL.Path) //vid 为3volumeId, ve := storage.NewVolumeId(vid) // volumeId : 7 根据请求参数,生成needle1needle, ne := storage.NewNeedle(r, vs.FixJpgOrientation) 使用multipartReader读取请求中的数据,有关multipart的介绍: golang的multipart包使用needle.go 中的ParseUpload方法解析请求,得到上传的文件名和数据;如果上传的数据类型是JPG或jpeg,调用 images.FixJpgOrientation(n.Data)对数据进行处理生成needle过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func NewNeedle(r *http.Request, fixJpgOrientation bool) (n *Needle, e error) &#123;truefname, mimeType, isGzipped, isChunkedFile := \"\", \"\", false, falsetruen = new(Needle)truefname, n.Data, mimeType, isGzipped, n.LastModified, n.Ttl, isChunkedFile, e = ParseUpload(r)trueif e != nil &#123;truetruereturntrue&#125;trueif len(fname) &lt; 256 &#123;truetruen.Name = []byte(fname)truetruen.SetHasName()true&#125;trueif len(mimeType) &lt; 256 &#123;truetruen.Mime = []byte(mimeType)truetruen.SetHasMime()true&#125;trueif isGzipped &#123;truetruen.SetGzipped()true&#125;trueif n.LastModified == 0 &#123;truetruen.LastModified = uint64(time.Now().Unix())true&#125;truen.SetHasLastModifiedDate()trueif n.Ttl != EMPTY_TTL &#123;truetruen.SetHasTtl()true&#125;trueif isChunkedFile &#123;truetruen.SetIsChunkManifest()true&#125;trueif fixJpgOrientation &#123;truetrueloweredName := strings.ToLower(fname)truetrueif mimeType == \"image/jpeg\" || strings.HasSuffix(loweredName, \".jpg\") || strings.HasSuffix(loweredName, \".jpeg\") &#123;truetruetruen.Data = images.FixJpgOrientation(n.Data)truetrue&#125;true&#125;truen.Checksum = NewCRC(n.Data)truecommaSep := strings.LastIndex(r.URL.Path, \",\")truedotSep := strings.LastIndex(r.URL.Path, \".\")truefid := r.URL.Path[commaSep+1:]trueif dotSep &gt; 0 &#123;truetruefid = r.URL.Path[commaSep+1 : dotSep]true&#125;truee = n.ParsePath(fid)truereturn&#125; 把数据及needle相关属性填充完成后,同步到其他volumeServer中,已needle作为传输载体1size, errorStatus := topology.ReplicatedWrite(vs.GetMasterNode(),vs.store, volumeId, needle, r)","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读4-volume启动过程","slug":"seaweedfs源码阅读4-volume启动","date":"2016-12-11T00:00:00.000Z","updated":"2017-02-08T12:23:41.872Z","comments":true,"path":"文件存储/seaweedfs源码阅读4-volume启动/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读4-volume启动/","excerpt":"","text":"根据文章使用delve调试Golang程序技巧使用go install -gcflags “-N -l” weed.go 对程序进行重新编译,方便调试 通过weed.go 调用volume.go ,参数处理完成后,生成一个ServeMux实例,有关go http ServeMux介绍,12345volumeMux := http.NewServeMux()publicVolumeMux := volumeMuxif isSeperatedPublicPort &#123;truepublicVolumeMux = http.NewServeMux()&#125; 根据参数VolumeServerOptions 中的 indexType,选择volume Needle Map 的存储位置,默认使用内存1234567volumeNeedleMapKind := storage.NeedleMapInMemoryswitch *v.indexType &#123;case \"leveldb\": volumeNeedleMapKind = storage.NeedleMapLevelDbcase \"boltdb\": volumeNeedleMapKind = storage.NeedleMapBoltDb&#125; 调试信息12(dlv) p *v.indexType\"memory\" 根据参数生成volumeServer,使用volume_server.go 中的NewVolumeServer 生成volumeServer在volume_server.go 中,设置masterNode ,store, guard1234vs.SetMasterNode(masterNode)vs.store = storage.NewStore(port, ip, publicUrl, folders, maxCounts, vs.needleMapKind)vs.guard = security.NewGuard(whiteList, \"\") 生成store时会加载已有的volume123456789101112// store.gofunc NewStore(port int, ip, publicUrl string, dirnames []string, maxVolumeCounts []int, needleMapKind NeedleMapType) (s *Store) &#123;trues = &amp;Store&#123;Port: port, Ip: ip, PublicUrl: publicUrl&#125;trues.Locations = make([]*DiskLocation, 0)truefor i := 0; i &lt; len(dirnames); i++ &#123;truetruelocation := NewDiskLocation(dirnames[i], maxVolumeCounts[i])truetruelocation.loadExistingVolumes(needleMapKind)truetrues.Locations = append(s.Locations, location)true&#125;truereturn&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"golang调试技巧","slug":"golang调试技巧","date":"2016-12-10T00:00:00.000Z","updated":"2016-12-11T02:52:49.574Z","comments":true,"path":"go/golang调试技巧/","link":"","permalink":"https://makeitpossible16.github.io/go/golang调试技巧/","excerpt":"","text":"在阅读seaweedfs过程中,发现对于复杂程序,跟踪调试相当困难,不过,在看了使用delve调试Golang程序技巧这篇文章后,调试问题得到很好的改善. 首先,liteIDE简直让人眼前一亮,使用它并结合delve实现图形化界面调试,使用命令行多少有点不太方便,特别是当你想在源码中加入注释的时候. 具体实现 安装delve,liteIDE 加入参数关闭编译器优化,如 go install -gcflags “-N -l” 程序名称 按照文章使用delve调试Golang程序技巧, 调试外部程序 调试启动后,可在Console设置断点, 命令为 : b packageName.functionName 或 b lineNum 使用命令c ,运行到断点停止,进行操作,具体命令可参照delve 还不清楚liteIDE能不能使用delve 进行图形化attach,如果可以就非常完美","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"}]},{"title":"golang 反射机制","slug":"golang 反射机制","date":"2016-12-02T00:00:00.000Z","updated":"2016-12-04T07:55:20.022Z","comments":true,"path":"go/golang 反射机制/","link":"","permalink":"https://makeitpossible16.github.io/go/golang 反射机制/","excerpt":"","text":"在阅读seaweedfs过程中,当程序在运行过程中,想要进行跟踪调试不好实现,目前也没找到很好的解决方案,只能跟踪程序的启动过程.不过回归最原始的方法,使用printf倒是可以查看变量的值,因此打算编写程序,把struct中的变量转化为json,发送给搭建的服务器,实现查看struct变量的方法.其中就了解到go的反射机制. laws-of-reflectionGolang之反射reflect包 使用反射可以得到struct中的变量及变量的值,前提是该变量是export的,即首字母大写,类似java中的public.","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"}]},{"title":"golang学习","slug":"golang学习","date":"2016-11-29T00:00:00.000Z","updated":"2016-12-15T03:15:17.470Z","comments":true,"path":"go/golang学习/","link":"","permalink":"https://makeitpossible16.github.io/go/golang学习/","excerpt":"","text":"在看seaweedfs过程中遇到的go 语法,不会的记录一下. interface: 是一组method的组合,通过interface来定义对象的一组行为.12345type Sequencer interface &#123;trueNextFileId(count uint64) (uint64, uint64)trueSetMax(uint64)truePeek() uint64&#125; go map1t.children = make(map[NodeId]Node) // NodeId --&gt; Node go sync.RWMutex和sync.Mutexgolang中sync包实现了两种锁Mutex （互斥锁）和RWMutex（读写锁），其中RWMutex是基于Mutex实现的，只读锁的实现使用类似引用计数器的功能．1234type Mutex func (m *Mutex) Lock() func (m *Mutex) Unlock() Mutex为互斥锁，Lock()加锁，Unlock()解锁，使用Lock()加锁后，便不能再次对其进行加锁，直到利用Unlock()解锁对其解锁后，才能再次加锁．适用于读写不确定场景，即读写次数没有明显的区别，并且只允许只有一个读或者写的场景，所以该锁也叫做全局锁． 123456type RWMutex func (rw *RWMutex) Lock() func (rw *RWMutex) RLock() func (rw *RWMutex) RLocker() Locker func (rw *RWMutex) RUnlock() func (rw *RWMutex) Unlock() func (rw RWMutex) Lock() 写锁，如果在添加写锁之前已经有其他的读锁和写锁，则lock就会阻塞直到该锁可用，为确保该锁最终可用，已阻塞的 Lock 调用会从获得的锁中排除新的读取器，即写锁权限高于读锁，有写锁时优先进行写锁定 func (rw RWMutex) Unlock() 写锁解锁，如果没有进行写锁定，则就会引起一个运行时错误． func (rw *RWMutex) RLock() 读锁，当有写锁时，无法加载读锁，当只有读锁或者没有锁时，可以加载读锁，读锁可以加载多个，所以适用于＂读多写少＂的场景 func (rw *RWMutex)RUnlock() 读锁解锁，RUnlock 撤销单次 RLock 调用，它对于其它同时存在的读取器则没有效果。若 rw 并没有为读取而锁定，调用 RUnlock 就会引发一个运行时错误(注：这种说法在go1.3版本中是不对的，例如下面这个例子)。 go Routine和Channelgo学习笔记_Routine和Channel上 goroutine 类似开辟进程、线程做法语法： 1. 定义一个函数functionName，要异步调用时使用语句go functionName即可。 2. 使用匿名函数，用法为go func(参数列表){函数执行体}()，说明最后一个()作用就是让该函数执行。 代码： 123456789101112131415/////////第一种示例代码：///////////func sayHello(name string)&#123; fmt.Println(\"hello\"+name)&#125;//主程序入口func main()&#123; go sayHello(\"PMST\")&#125;/////////第二种示例代码：////////////主程序入口func main()&#123; go func()&#123; fmt.Println(\"hello world\") &#125;() //别忘记这里的()&#125; 一旦将go放在函数之前，意味分配一个子routine让这个函数自个玩去(有点自身自灭的感觉),而主routine则继续该干嘛干嘛。 channelgoroutine 之间进行数据通信方式： 共用内存内存空间。 Go语言推荐的通信机制channel。 通过make来创建channel,例如无缓存ci := make(chan int),指定缓存cib := make(chan int,2)。给这个通道分类了2个缓存空间 通道的接收和发送都是阻塞的，除非与之对应的一端已经准备好阻塞状态： 数据写入channel（或缓存已满）却没读出 channel中没有数据，读channel会阻塞。 go反引号参考文章:GoLang获取struct的tag123456789type AppendEntriesRequest struct &#123;trueTerm *uint64 `protobuf:\"varint,1,req\" json:\"Term,omitempty\"`truePrevLogIndex *uint64 `protobuf:\"varint,2,req\" json:\"PrevLogIndex,omitempty\"`truePrevLogTerm *uint64 `protobuf:\"varint,3,req\" json:\"PrevLogTerm,omitempty\"`trueCommitIndex *uint64 `protobuf:\"varint,4,req\" json:\"CommitIndex,omitempty\"`trueLeaderName *string `protobuf:\"bytes,5,req\" json:\"LeaderName,omitempty\"`trueEntries []*LogEntry `protobuf:\"bytes,6,rep\" json:\"Entries,omitempty\"`trueXXX_unrecognized []byte `json:\"-\"`&#125; 其中,反引号表示字符串,struct后面的字符串用于reflect,具体用法s := AppendEntriesRequest{}st := reflect.TypeOf(s)field := st.Field(0)field.Tag.Get(“protobuf”) // varint,1,reqfield.Tag.Get(“json”) // Term,omitempty go get 安装程序错误错误提示:123unrecognized import path \"code.google.com/p/goprotobuf/proto\"parse https://code.google.com/p/goprotobuf?go-get=1: no go-import meta tags 错误原因:依赖包已从code.google.com移除, 已重定向到github.com/golang/protobuf/proto,修改程序中的代码即可 strconv.ParseInt(s string, base int, bitSize int) (i int64, err error) 或strconv.ParseUint把字符串转换为整数,参数1 数字的字符串形式 参数2 数字字符串的进制 比如二进制 八进制 十进制 十六进制 参数3 返回结果的bit大小 也就是int8 int16 int32 int64","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"}]},{"title":"seaweedfs源码阅读记录3-raft协议理解","slug":"seaweedfs源码阅读记录3-raft协议理解","date":"2016-11-28T00:00:00.000Z","updated":"2017-03-06T13:17:24.039Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录3-raft协议理解/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读记录3-raft协议理解/","excerpt":"","text":"raft用于seaweedfs的多个master server间进行leader选举,选出leader对其他master server进行管理. 参考文章Raft一致性算法raft动画演示raft介绍go-raft源码解析go-raft文档goraft的简单实现分布式一致性，Raft以及其它 阅读记录本文按照参考文章中的go-raft源码解析中的文章阅读,记录阅读过程.12345678910111213141516// The request sent to a server to append entries to the log.type AppendEntriesRequest struct &#123;trueTerm uint64truePrevLogIndex uint64truePrevLogTerm uint64trueCommitIndex uint64trueLeaderName stringtrueEntries []*protobuf.LogEntry // 定义在protobuf中的LogEntry&#125;// The response returned from a server appending entries to the log.type AppendEntriesResponse struct &#123;truepb *protobuf.AppendEntriesResponsetruepeer stringtrueappend bool&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"},{"name":"raft","slug":"raft","permalink":"https://makeitpossible16.github.io/tags/raft/"}]},{"title":"seaweedfs源码阅读记录1","slug":"seaweedfs源码阅读记录","date":"2016-11-22T00:00:00.000Z","updated":"2017-02-25T11:47:17.603Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读记录/","excerpt":"","text":"接下来的日子都会抽出部分时间学习文件存储,目标是修改openstack-swift的源码,通过源码学习文件存储知识.目前学习对象:seaweedfs. 目标:学习seaweedfs 的文件合并存储文件合并后必然会带来的一堆问题待解决,比如文件索引,响应速率等. 学习方式: google + 调试github 上能找到项目的wiki文档,会介绍简单的使用.调试方案: IDEA/pycharm , 需要结合atom/vscode 的delve调试go程序,各有利弊,结合使用. 测试用命令启动:master : weed master -mdir=/home/ubuntu/weedfsvolume : weed volume -dir=”/home/ubuntu/weedfs/data1” -mserver=”localhost:9333” -port=8080启用目录filter: weed filer -port=8888 -dir=/home/ubuntu/weedfs/filter1 -master=localhost:9333使用:curl -X POST http://localhost:9333/dir/assign 获取fid 参考文章分布式存储Seaweedfs源码分析 tonybai的个人blog weed-fs 源码解读—分布式处理过程 weed-fs 源码解读","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"seaweedfs源码阅读记录2","slug":"seaweedfs源码阅读记录2","date":"2016-11-22T00:00:00.000Z","updated":"2016-11-28T11:57:03.000Z","comments":true,"path":"文件存储/seaweedfs源码阅读记录2/","link":"","permalink":"https://makeitpossible16.github.io/文件存储/seaweedfs源码阅读记录2/","excerpt":"","text":"master启动过程使用pycharm , 入口为weed.go, 根据参数调用command文件夹下的文件.opology 核心模块，主要包括 【DataCenter, Rack, DataNode】 三层拓扑结构,参考文章： weed-fs 源码解读 12345type Sequencer interface &#123;trueNextFileId(count uint64) (uint64, uint64)trueSetMax(uint64)truePeek() uint64&#125; topology中包含Sequencer , sequence 负责FileID的全局有序生成 12345678910111213141516171819type Topology struct &#123;trueNodeImpl //指向NodeImpl对象，即Topology和node相互指向truecollectionMap *util.ConcurrentReadMaptruepulse int64truevolumeSizeLimit uint64trueSequence sequence.SequencertruechanDeadDataNodes chan *DataNodetruechanRecoveredDataNodes chan *DataNodetruechanFullVolumes chan storage.VolumeInfotrueconfiguration *ConfigurationtrueRaftServer raft.Server&#125; NodeImpl结构1234567891011121314type NodeImpl struct &#123;trueid NodeIdtruevolumeCount inttrueactiveVolumeCount inttruemaxVolumeCount inttrueparent Nodetruesync.RWMutex // lock childrentruechildren map[NodeId]NodetruemaxVolumeId storage.VolumeIdtrue//for rack, data center, topologytruenodeType stringtruevalue interface&#123;&#125; //指向Topology对象，即Topology和node相互指向&#125; DataNode数据结构123456789type DataNode struct &#123;trueNodeImpltruevolumes map[storage.VolumeId]storage.VolumeInfotrueIp stringtruePort inttruePublicUrl stringtrueLastSeen int64 // unix time in secondstrueDead bool&#125; 123456789101112type VolumeInfo struct &#123;trueId VolumeIdtrueSize uint64trueReplicaPlacement *ReplicaPlacementtrueTtl *TTLtrueCollection stringtrueVersion VersiontrueFileCount inttrueDeleteCount inttrueDeletedByteCount uint64trueReadOnly bool&#125; 通过RaftServer的raft协议，完成多个weedmaster间投票选leader的事情,当启动多个ServerMaster时，它们之间会进行通信，通过raft协议选举出一个Leader，对所有的master进行管理。weed-fs中，通过使用raftServer完成上述选举过程；而raftServer则是用到了第三方资源，即goRaft（参照http://ayende.com/blog/165858/reviewing-go-raft-part-i）。12345678type RaftServer struct &#123;truepeers []string // initial peers to join withtrueraftServer raft.Server //使用goraft //type Server interface 包含实现raft的方法truedataDir stringtruehttpAddr stringtruerouter *mux.Routertruetopo *topology.Topology&#125;","raw":null,"content":null,"categories":[{"name":"文件存储","slug":"文件存储","permalink":"https://makeitpossible16.github.io/categories/文件存储/"}],"tags":[{"name":"go","slug":"go","permalink":"https://makeitpossible16.github.io/tags/go/"},{"name":"seaweedfs","slug":"seaweedfs","permalink":"https://makeitpossible16.github.io/tags/seaweedfs/"}]},{"title":"cloudstack 搭建总结","slug":"cloudstack搭建总结","date":"2016-11-20T00:00:00.000Z","updated":"2017-02-14T04:09:05.448Z","comments":true,"path":"cloudsatck搭建/cloudstack搭建总结/","link":"","permalink":"https://makeitpossible16.github.io/cloudsatck搭建/cloudstack搭建总结/","excerpt":"","text":"按照官网的教程搭建cloudstack,稍不注意,就出现错误.总结一下. 子节点状态不对123[root@node3 ~]# service cloudstack-agent statuscloudstack-agent dead but subsys locked 解决：管理节点防火墙问题，正常状态下计算节点应通过NFS挂载主存储,管理节点应开放8250端口 执行完后把cloudstack-agent 重启一下，其状态应为running 系统VM 状态为Starting解决：在数据库中将这个虚拟机的状态由“Starting”更改成“Stopped”，重新启动虚拟机即可。 1MySQL -uroot -p -e \"update cloud.vm_instance set state='Stopped' where name=VMNAME 系统VM 状态为Running , 代理状态为空（centos6.5 图形化界面下的防火墙重启会清空iptables 文件下的规则）防火墙问题 管理节点也用作计算节点，防火墙状态应为 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# Generated by iptables-save v1.4.7 on Thu Jun 2 13:23:26 2016*nat:PREROUTING ACCEPT [187042:40599771]:POSTROUTING ACCEPT [36644:2281945]:OUTPUT ACCEPT [36644:2281945]COMMIT# Completed on Thu Jun 2 13:23:26 2016# Generated by iptables-save v1.4.7 on Thu Jun 2 13:23:26 2016*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [13422:54204084]:BF-cloud0 - [0:0]:BF-cloud0-IN - [0:0]:BF-cloud0-OUT - [0:0]-A INPUT -p tcp -m tcp --dport 49152:49216 -j ACCEPT-A INPUT -p tcp -m tcp --dport 5900:6100 -j ACCEPT-A INPUT -p tcp -m tcp --dport 16509 -j ACCEPT-A INPUT -p tcp -m tcp --dport 1798 -j ACCEPT-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5900 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5901 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5902 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8250 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 111 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 111 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 2049 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 32803 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 32769 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 892 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 892 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 875 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 875 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p tcp -m state --state NEW -m tcp --dport 662 -j ACCEPT-A INPUT -s 172.31.156.0/24 -p udp -m state --state NEW -m udp --dport 662 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -o cloud0 -m physdev --physdev-is-bridged -j BF-cloud0-A FORWARD -i cloud0 -m physdev --physdev-is-bridged -j BF-cloud0-A FORWARD -o cloud0 -j DROP-A FORWARD -i cloud0 -j DROP-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A BF-cloud0 -m state --state RELATED,ESTABLISHED -j ACCEPT-A BF-cloud0 -m physdev --physdev-is-in --physdev-is-bridged -j BF-cloud0-IN-A BF-cloud0 -m physdev --physdev-is-out --physdev-is-bridged -j BF-cloud0-OUT-A BF-cloud0 -m physdev --physdev-out vnet0 --physdev-is-bridged -j ACCEPTCOMMIT# Completed on Thu Jun 2 13:23:26 2016 计算节点防火墙状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*mangle:PREROUTING ACCEPT [654:130068]:INPUT ACCEPT [210:107800]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [143:8276]:POSTROUTING ACCEPT [143:8276]-A POSTROUTING -o virbr0 -p udp -m udp --dport 68 -j CHECKSUM --checksum-fill-A POSTROUTING -o virbr0 -p udp -m udp --dport 68 -j CHECKSUM --checksum-fillCOMMIT# Completed on Wed Jun 1 19:37:24 2016# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*nat:PREROUTING ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:OUTPUT ACCEPT [0:0]COMMIT# Completed on Wed Jun 1 19:37:24 2016# Generated by iptables-save v1.4.7 on Wed Jun 1 19:37:24 2016*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 53 -j ACCEPT-A INPUT -i virbr0 -p udp -m udp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT-A INPUT -p tcp -m tcp --dport 49152:49216 -j ACCEPT-A INPUT -p tcp -m tcp --dport 5900:6100 -j ACCEPT-A INPUT -p tcp -m tcp --dport 16509 -j ACCEPT-A INPUT -p tcp -m tcp --dport 1798 -j ACCEPT-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 5900 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 5901 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8250 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -i virbr0 -o virbr0 -j ACCEPT-A FORWARD -o virbr0 -j REJECT --reject-with icmp-port-unreachable-A FORWARD -i virbr0 -j REJECT --reject-with icmp-port-unreachableCOMMIT# Completed on Wed Jun 1 19:37:24 2016 二级存储及主存储路径需要设置权限，否则二级存储虽能挂载，但无法写入文件注意看日志文件，里面有详细的输出说明","raw":null,"content":null,"categories":[{"name":"cloudsatck搭建","slug":"cloudsatck搭建","permalink":"https://makeitpossible16.github.io/categories/cloudsatck搭建/"}],"tags":[{"name":"cloudsatck","slug":"cloudsatck","permalink":"https://makeitpossible16.github.io/tags/cloudsatck/"}]},{"title":"nodeJS入门总结","slug":"nodeJS入门总结","date":"2016-11-20T00:00:00.000Z","updated":"2016-11-24T14:55:44.836Z","comments":true,"path":"网站相关/nodeJS入门总结/","link":"","permalink":"https://makeitpossible16.github.io/网站相关/nodeJS入门总结/","excerpt":"","text":"刚做完nodeJS的课设,写了个小程序,总结一下 程序功能实现简单的电商网站,能登陆,注册,浏览商品,购物车操作. 使用技术 nodeJS + Express + ejs mongoDB + mongoose bootstrap + jquery (前端页面是在网上找的,随便改了一下) 实现代码github 有关mongoosemongoose实现了把mongodb中的数据进行映射,可以直接使用mongoose对数据库进行操作,比较方便.使用嵌套document时,需要创建多个Schema(类似于Java中的POJO吧).12345678910111213141516171819202122232425var contactInformationSchema = new Schema(&#123; address: String, phone: String&#125;)var alreadyPaidSchema = new Schema(&#123; productID: Schema.Types.ObjectId, price: Number, address: String, phone: String, userName: String&#125;)var unpaidSchema = new Schema(&#123; productID: Schema.Types.ObjectId, price: Number&#125;)var schema = new Schema(&#123; username: String, password: String, contactInformation: [contactInformationSchema], alreadyPaid: [alreadyPaidSchema], unpaid: [unpaidSchema]&#125;); 有关nodeJS最大的优点就是回调,实现网站的并发访问. 不过缺点也不少,可能是我经验不足,记录一下掉过的坑. 1. 回调,感觉就像是不负责任地甩锅.1234567var test;for (var i = 0; i &lt; array.length; i++) &#123; test = array[i]; mongooseModel.find(&#123;\"something\":test&#125;).exec(function(err,document)&#123; var test1 = test; //此时的test可能已经是下一循环的值 &#125;)&#125; 2. 回调,导致代码层层嵌套3. 单进程,一旦进程发生阻塞,这个程序都会阻塞123while (true) &#123; //整个程序陷入死循环&#125; 4. 还是回调,导致数据库跨collection查询困难5. Express 中的模板应谨慎使用.我在项目中大量使用了ejs模板,当初就是为了图方便,直接使用ejs,实际上模板只应在静态文件中使用,也就是能保证模板中的内容在多个页面中同时适用,对于内容变化比较的页面,还是乖乖地写接口,返回JSON数据比较靠谱. 总结项目总体还是比较失败,不过也能学点东西. 比如 nodeJS , mongodb, 还有一点前端知识","raw":null,"content":null,"categories":[{"name":"网站相关","slug":"网站相关","permalink":"https://makeitpossible16.github.io/categories/网站相关/"}],"tags":[{"name":"nodeJS","slug":"nodeJS","permalink":"https://makeitpossible16.github.io/tags/nodeJS/"},{"name":"mongodb","slug":"mongodb","permalink":"https://makeitpossible16.github.io/tags/mongodb/"},{"name":"Express","slug":"Express","permalink":"https://makeitpossible16.github.io/tags/Express/"},{"name":"mongoose","slug":"mongoose","permalink":"https://makeitpossible16.github.io/tags/mongoose/"}]},{"title":"ubuntu下如何优雅地使用翻译","slug":"ubuntu下如何优雅地使用翻译","date":"2016-10-26T00:00:00.000Z","updated":"2017-03-01T03:03:27.140Z","comments":true,"path":"有道字典修改/ubuntu下如何优雅地使用翻译/","link":"","permalink":"https://makeitpossible16.github.io/有道字典修改/ubuntu下如何优雅地使用翻译/","excerpt":"","text":"最近看英文文档比较多，但英语水平不咋地，需要借助翻译工具。在ubuntu下，有startdict、goldendict等字典，但字典毕竟是字典，解释太多，用着不太爽。平时喜欢用谷歌翻译，最近谷歌翻译的水平也的确提升了不少，可惜没有客户端，平时看个PDF啥的也用不了，github 上的发现mtranslate模块，把网址改为中国的网址，得到结果还挺快. 本来想写个接口封装一下，直接用goldendict显示的，无奈网络延迟太大，谷歌翻译都没出结果，字典的弹框就出来了，能找到goldendict的源码，但看到那一坨代码，实在没有修改的欲望。偶然的机会，发现了某道有ubuntu的客户端，解压出来，居然是python的代码，还是python大法好，这样就来优雅地改一下代码吧。最后实现功能：在弹框中显示调用mtranslate模块显示的翻译信息 点击保存，将所翻译的单词保存到指定目录的translate.csv文件中 调整弹框显示，解决翻译文本过长导致弹框显示不全的问题 实现过程：下载mtranslate模块配置运行环境使用python3，先安装youdao的客户端，解决依赖关系，然后把youdao卸载。 代码实现过程下载.deb包，解压，参考文章http://www.cnblogs.com/scplee/archive/2016/05/13/5489024.html 在dae/utils.py增加代码123456def get_conf(): import json import os with open('configuration.json', 'r') as f: conf = json.load(f) return conf 修改translate.py文件修改get_translate方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546def get_translate(self, text): data = &#123; \"keyfrom\" : \"deskdict.linux\", \"q\" : text.encode(\"utf-8\"), \"doctype\" : \"xml\", \"xmlVersion\" : 8.2, \"client\" : const.client, \"id\" : \"cee84504d9984f1b2\", \"vendor\": \"deskdict.linux\", \"in\" : \"YoudaoDict\", \"appVer\" : \"5.4.46.5554\", \"appZengqiang\" : 0, \"le\" : \"eng\", \"LTH\" : 40&#125; # self.clear_translate() # try: ret = requests.get(\"http://dict.youdao.com/search\", params=data).text ret = ret.encode('utf-8') pq = PyQuery(ret, parser=\"xml\") test_data = &#123;\"q\": text, \"type\": 1, \"pos\": -1, \"client\": const.client&#125; test_ret = json.loads(requests.get(\"http://dict.youdao.com/jsonresult\", params=test_data).text) self.translate_info.text = text text = str(text).replace('\\n',' ') from dae.utils import get_conf conf = get_conf() self.translate_info.webtrans = \"谷歌翻译:\\n\" if (str(conf['useTranslateModule']).upper() == 'TRUE' ): self.translate_info.webtrans = self.translate_info.webtrans + useTranslateComponent(text) + \"\\n\" # if self.translate_info.webtrans: self.translate_info.webtrans =self.translate_info.webtrans + \"有道:\\n\" self.translate_info.trans = '\\n'.join([PyQuery(l)(\"i\").text() for l in pq('trs l')]) self.translate_info.phonetic = test_ret.get(\"ussm\", \"\") self.translate_info.webtrans = self.translate_info.webtrans + self.wrap_web_trans(pq) # self.translate_info.lang = test_ret.get(\"lang\", \"\") # # except: # with open_offline_dict() as obj: # ret = obj.query(text) # if ret: # self.translate_info.text = text # self.translate_info.trans = ret[1].replace(\"\\\\n\", \"\\n\") # self.translate_info.phonetic = ret[0][1:-1] # self.translate_info.webtrans = \"抱歉，从网络获取结果失败，请检测网络重试\" # self.translate_info.lang = \"eng\" # self.translate_info.voices = get_voice_simple(text) # if not text: # return #self.clear_translate() #self.translate_info.text = text if not self.translate_info.webtrans: self.translate_info.webtrans = \"查询失败\" if self.translate_info.webtrans: self.translateFinished.emit() 在translate.py中添加代码：12345678def useTranslateComponent(text): import os from dae.utils import get_conf conf = get_conf() toLang = conf['toLang'] from mtranslate import translate translation = translate(text,toLang) return translation 在windows.py添加类：12345678910111213141516171819202122232425262728293031323334353637383940#@ 保存到文件 class saveToFile(QtCore.QObject): @QtCore.pyqtSlot(str, str) def saveToFile(self,fromText,toText): import os import csv from dae.utils import get_conf toText = str(toText).replace('谷歌翻译:','') toText = toText.split('有道:') firstText = '' if toText[0]: firstText = toText[0].strip('\\n') lastText = toText[1].replace('有道:','').strip('\\n').lstrip('w. ') if (firstText or lastText): if not firstText: firstText = ' ' if not lastText: lastText = ' ' conf = get_conf() savePath = str(conf['savePath']).rstrip('/') + '/translate.csv' if not os.path.exists(savePath): with open(savePath,'a+') as f: writer = csv.writer(f) writer.writerow(['翻译内容','谷歌翻译','有道词典']) writeData = [ fromText, firstText, lastText ] writer.writerow(writeData) f.close() return with open(savePath,'a+') as f: writer = csv.writer(f) writeData = [ fromText, firstText, lastText ] writer.writerow(writeData) f.close() return return 在window.py 的init()方法中添加代码123#@ 单词保存到文件 self.saveToFile = saveToFile() self.qml_context.setContextProperty(\"saveToFile\", self.saveToFile) #把saveToFile类暴露给qml文件 在TranslateContent.qml 添加TextEdit，位置自己看着办就行1234567891011121314151617181920212223242526TextEdit&#123; color: \"#ff0000\" anchors.verticalCenter: parent.verticalCenter text: \" 保存\" selectByMouse: true readOnly: true font.pixelSize: 15 MouseArea &#123; anchors.fill: parent hoverEnabled: true onExited: &#123; cursorShape = Qt.ArrowCursor &#125; onClicked: &#123; saveToFile.saveToFile(translateInfo.text, translateInfo.webtrans) if (parent.color == \"#2699eb\")&#123; parent.color = \"#ff0000\"; &#125; else&#123; if(parent.color == \"#ff0000\")&#123; parent.color = \"#2699eb\" &#125; &#125; &#125; &#125; &#125; 修改翻译内容显示方式1234567891011TextEdit&#123; id: keywordsText width: parent.width //anchors.verticalCenter: parent.verticalCenter selectByMouse: true readOnly: true text: translateInfo.text wrapMode: Text.WordWrap font.pixelSize: 13 font.bold: true &#125; 添加配置文件在main.py所在文件夹下添加配置文件configuration.json，配置文件，可以选择是否启用translate模块，配置保存翻译信息文件位置，使用translate时系统调用的命令123456&#123; \"useTranslateModule\": \"true\", \"savePath\": \"/home/ubuntu/Desktop\", \"cmd\": \"translate -f en -t zh \", \"toLang\": \"zh\"&#125; 运行直接运行main.py youdao-dict-backend.py就行, 可写个简单的脚本来实现 总结直接利用youdao原有的事件处理，总体能用，但没有startdict或goldendict流畅，如果能直接修改startdict或goldendict的代码，利用它们的事件处理，估计会更稳定，不过最近比较忙,先凑合着用吧.","raw":null,"content":null,"categories":[{"name":"有道字典修改","slug":"有道字典修改","permalink":"https://makeitpossible16.github.io/categories/有道字典修改/"}],"tags":[{"name":"python","slug":"python","permalink":"https://makeitpossible16.github.io/tags/python/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://makeitpossible16.github.io/tags/ubuntu/"}]},{"title":"github目录","slug":"README","date":"2016-01-01T00:00:00.000Z","updated":"2017-03-08T11:40:10.079Z","comments":true,"path":"uncategorized/README/","link":"","permalink":"https://makeitpossible16.github.io/uncategorized/README/","excerpt":"","text":"blogMarkdownFile寻找实习单位,个人简介myblogC++语法记录ELKStack搭建问题总结LRU缓存淘汰算法LeetCode解题-Next Permutation(全排列生成算法).md)LeetCode解题-Permutation Sequencecloudstack搭建总结gdb调试错误-找不到文件golang 反射机制golang学习golang调试技巧kafka学习笔记linux内核学习-数据结构linux命令学习linux学习-linux文件存储linux文件存储机制nodeJS入门总结openstack-swift源码阅读记录1-文件上传过程openstack-swift源码阅读记录3-diskfileopenstack-swift源码阅读记录4-启用mem_diskfileopenstack-swift调试openstack源码阅读记录2-object metadatapython语法记录seaweedfs源码阅读4-volume启动seaweedfs源码阅读5-文件PUT过程seaweedfs源码阅读6-文件存储格式seaweedfs源码阅读7-文件存储过程seaweedfs源码阅读8-GET&amp;HEAD获取文件过程seaweedfs源码阅读记录seaweedfs源码阅读记录2seaweedfs源码阅读记录3-raft协议理解seaweedfs源码阅读记录9-生成fid过程swift-weedfs-backend diskfile代码实现swift-weedfs-backend接口设计ubuntu下如何优雅地使用翻译ubuntu使用问题总结伪随机数在Openstack Swift中使用多种后端存储实现对象存储VS文件系统数据结构文件系统(seaweedfs)与关系型数据库优劣势分析与关系型数据库优劣势分析.md)查找-数据结构学习","raw":null,"content":null,"categories":[],"tags":[]}]}